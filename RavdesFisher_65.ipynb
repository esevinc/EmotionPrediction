{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esevinc/SER/blob/main/RavdesFisher_65.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "ZVbHKrKpXnOH"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import IPython.display as ipd  # To play sound in the notebook\n",
        "import os # interface with underlying OS that python is running on\n",
        "import sys\n",
        "main_dir='drive/MyDrive/SER/'\n",
        "\n",
        "data = pd.read_csv(main_dir+'../ravdes/featureNormal_Ek.csv')\n",
        "\n",
        "#data = pd.read_csv('../ravdes/featureNormal_Ek.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC1vjaa1Y34V",
        "outputId": "c16e1ac9-7add-4d92-b162-e0399d13a55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq0-b_KUY9nv",
        "outputId": "576105eb-99c0-4d8e-fd2f-4f7f42d3c4ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EmoDBFisher_Fem_75.ipynb   Femalemodel2.json\t  RavdesFisherFemale_75.ipynb  RAVDESS_Model_Female\n",
            "EmoDBFisher_Male_75.ipynb  Femalemodel3.json\t  RavdesFisherMale_75.ipynb    RAVDESS_Model_Male75\n",
            "Emodb_Model75\t\t   Femalemodel4.json\t  ravdesMale_5FoldsMale.png\n",
            "Femalemodel0.json\t   peerj\t\t  ravdesMale_75.png\n",
            "Femalemodel1.json\t   RavdesFisher_50.ipynb  RAVDESS_Model50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "4vdCRE7DXnOH",
        "outputId": "be10ba9a-6cd8-47e3-ea2c-c1c2198ec96b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               0          1          2          3          4          5  \\\n",
              "0    -673.301697  69.508095  -3.494582  18.998575   5.041687   4.626438   \n",
              "1    -663.297852  67.747589  -6.961255  22.244839   5.313937   2.970508   \n",
              "2    -664.776184  70.703842  -4.903909  18.797665   1.573513   4.084437   \n",
              "3    -660.674133  69.261803  -1.020717  19.743364   3.635317   6.417199   \n",
              "4    -699.495178  76.727394  -1.602398  21.554548   4.587931   6.054961   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "1435 -558.443298  34.201637 -25.876736   3.420890 -22.962826  -6.289969   \n",
              "1436 -509.914642  49.378990 -22.979485  -0.832579 -23.050257 -10.238819   \n",
              "1437 -517.733276  40.459633 -27.217442   2.902560 -22.611633 -14.189220   \n",
              "1438 -463.998352  35.496925 -14.260783   9.399699 -19.878208   0.799514   \n",
              "1439 -499.242126  39.540497  -8.361695   3.750752 -10.930555  -1.502927   \n",
              "\n",
              "              6          7          8         9  ...        185        186  \\\n",
              "0     -7.605268  -0.057042 -16.231766 -0.299419  ...  17.645388  31.995356   \n",
              "1     -6.046401  -3.327282 -17.383774  0.806942  ...  17.582760  31.223174   \n",
              "2     -6.752044  -3.895945 -15.839313 -2.361090  ...  17.437520  31.753796   \n",
              "3     -5.448439  -4.090719 -15.130262 -1.551855  ...  16.492804  30.522612   \n",
              "4     -8.122147  -1.003357 -15.158166 -2.688365  ...  17.020093  31.293542   \n",
              "...         ...        ...        ...       ...  ...        ...        ...   \n",
              "1435 -22.845768 -13.475706 -11.609130 -4.602691  ...  17.573820  31.661293   \n",
              "1436 -17.452888  -8.696088 -14.158811  0.367432  ...  17.932740  31.846921   \n",
              "1437 -19.589163  -8.899709 -12.807209  3.745601  ...  18.503842  31.628901   \n",
              "1438 -18.052525  -4.351163  -7.299998  0.214021  ...  17.360766  31.137002   \n",
              "1439 -16.925844  -1.147182 -14.435615  2.066961  ...  16.629113  31.947595   \n",
              "\n",
              "           187       188       189       190       191       192  0.1  0.2  \n",
              "0    -0.051473  0.025316 -0.044013 -0.079353  0.022513  0.010037    1    1  \n",
              "1    -0.079423  0.034342 -0.070702 -0.074578  0.025509 -0.001626    1    1  \n",
              "2    -0.024101 -0.010724 -0.007700  0.022802 -0.000364  0.032532    1    1  \n",
              "3    -0.065819  0.008619  0.004848 -0.030447 -0.000754  0.014753    1    1  \n",
              "4    -0.070505  0.011104  0.031151 -0.115693  0.024391  0.003346    1    2  \n",
              "...        ...       ...       ...       ...       ...       ...  ...  ...  \n",
              "1435 -0.020466  0.014107  0.020899  0.050697 -0.005623  0.022015    0    8  \n",
              "1436 -0.040751  0.017479  0.014917  0.015533  0.016873 -0.000375    0    8  \n",
              "1437 -0.032364  0.032572 -0.050994  0.009171  0.007204  0.013219    0    8  \n",
              "1438 -0.045889  0.027680 -0.042989 -0.060098  0.005997 -0.009220    0    8  \n",
              "1439 -0.068432  0.061563 -0.022390 -0.051703 -0.010379  0.017864    0    8  \n",
              "\n",
              "[1440 rows x 195 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a0d1155-81bc-4ae2-99e0-c7b723bf1507\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-673.301697</td>\n",
              "      <td>69.508095</td>\n",
              "      <td>-3.494582</td>\n",
              "      <td>18.998575</td>\n",
              "      <td>5.041687</td>\n",
              "      <td>4.626438</td>\n",
              "      <td>-7.605268</td>\n",
              "      <td>-0.057042</td>\n",
              "      <td>-16.231766</td>\n",
              "      <td>-0.299419</td>\n",
              "      <td>...</td>\n",
              "      <td>17.645388</td>\n",
              "      <td>31.995356</td>\n",
              "      <td>-0.051473</td>\n",
              "      <td>0.025316</td>\n",
              "      <td>-0.044013</td>\n",
              "      <td>-0.079353</td>\n",
              "      <td>0.022513</td>\n",
              "      <td>0.010037</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-663.297852</td>\n",
              "      <td>67.747589</td>\n",
              "      <td>-6.961255</td>\n",
              "      <td>22.244839</td>\n",
              "      <td>5.313937</td>\n",
              "      <td>2.970508</td>\n",
              "      <td>-6.046401</td>\n",
              "      <td>-3.327282</td>\n",
              "      <td>-17.383774</td>\n",
              "      <td>0.806942</td>\n",
              "      <td>...</td>\n",
              "      <td>17.582760</td>\n",
              "      <td>31.223174</td>\n",
              "      <td>-0.079423</td>\n",
              "      <td>0.034342</td>\n",
              "      <td>-0.070702</td>\n",
              "      <td>-0.074578</td>\n",
              "      <td>0.025509</td>\n",
              "      <td>-0.001626</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-664.776184</td>\n",
              "      <td>70.703842</td>\n",
              "      <td>-4.903909</td>\n",
              "      <td>18.797665</td>\n",
              "      <td>1.573513</td>\n",
              "      <td>4.084437</td>\n",
              "      <td>-6.752044</td>\n",
              "      <td>-3.895945</td>\n",
              "      <td>-15.839313</td>\n",
              "      <td>-2.361090</td>\n",
              "      <td>...</td>\n",
              "      <td>17.437520</td>\n",
              "      <td>31.753796</td>\n",
              "      <td>-0.024101</td>\n",
              "      <td>-0.010724</td>\n",
              "      <td>-0.007700</td>\n",
              "      <td>0.022802</td>\n",
              "      <td>-0.000364</td>\n",
              "      <td>0.032532</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-660.674133</td>\n",
              "      <td>69.261803</td>\n",
              "      <td>-1.020717</td>\n",
              "      <td>19.743364</td>\n",
              "      <td>3.635317</td>\n",
              "      <td>6.417199</td>\n",
              "      <td>-5.448439</td>\n",
              "      <td>-4.090719</td>\n",
              "      <td>-15.130262</td>\n",
              "      <td>-1.551855</td>\n",
              "      <td>...</td>\n",
              "      <td>16.492804</td>\n",
              "      <td>30.522612</td>\n",
              "      <td>-0.065819</td>\n",
              "      <td>0.008619</td>\n",
              "      <td>0.004848</td>\n",
              "      <td>-0.030447</td>\n",
              "      <td>-0.000754</td>\n",
              "      <td>0.014753</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-699.495178</td>\n",
              "      <td>76.727394</td>\n",
              "      <td>-1.602398</td>\n",
              "      <td>21.554548</td>\n",
              "      <td>4.587931</td>\n",
              "      <td>6.054961</td>\n",
              "      <td>-8.122147</td>\n",
              "      <td>-1.003357</td>\n",
              "      <td>-15.158166</td>\n",
              "      <td>-2.688365</td>\n",
              "      <td>...</td>\n",
              "      <td>17.020093</td>\n",
              "      <td>31.293542</td>\n",
              "      <td>-0.070505</td>\n",
              "      <td>0.011104</td>\n",
              "      <td>0.031151</td>\n",
              "      <td>-0.115693</td>\n",
              "      <td>0.024391</td>\n",
              "      <td>0.003346</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>-558.443298</td>\n",
              "      <td>34.201637</td>\n",
              "      <td>-25.876736</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.845768</td>\n",
              "      <td>-13.475706</td>\n",
              "      <td>-11.609130</td>\n",
              "      <td>-4.602691</td>\n",
              "      <td>...</td>\n",
              "      <td>17.573820</td>\n",
              "      <td>31.661293</td>\n",
              "      <td>-0.020466</td>\n",
              "      <td>0.014107</td>\n",
              "      <td>0.020899</td>\n",
              "      <td>0.050697</td>\n",
              "      <td>-0.005623</td>\n",
              "      <td>0.022015</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>-509.914642</td>\n",
              "      <td>49.378990</td>\n",
              "      <td>-22.979485</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-17.452888</td>\n",
              "      <td>-8.696088</td>\n",
              "      <td>-14.158811</td>\n",
              "      <td>0.367432</td>\n",
              "      <td>...</td>\n",
              "      <td>17.932740</td>\n",
              "      <td>31.846921</td>\n",
              "      <td>-0.040751</td>\n",
              "      <td>0.017479</td>\n",
              "      <td>0.014917</td>\n",
              "      <td>0.015533</td>\n",
              "      <td>0.016873</td>\n",
              "      <td>-0.000375</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>-517.733276</td>\n",
              "      <td>40.459633</td>\n",
              "      <td>-27.217442</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-19.589163</td>\n",
              "      <td>-8.899709</td>\n",
              "      <td>-12.807209</td>\n",
              "      <td>3.745601</td>\n",
              "      <td>...</td>\n",
              "      <td>18.503842</td>\n",
              "      <td>31.628901</td>\n",
              "      <td>-0.032364</td>\n",
              "      <td>0.032572</td>\n",
              "      <td>-0.050994</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.007204</td>\n",
              "      <td>0.013219</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>-463.998352</td>\n",
              "      <td>35.496925</td>\n",
              "      <td>-14.260783</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-18.052525</td>\n",
              "      <td>-4.351163</td>\n",
              "      <td>-7.299998</td>\n",
              "      <td>0.214021</td>\n",
              "      <td>...</td>\n",
              "      <td>17.360766</td>\n",
              "      <td>31.137002</td>\n",
              "      <td>-0.045889</td>\n",
              "      <td>0.027680</td>\n",
              "      <td>-0.042989</td>\n",
              "      <td>-0.060098</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>-0.009220</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>-499.242126</td>\n",
              "      <td>39.540497</td>\n",
              "      <td>-8.361695</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-16.925844</td>\n",
              "      <td>-1.147182</td>\n",
              "      <td>-14.435615</td>\n",
              "      <td>2.066961</td>\n",
              "      <td>...</td>\n",
              "      <td>16.629113</td>\n",
              "      <td>31.947595</td>\n",
              "      <td>-0.068432</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>-0.022390</td>\n",
              "      <td>-0.051703</td>\n",
              "      <td>-0.010379</td>\n",
              "      <td>0.017864</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1440 rows × 195 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a0d1155-81bc-4ae2-99e0-c7b723bf1507')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1a0d1155-81bc-4ae2-99e0-c7b723bf1507 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1a0d1155-81bc-4ae2-99e0-c7b723bf1507');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-169dfb07-8474-4e3e-91c7-35aa301a8343\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-169dfb07-8474-4e3e-91c7-35aa301a8343')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-169dfb07-8474-4e3e-91c7-35aa301a8343 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8e292b91-abd9-4712-8241-63080a178f95\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8e292b91-abd9-4712-8241-63080a178f95 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "QelSI94GXnOI",
        "outputId": "0b1f025b-ece4-4d2e-8ec4-3cdb00ffbae6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1440, 195)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "kcxi_dM-XnOI"
      },
      "outputs": [],
      "source": [
        "df=data.loc[data.iloc[:,-2] == 0] #female\n",
        "#ymale=data.loc[data.iloc[:,-2] == 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "HMbM0m37XnOJ",
        "outputId": "01c647a8-0a91-4358-fafd-228fb9151bba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       False\n",
              "1       False\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "        ...  \n",
              "1435     True\n",
              "1436     True\n",
              "1437     True\n",
              "1438     True\n",
              "1439     True\n",
              "Name: 0.1, Length: 1440, dtype: bool"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.iloc[:,-2] == 0 #female"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "88-AyDRtXnOJ"
      },
      "outputs": [],
      "source": [
        "X=df.iloc[:,:-2].copy()\n",
        "y=df.iloc[:,-1].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "DWsxDWMbXnOJ",
        "outputId": "9ce0f411-834b-457f-e209-c2824e44528e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>-626.065857</td>\n",
              "      <td>67.129211</td>\n",
              "      <td>-14.506104</td>\n",
              "      <td>13.734784</td>\n",
              "      <td>-8.915299</td>\n",
              "      <td>-0.597560</td>\n",
              "      <td>-9.627712</td>\n",
              "      <td>-6.697053</td>\n",
              "      <td>-7.643127</td>\n",
              "      <td>1.682984</td>\n",
              "      <td>...</td>\n",
              "      <td>15.032267</td>\n",
              "      <td>17.122944</td>\n",
              "      <td>17.137267</td>\n",
              "      <td>32.684056</td>\n",
              "      <td>-0.035477</td>\n",
              "      <td>0.046495</td>\n",
              "      <td>0.018824</td>\n",
              "      <td>-0.060412</td>\n",
              "      <td>0.011128</td>\n",
              "      <td>0.000489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>-622.978882</td>\n",
              "      <td>61.610241</td>\n",
              "      <td>-16.155281</td>\n",
              "      <td>17.274385</td>\n",
              "      <td>-10.515155</td>\n",
              "      <td>-0.012929</td>\n",
              "      <td>-9.384588</td>\n",
              "      <td>-5.405496</td>\n",
              "      <td>-6.061921</td>\n",
              "      <td>0.427206</td>\n",
              "      <td>...</td>\n",
              "      <td>15.800671</td>\n",
              "      <td>16.939402</td>\n",
              "      <td>16.786359</td>\n",
              "      <td>32.054128</td>\n",
              "      <td>-0.038423</td>\n",
              "      <td>0.033620</td>\n",
              "      <td>0.028817</td>\n",
              "      <td>-0.024666</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>-0.008258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>-594.977844</td>\n",
              "      <td>62.693829</td>\n",
              "      <td>-16.257780</td>\n",
              "      <td>9.051161</td>\n",
              "      <td>-9.175509</td>\n",
              "      <td>-0.249130</td>\n",
              "      <td>-9.898236</td>\n",
              "      <td>-7.671722</td>\n",
              "      <td>-8.782819</td>\n",
              "      <td>0.426915</td>\n",
              "      <td>...</td>\n",
              "      <td>15.484927</td>\n",
              "      <td>17.181703</td>\n",
              "      <td>18.043089</td>\n",
              "      <td>31.869979</td>\n",
              "      <td>-0.053699</td>\n",
              "      <td>0.053169</td>\n",
              "      <td>0.032318</td>\n",
              "      <td>-0.044163</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>-0.013748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>-612.936279</td>\n",
              "      <td>58.990162</td>\n",
              "      <td>-15.687172</td>\n",
              "      <td>10.080914</td>\n",
              "      <td>-11.711167</td>\n",
              "      <td>-1.830589</td>\n",
              "      <td>-11.331991</td>\n",
              "      <td>-8.769240</td>\n",
              "      <td>-10.589375</td>\n",
              "      <td>-0.807020</td>\n",
              "      <td>...</td>\n",
              "      <td>15.257555</td>\n",
              "      <td>16.719364</td>\n",
              "      <td>17.726324</td>\n",
              "      <td>31.140206</td>\n",
              "      <td>-0.045528</td>\n",
              "      <td>0.042565</td>\n",
              "      <td>-0.070671</td>\n",
              "      <td>-0.055261</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>-0.008018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>-639.557617</td>\n",
              "      <td>64.624420</td>\n",
              "      <td>-8.859457</td>\n",
              "      <td>17.944416</td>\n",
              "      <td>-9.782133</td>\n",
              "      <td>2.161584</td>\n",
              "      <td>-7.936422</td>\n",
              "      <td>-4.958043</td>\n",
              "      <td>-6.853294</td>\n",
              "      <td>0.523445</td>\n",
              "      <td>...</td>\n",
              "      <td>16.251168</td>\n",
              "      <td>17.629721</td>\n",
              "      <td>16.558219</td>\n",
              "      <td>31.837218</td>\n",
              "      <td>-0.089607</td>\n",
              "      <td>0.068644</td>\n",
              "      <td>-0.019986</td>\n",
              "      <td>-0.011248</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>0.004188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>-558.443298</td>\n",
              "      <td>34.201637</td>\n",
              "      <td>-25.876736</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.845768</td>\n",
              "      <td>-13.475706</td>\n",
              "      <td>-11.609130</td>\n",
              "      <td>-4.602691</td>\n",
              "      <td>...</td>\n",
              "      <td>16.391113</td>\n",
              "      <td>18.151034</td>\n",
              "      <td>17.573820</td>\n",
              "      <td>31.661293</td>\n",
              "      <td>-0.020466</td>\n",
              "      <td>0.014107</td>\n",
              "      <td>0.020899</td>\n",
              "      <td>0.050697</td>\n",
              "      <td>-0.005623</td>\n",
              "      <td>0.022015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>-509.914642</td>\n",
              "      <td>49.378990</td>\n",
              "      <td>-22.979485</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-17.452888</td>\n",
              "      <td>-8.696088</td>\n",
              "      <td>-14.158811</td>\n",
              "      <td>0.367432</td>\n",
              "      <td>...</td>\n",
              "      <td>16.270073</td>\n",
              "      <td>17.091367</td>\n",
              "      <td>17.932740</td>\n",
              "      <td>31.846921</td>\n",
              "      <td>-0.040751</td>\n",
              "      <td>0.017479</td>\n",
              "      <td>0.014917</td>\n",
              "      <td>0.015533</td>\n",
              "      <td>0.016873</td>\n",
              "      <td>-0.000375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>-517.733276</td>\n",
              "      <td>40.459633</td>\n",
              "      <td>-27.217442</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-19.589163</td>\n",
              "      <td>-8.899709</td>\n",
              "      <td>-12.807209</td>\n",
              "      <td>3.745601</td>\n",
              "      <td>...</td>\n",
              "      <td>16.128660</td>\n",
              "      <td>16.947312</td>\n",
              "      <td>18.503842</td>\n",
              "      <td>31.628901</td>\n",
              "      <td>-0.032364</td>\n",
              "      <td>0.032572</td>\n",
              "      <td>-0.050994</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.007204</td>\n",
              "      <td>0.013219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>-463.998352</td>\n",
              "      <td>35.496925</td>\n",
              "      <td>-14.260783</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-18.052525</td>\n",
              "      <td>-4.351163</td>\n",
              "      <td>-7.299998</td>\n",
              "      <td>0.214021</td>\n",
              "      <td>...</td>\n",
              "      <td>16.307834</td>\n",
              "      <td>17.859030</td>\n",
              "      <td>17.360766</td>\n",
              "      <td>31.137002</td>\n",
              "      <td>-0.045889</td>\n",
              "      <td>0.027680</td>\n",
              "      <td>-0.042989</td>\n",
              "      <td>-0.060098</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>-0.009220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>-499.242126</td>\n",
              "      <td>39.540497</td>\n",
              "      <td>-8.361695</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-16.925844</td>\n",
              "      <td>-1.147182</td>\n",
              "      <td>-14.435615</td>\n",
              "      <td>2.066961</td>\n",
              "      <td>...</td>\n",
              "      <td>15.493485</td>\n",
              "      <td>16.808408</td>\n",
              "      <td>16.629113</td>\n",
              "      <td>31.947595</td>\n",
              "      <td>-0.068432</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>-0.022390</td>\n",
              "      <td>-0.051703</td>\n",
              "      <td>-0.010379</td>\n",
              "      <td>0.017864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0          1          2          3          4          5  \\\n",
              "60   -626.065857  67.129211 -14.506104  13.734784  -8.915299  -0.597560   \n",
              "61   -622.978882  61.610241 -16.155281  17.274385 -10.515155  -0.012929   \n",
              "62   -594.977844  62.693829 -16.257780   9.051161  -9.175509  -0.249130   \n",
              "63   -612.936279  58.990162 -15.687172  10.080914 -11.711167  -1.830589   \n",
              "64   -639.557617  64.624420  -8.859457  17.944416  -9.782133   2.161584   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "1435 -558.443298  34.201637 -25.876736   3.420890 -22.962826  -6.289969   \n",
              "1436 -509.914642  49.378990 -22.979485  -0.832579 -23.050257 -10.238819   \n",
              "1437 -517.733276  40.459633 -27.217442   2.902560 -22.611633 -14.189220   \n",
              "1438 -463.998352  35.496925 -14.260783   9.399699 -19.878208   0.799514   \n",
              "1439 -499.242126  39.540497  -8.361695   3.750752 -10.930555  -1.502927   \n",
              "\n",
              "              6          7          8         9  ...        183        184  \\\n",
              "60    -9.627712  -6.697053  -7.643127  1.682984  ...  15.032267  17.122944   \n",
              "61    -9.384588  -5.405496  -6.061921  0.427206  ...  15.800671  16.939402   \n",
              "62    -9.898236  -7.671722  -8.782819  0.426915  ...  15.484927  17.181703   \n",
              "63   -11.331991  -8.769240 -10.589375 -0.807020  ...  15.257555  16.719364   \n",
              "64    -7.936422  -4.958043  -6.853294  0.523445  ...  16.251168  17.629721   \n",
              "...         ...        ...        ...       ...  ...        ...        ...   \n",
              "1435 -22.845768 -13.475706 -11.609130 -4.602691  ...  16.391113  18.151034   \n",
              "1436 -17.452888  -8.696088 -14.158811  0.367432  ...  16.270073  17.091367   \n",
              "1437 -19.589163  -8.899709 -12.807209  3.745601  ...  16.128660  16.947312   \n",
              "1438 -18.052525  -4.351163  -7.299998  0.214021  ...  16.307834  17.859030   \n",
              "1439 -16.925844  -1.147182 -14.435615  2.066961  ...  15.493485  16.808408   \n",
              "\n",
              "            185        186       187       188       189       190       191  \\\n",
              "60    17.137267  32.684056 -0.035477  0.046495  0.018824 -0.060412  0.011128   \n",
              "61    16.786359  32.054128 -0.038423  0.033620  0.028817 -0.024666  0.011614   \n",
              "62    18.043089  31.869979 -0.053699  0.053169  0.032318 -0.044163  0.002315   \n",
              "63    17.726324  31.140206 -0.045528  0.042565 -0.070671 -0.055261  0.010003   \n",
              "64    16.558219  31.837218 -0.089607  0.068644 -0.019986 -0.011248  0.001546   \n",
              "...         ...        ...       ...       ...       ...       ...       ...   \n",
              "1435  17.573820  31.661293 -0.020466  0.014107  0.020899  0.050697 -0.005623   \n",
              "1436  17.932740  31.846921 -0.040751  0.017479  0.014917  0.015533  0.016873   \n",
              "1437  18.503842  31.628901 -0.032364  0.032572 -0.050994  0.009171  0.007204   \n",
              "1438  17.360766  31.137002 -0.045889  0.027680 -0.042989 -0.060098  0.005997   \n",
              "1439  16.629113  31.947595 -0.068432  0.061563 -0.022390 -0.051703 -0.010379   \n",
              "\n",
              "           192  \n",
              "60    0.000489  \n",
              "61   -0.008258  \n",
              "62   -0.013748  \n",
              "63   -0.008018  \n",
              "64    0.004188  \n",
              "...        ...  \n",
              "1435  0.022015  \n",
              "1436 -0.000375  \n",
              "1437  0.013219  \n",
              "1438 -0.009220  \n",
              "1439  0.017864  \n",
              "\n",
              "[720 rows x 193 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2d_hNKI3XnOK",
        "outputId": "1b4a55d3-4089-4638-a127-8d213cf55f59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "60      1\n",
              "61      1\n",
              "62      1\n",
              "63      1\n",
              "64      2\n",
              "       ..\n",
              "1435    8\n",
              "1436    8\n",
              "1437    8\n",
              "1438    8\n",
              "1439    8\n",
              "Name: 0.2, Length: 720, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#y=y-1\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "_MiCDqlgXnOK",
        "outputId": "f567aa2f-d0ca-435b-887a-6eae86402565"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>-626.065857</td>\n",
              "      <td>67.129211</td>\n",
              "      <td>-14.506104</td>\n",
              "      <td>13.734784</td>\n",
              "      <td>-8.915299</td>\n",
              "      <td>-0.597560</td>\n",
              "      <td>-9.627712</td>\n",
              "      <td>-6.697053</td>\n",
              "      <td>-7.643127</td>\n",
              "      <td>1.682984</td>\n",
              "      <td>...</td>\n",
              "      <td>15.032267</td>\n",
              "      <td>17.122944</td>\n",
              "      <td>17.137267</td>\n",
              "      <td>32.684056</td>\n",
              "      <td>-0.035477</td>\n",
              "      <td>0.046495</td>\n",
              "      <td>0.018824</td>\n",
              "      <td>-0.060412</td>\n",
              "      <td>0.011128</td>\n",
              "      <td>0.000489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>-622.978882</td>\n",
              "      <td>61.610241</td>\n",
              "      <td>-16.155281</td>\n",
              "      <td>17.274385</td>\n",
              "      <td>-10.515155</td>\n",
              "      <td>-0.012929</td>\n",
              "      <td>-9.384588</td>\n",
              "      <td>-5.405496</td>\n",
              "      <td>-6.061921</td>\n",
              "      <td>0.427206</td>\n",
              "      <td>...</td>\n",
              "      <td>15.800671</td>\n",
              "      <td>16.939402</td>\n",
              "      <td>16.786359</td>\n",
              "      <td>32.054128</td>\n",
              "      <td>-0.038423</td>\n",
              "      <td>0.033620</td>\n",
              "      <td>0.028817</td>\n",
              "      <td>-0.024666</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>-0.008258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>-594.977844</td>\n",
              "      <td>62.693829</td>\n",
              "      <td>-16.257780</td>\n",
              "      <td>9.051161</td>\n",
              "      <td>-9.175509</td>\n",
              "      <td>-0.249130</td>\n",
              "      <td>-9.898236</td>\n",
              "      <td>-7.671722</td>\n",
              "      <td>-8.782819</td>\n",
              "      <td>0.426915</td>\n",
              "      <td>...</td>\n",
              "      <td>15.484927</td>\n",
              "      <td>17.181703</td>\n",
              "      <td>18.043089</td>\n",
              "      <td>31.869979</td>\n",
              "      <td>-0.053699</td>\n",
              "      <td>0.053169</td>\n",
              "      <td>0.032318</td>\n",
              "      <td>-0.044163</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>-0.013748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>-612.936279</td>\n",
              "      <td>58.990162</td>\n",
              "      <td>-15.687172</td>\n",
              "      <td>10.080914</td>\n",
              "      <td>-11.711167</td>\n",
              "      <td>-1.830589</td>\n",
              "      <td>-11.331991</td>\n",
              "      <td>-8.769240</td>\n",
              "      <td>-10.589375</td>\n",
              "      <td>-0.807020</td>\n",
              "      <td>...</td>\n",
              "      <td>15.257555</td>\n",
              "      <td>16.719364</td>\n",
              "      <td>17.726324</td>\n",
              "      <td>31.140206</td>\n",
              "      <td>-0.045528</td>\n",
              "      <td>0.042565</td>\n",
              "      <td>-0.070671</td>\n",
              "      <td>-0.055261</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>-0.008018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>-639.557617</td>\n",
              "      <td>64.624420</td>\n",
              "      <td>-8.859457</td>\n",
              "      <td>17.944416</td>\n",
              "      <td>-9.782133</td>\n",
              "      <td>2.161584</td>\n",
              "      <td>-7.936422</td>\n",
              "      <td>-4.958043</td>\n",
              "      <td>-6.853294</td>\n",
              "      <td>0.523445</td>\n",
              "      <td>...</td>\n",
              "      <td>16.251168</td>\n",
              "      <td>17.629721</td>\n",
              "      <td>16.558219</td>\n",
              "      <td>31.837218</td>\n",
              "      <td>-0.089607</td>\n",
              "      <td>0.068644</td>\n",
              "      <td>-0.019986</td>\n",
              "      <td>-0.011248</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>0.004188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>-558.443298</td>\n",
              "      <td>34.201637</td>\n",
              "      <td>-25.876736</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.845768</td>\n",
              "      <td>-13.475706</td>\n",
              "      <td>-11.609130</td>\n",
              "      <td>-4.602691</td>\n",
              "      <td>...</td>\n",
              "      <td>16.391113</td>\n",
              "      <td>18.151034</td>\n",
              "      <td>17.573820</td>\n",
              "      <td>31.661293</td>\n",
              "      <td>-0.020466</td>\n",
              "      <td>0.014107</td>\n",
              "      <td>0.020899</td>\n",
              "      <td>0.050697</td>\n",
              "      <td>-0.005623</td>\n",
              "      <td>0.022015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>-509.914642</td>\n",
              "      <td>49.378990</td>\n",
              "      <td>-22.979485</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-17.452888</td>\n",
              "      <td>-8.696088</td>\n",
              "      <td>-14.158811</td>\n",
              "      <td>0.367432</td>\n",
              "      <td>...</td>\n",
              "      <td>16.270073</td>\n",
              "      <td>17.091367</td>\n",
              "      <td>17.932740</td>\n",
              "      <td>31.846921</td>\n",
              "      <td>-0.040751</td>\n",
              "      <td>0.017479</td>\n",
              "      <td>0.014917</td>\n",
              "      <td>0.015533</td>\n",
              "      <td>0.016873</td>\n",
              "      <td>-0.000375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>-517.733276</td>\n",
              "      <td>40.459633</td>\n",
              "      <td>-27.217442</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-19.589163</td>\n",
              "      <td>-8.899709</td>\n",
              "      <td>-12.807209</td>\n",
              "      <td>3.745601</td>\n",
              "      <td>...</td>\n",
              "      <td>16.128660</td>\n",
              "      <td>16.947312</td>\n",
              "      <td>18.503842</td>\n",
              "      <td>31.628901</td>\n",
              "      <td>-0.032364</td>\n",
              "      <td>0.032572</td>\n",
              "      <td>-0.050994</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.007204</td>\n",
              "      <td>0.013219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>-463.998352</td>\n",
              "      <td>35.496925</td>\n",
              "      <td>-14.260783</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-18.052525</td>\n",
              "      <td>-4.351163</td>\n",
              "      <td>-7.299998</td>\n",
              "      <td>0.214021</td>\n",
              "      <td>...</td>\n",
              "      <td>16.307834</td>\n",
              "      <td>17.859030</td>\n",
              "      <td>17.360766</td>\n",
              "      <td>31.137002</td>\n",
              "      <td>-0.045889</td>\n",
              "      <td>0.027680</td>\n",
              "      <td>-0.042989</td>\n",
              "      <td>-0.060098</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>-0.009220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>-499.242126</td>\n",
              "      <td>39.540497</td>\n",
              "      <td>-8.361695</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-16.925844</td>\n",
              "      <td>-1.147182</td>\n",
              "      <td>-14.435615</td>\n",
              "      <td>2.066961</td>\n",
              "      <td>...</td>\n",
              "      <td>15.493485</td>\n",
              "      <td>16.808408</td>\n",
              "      <td>16.629113</td>\n",
              "      <td>31.947595</td>\n",
              "      <td>-0.068432</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>-0.022390</td>\n",
              "      <td>-0.051703</td>\n",
              "      <td>-0.010379</td>\n",
              "      <td>0.017864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0          1          2          3          4          5  \\\n",
              "60   -626.065857  67.129211 -14.506104  13.734784  -8.915299  -0.597560   \n",
              "61   -622.978882  61.610241 -16.155281  17.274385 -10.515155  -0.012929   \n",
              "62   -594.977844  62.693829 -16.257780   9.051161  -9.175509  -0.249130   \n",
              "63   -612.936279  58.990162 -15.687172  10.080914 -11.711167  -1.830589   \n",
              "64   -639.557617  64.624420  -8.859457  17.944416  -9.782133   2.161584   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "1435 -558.443298  34.201637 -25.876736   3.420890 -22.962826  -6.289969   \n",
              "1436 -509.914642  49.378990 -22.979485  -0.832579 -23.050257 -10.238819   \n",
              "1437 -517.733276  40.459633 -27.217442   2.902560 -22.611633 -14.189220   \n",
              "1438 -463.998352  35.496925 -14.260783   9.399699 -19.878208   0.799514   \n",
              "1439 -499.242126  39.540497  -8.361695   3.750752 -10.930555  -1.502927   \n",
              "\n",
              "              6          7          8         9  ...        183        184  \\\n",
              "60    -9.627712  -6.697053  -7.643127  1.682984  ...  15.032267  17.122944   \n",
              "61    -9.384588  -5.405496  -6.061921  0.427206  ...  15.800671  16.939402   \n",
              "62    -9.898236  -7.671722  -8.782819  0.426915  ...  15.484927  17.181703   \n",
              "63   -11.331991  -8.769240 -10.589375 -0.807020  ...  15.257555  16.719364   \n",
              "64    -7.936422  -4.958043  -6.853294  0.523445  ...  16.251168  17.629721   \n",
              "...         ...        ...        ...       ...  ...        ...        ...   \n",
              "1435 -22.845768 -13.475706 -11.609130 -4.602691  ...  16.391113  18.151034   \n",
              "1436 -17.452888  -8.696088 -14.158811  0.367432  ...  16.270073  17.091367   \n",
              "1437 -19.589163  -8.899709 -12.807209  3.745601  ...  16.128660  16.947312   \n",
              "1438 -18.052525  -4.351163  -7.299998  0.214021  ...  16.307834  17.859030   \n",
              "1439 -16.925844  -1.147182 -14.435615  2.066961  ...  15.493485  16.808408   \n",
              "\n",
              "            185        186       187       188       189       190       191  \\\n",
              "60    17.137267  32.684056 -0.035477  0.046495  0.018824 -0.060412  0.011128   \n",
              "61    16.786359  32.054128 -0.038423  0.033620  0.028817 -0.024666  0.011614   \n",
              "62    18.043089  31.869979 -0.053699  0.053169  0.032318 -0.044163  0.002315   \n",
              "63    17.726324  31.140206 -0.045528  0.042565 -0.070671 -0.055261  0.010003   \n",
              "64    16.558219  31.837218 -0.089607  0.068644 -0.019986 -0.011248  0.001546   \n",
              "...         ...        ...       ...       ...       ...       ...       ...   \n",
              "1435  17.573820  31.661293 -0.020466  0.014107  0.020899  0.050697 -0.005623   \n",
              "1436  17.932740  31.846921 -0.040751  0.017479  0.014917  0.015533  0.016873   \n",
              "1437  18.503842  31.628901 -0.032364  0.032572 -0.050994  0.009171  0.007204   \n",
              "1438  17.360766  31.137002 -0.045889  0.027680 -0.042989 -0.060098  0.005997   \n",
              "1439  16.629113  31.947595 -0.068432  0.061563 -0.022390 -0.051703 -0.010379   \n",
              "\n",
              "           192  \n",
              "60    0.000489  \n",
              "61   -0.008258  \n",
              "62   -0.013748  \n",
              "63   -0.008018  \n",
              "64    0.004188  \n",
              "...        ...  \n",
              "1435  0.022015  \n",
              "1436 -0.000375  \n",
              "1437  0.013219  \n",
              "1438 -0.009220  \n",
              "1439  0.017864  \n",
              "\n",
              "[720 rows x 193 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "D1gwLerZXnOK",
        "outputId": "23f8baf8-6b87-4d9a-f3d4-db44d669edf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((720, 193),\n",
              " 60      1\n",
              " 61      1\n",
              " 62      1\n",
              " 63      1\n",
              " 64      2\n",
              "        ..\n",
              " 1435    8\n",
              " 1436    8\n",
              " 1437    8\n",
              " 1438    8\n",
              " 1439    8\n",
              " Name: 0.2, Length: 720, dtype: int64)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "83DhgAnrXnOL"
      },
      "outputs": [],
      "source": [
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lb = LabelEncoder()\n",
        "y1 = to_categorical(lb.fit_transform(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "4HjNDbnDXnOL",
        "outputId": "279db19c-580a-436c-ac21-98bdcf3f4c53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "N01N_BlGXnOL",
        "outputId": "6db82999-1241-4ac4-f4fb-1ea2f053ad52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((720, 193), (720, 8))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Zv9uOrLYXnOL",
        "outputId": "ae10ab56-372f-4bfb-be01-49f081dc0842"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>183</th>\n",
              "      <th>184</th>\n",
              "      <th>185</th>\n",
              "      <th>186</th>\n",
              "      <th>187</th>\n",
              "      <th>188</th>\n",
              "      <th>189</th>\n",
              "      <th>190</th>\n",
              "      <th>191</th>\n",
              "      <th>192</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>-626.065857</td>\n",
              "      <td>67.129211</td>\n",
              "      <td>-14.506104</td>\n",
              "      <td>13.734784</td>\n",
              "      <td>-8.915299</td>\n",
              "      <td>-0.597560</td>\n",
              "      <td>-9.627712</td>\n",
              "      <td>-6.697053</td>\n",
              "      <td>-7.643127</td>\n",
              "      <td>1.682984</td>\n",
              "      <td>...</td>\n",
              "      <td>15.032267</td>\n",
              "      <td>17.122944</td>\n",
              "      <td>17.137267</td>\n",
              "      <td>32.684056</td>\n",
              "      <td>-0.035477</td>\n",
              "      <td>0.046495</td>\n",
              "      <td>0.018824</td>\n",
              "      <td>-0.060412</td>\n",
              "      <td>0.011128</td>\n",
              "      <td>0.000489</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>-622.978882</td>\n",
              "      <td>61.610241</td>\n",
              "      <td>-16.155281</td>\n",
              "      <td>17.274385</td>\n",
              "      <td>-10.515155</td>\n",
              "      <td>-0.012929</td>\n",
              "      <td>-9.384588</td>\n",
              "      <td>-5.405496</td>\n",
              "      <td>-6.061921</td>\n",
              "      <td>0.427206</td>\n",
              "      <td>...</td>\n",
              "      <td>15.800671</td>\n",
              "      <td>16.939402</td>\n",
              "      <td>16.786359</td>\n",
              "      <td>32.054128</td>\n",
              "      <td>-0.038423</td>\n",
              "      <td>0.033620</td>\n",
              "      <td>0.028817</td>\n",
              "      <td>-0.024666</td>\n",
              "      <td>0.011614</td>\n",
              "      <td>-0.008258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>-594.977844</td>\n",
              "      <td>62.693829</td>\n",
              "      <td>-16.257780</td>\n",
              "      <td>9.051161</td>\n",
              "      <td>-9.175509</td>\n",
              "      <td>-0.249130</td>\n",
              "      <td>-9.898236</td>\n",
              "      <td>-7.671722</td>\n",
              "      <td>-8.782819</td>\n",
              "      <td>0.426915</td>\n",
              "      <td>...</td>\n",
              "      <td>15.484927</td>\n",
              "      <td>17.181703</td>\n",
              "      <td>18.043089</td>\n",
              "      <td>31.869979</td>\n",
              "      <td>-0.053699</td>\n",
              "      <td>0.053169</td>\n",
              "      <td>0.032318</td>\n",
              "      <td>-0.044163</td>\n",
              "      <td>0.002315</td>\n",
              "      <td>-0.013748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>-612.936279</td>\n",
              "      <td>58.990162</td>\n",
              "      <td>-15.687172</td>\n",
              "      <td>10.080914</td>\n",
              "      <td>-11.711167</td>\n",
              "      <td>-1.830589</td>\n",
              "      <td>-11.331991</td>\n",
              "      <td>-8.769240</td>\n",
              "      <td>-10.589375</td>\n",
              "      <td>-0.807020</td>\n",
              "      <td>...</td>\n",
              "      <td>15.257555</td>\n",
              "      <td>16.719364</td>\n",
              "      <td>17.726324</td>\n",
              "      <td>31.140206</td>\n",
              "      <td>-0.045528</td>\n",
              "      <td>0.042565</td>\n",
              "      <td>-0.070671</td>\n",
              "      <td>-0.055261</td>\n",
              "      <td>0.010003</td>\n",
              "      <td>-0.008018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>-639.557617</td>\n",
              "      <td>64.624420</td>\n",
              "      <td>-8.859457</td>\n",
              "      <td>17.944416</td>\n",
              "      <td>-9.782133</td>\n",
              "      <td>2.161584</td>\n",
              "      <td>-7.936422</td>\n",
              "      <td>-4.958043</td>\n",
              "      <td>-6.853294</td>\n",
              "      <td>0.523445</td>\n",
              "      <td>...</td>\n",
              "      <td>16.251168</td>\n",
              "      <td>17.629721</td>\n",
              "      <td>16.558219</td>\n",
              "      <td>31.837218</td>\n",
              "      <td>-0.089607</td>\n",
              "      <td>0.068644</td>\n",
              "      <td>-0.019986</td>\n",
              "      <td>-0.011248</td>\n",
              "      <td>0.001546</td>\n",
              "      <td>0.004188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>-558.443298</td>\n",
              "      <td>34.201637</td>\n",
              "      <td>-25.876736</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.845768</td>\n",
              "      <td>-13.475706</td>\n",
              "      <td>-11.609130</td>\n",
              "      <td>-4.602691</td>\n",
              "      <td>...</td>\n",
              "      <td>16.391113</td>\n",
              "      <td>18.151034</td>\n",
              "      <td>17.573820</td>\n",
              "      <td>31.661293</td>\n",
              "      <td>-0.020466</td>\n",
              "      <td>0.014107</td>\n",
              "      <td>0.020899</td>\n",
              "      <td>0.050697</td>\n",
              "      <td>-0.005623</td>\n",
              "      <td>0.022015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>-509.914642</td>\n",
              "      <td>49.378990</td>\n",
              "      <td>-22.979485</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-17.452888</td>\n",
              "      <td>-8.696088</td>\n",
              "      <td>-14.158811</td>\n",
              "      <td>0.367432</td>\n",
              "      <td>...</td>\n",
              "      <td>16.270073</td>\n",
              "      <td>17.091367</td>\n",
              "      <td>17.932740</td>\n",
              "      <td>31.846921</td>\n",
              "      <td>-0.040751</td>\n",
              "      <td>0.017479</td>\n",
              "      <td>0.014917</td>\n",
              "      <td>0.015533</td>\n",
              "      <td>0.016873</td>\n",
              "      <td>-0.000375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>-517.733276</td>\n",
              "      <td>40.459633</td>\n",
              "      <td>-27.217442</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-19.589163</td>\n",
              "      <td>-8.899709</td>\n",
              "      <td>-12.807209</td>\n",
              "      <td>3.745601</td>\n",
              "      <td>...</td>\n",
              "      <td>16.128660</td>\n",
              "      <td>16.947312</td>\n",
              "      <td>18.503842</td>\n",
              "      <td>31.628901</td>\n",
              "      <td>-0.032364</td>\n",
              "      <td>0.032572</td>\n",
              "      <td>-0.050994</td>\n",
              "      <td>0.009171</td>\n",
              "      <td>0.007204</td>\n",
              "      <td>0.013219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>-463.998352</td>\n",
              "      <td>35.496925</td>\n",
              "      <td>-14.260783</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-18.052525</td>\n",
              "      <td>-4.351163</td>\n",
              "      <td>-7.299998</td>\n",
              "      <td>0.214021</td>\n",
              "      <td>...</td>\n",
              "      <td>16.307834</td>\n",
              "      <td>17.859030</td>\n",
              "      <td>17.360766</td>\n",
              "      <td>31.137002</td>\n",
              "      <td>-0.045889</td>\n",
              "      <td>0.027680</td>\n",
              "      <td>-0.042989</td>\n",
              "      <td>-0.060098</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>-0.009220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>-499.242126</td>\n",
              "      <td>39.540497</td>\n",
              "      <td>-8.361695</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-16.925844</td>\n",
              "      <td>-1.147182</td>\n",
              "      <td>-14.435615</td>\n",
              "      <td>2.066961</td>\n",
              "      <td>...</td>\n",
              "      <td>15.493485</td>\n",
              "      <td>16.808408</td>\n",
              "      <td>16.629113</td>\n",
              "      <td>31.947595</td>\n",
              "      <td>-0.068432</td>\n",
              "      <td>0.061563</td>\n",
              "      <td>-0.022390</td>\n",
              "      <td>-0.051703</td>\n",
              "      <td>-0.010379</td>\n",
              "      <td>0.017864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 193 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0          1          2          3          4          5  \\\n",
              "60   -626.065857  67.129211 -14.506104  13.734784  -8.915299  -0.597560   \n",
              "61   -622.978882  61.610241 -16.155281  17.274385 -10.515155  -0.012929   \n",
              "62   -594.977844  62.693829 -16.257780   9.051161  -9.175509  -0.249130   \n",
              "63   -612.936279  58.990162 -15.687172  10.080914 -11.711167  -1.830589   \n",
              "64   -639.557617  64.624420  -8.859457  17.944416  -9.782133   2.161584   \n",
              "...          ...        ...        ...        ...        ...        ...   \n",
              "1435 -558.443298  34.201637 -25.876736   3.420890 -22.962826  -6.289969   \n",
              "1436 -509.914642  49.378990 -22.979485  -0.832579 -23.050257 -10.238819   \n",
              "1437 -517.733276  40.459633 -27.217442   2.902560 -22.611633 -14.189220   \n",
              "1438 -463.998352  35.496925 -14.260783   9.399699 -19.878208   0.799514   \n",
              "1439 -499.242126  39.540497  -8.361695   3.750752 -10.930555  -1.502927   \n",
              "\n",
              "              6          7          8         9  ...        183        184  \\\n",
              "60    -9.627712  -6.697053  -7.643127  1.682984  ...  15.032267  17.122944   \n",
              "61    -9.384588  -5.405496  -6.061921  0.427206  ...  15.800671  16.939402   \n",
              "62    -9.898236  -7.671722  -8.782819  0.426915  ...  15.484927  17.181703   \n",
              "63   -11.331991  -8.769240 -10.589375 -0.807020  ...  15.257555  16.719364   \n",
              "64    -7.936422  -4.958043  -6.853294  0.523445  ...  16.251168  17.629721   \n",
              "...         ...        ...        ...       ...  ...        ...        ...   \n",
              "1435 -22.845768 -13.475706 -11.609130 -4.602691  ...  16.391113  18.151034   \n",
              "1436 -17.452888  -8.696088 -14.158811  0.367432  ...  16.270073  17.091367   \n",
              "1437 -19.589163  -8.899709 -12.807209  3.745601  ...  16.128660  16.947312   \n",
              "1438 -18.052525  -4.351163  -7.299998  0.214021  ...  16.307834  17.859030   \n",
              "1439 -16.925844  -1.147182 -14.435615  2.066961  ...  15.493485  16.808408   \n",
              "\n",
              "            185        186       187       188       189       190       191  \\\n",
              "60    17.137267  32.684056 -0.035477  0.046495  0.018824 -0.060412  0.011128   \n",
              "61    16.786359  32.054128 -0.038423  0.033620  0.028817 -0.024666  0.011614   \n",
              "62    18.043089  31.869979 -0.053699  0.053169  0.032318 -0.044163  0.002315   \n",
              "63    17.726324  31.140206 -0.045528  0.042565 -0.070671 -0.055261  0.010003   \n",
              "64    16.558219  31.837218 -0.089607  0.068644 -0.019986 -0.011248  0.001546   \n",
              "...         ...        ...       ...       ...       ...       ...       ...   \n",
              "1435  17.573820  31.661293 -0.020466  0.014107  0.020899  0.050697 -0.005623   \n",
              "1436  17.932740  31.846921 -0.040751  0.017479  0.014917  0.015533  0.016873   \n",
              "1437  18.503842  31.628901 -0.032364  0.032572 -0.050994  0.009171  0.007204   \n",
              "1438  17.360766  31.137002 -0.045889  0.027680 -0.042989 -0.060098  0.005997   \n",
              "1439  16.629113  31.947595 -0.068432  0.061563 -0.022390 -0.051703 -0.010379   \n",
              "\n",
              "           192  \n",
              "60    0.000489  \n",
              "61   -0.008258  \n",
              "62   -0.013748  \n",
              "63   -0.008018  \n",
              "64    0.004188  \n",
              "...        ...  \n",
              "1435  0.022015  \n",
              "1436 -0.000375  \n",
              "1437  0.013219  \n",
              "1438 -0.009220  \n",
              "1439  0.017864  \n",
              "\n",
              "[720 rows x 193 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "m-_a8mmoXnOL"
      },
      "outputs": [],
      "source": [
        "#########fisher score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "0eKjOZezXnOL"
      },
      "outputs": [],
      "source": [
        "X2=X.copy().to_numpy()\n",
        "y2=y.copy().to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "1Lw2XnqJXnOL"
      },
      "outputs": [],
      "source": [
        "from skfeature.function.similarity_based import fisher_score\n",
        "fisherindex = fisher_score.fisher_score(X2, y2, mode='index')\n",
        "score  = fisher_score.fisher_score(X2, y2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "34mfCW_0XnOM",
        "outputId": "2a59373b-8211-43be-fd98-7a1d03879f82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  0,   2,   1,  20, 185,   5,   4,   3, 182, 183, 155, 154, 157,\n",
              "       184,  35,  22, 153,  21,  17, 141, 151,  34, 142, 150, 156, 140,\n",
              "        19,  45, 132,  44,  23, 143, 152, 133, 186, 144, 131, 139, 179,\n",
              "       129, 158, 138, 130, 136,  33,  18, 166, 177,  36,  55, 115, 149,\n",
              "       122, 123, 105,  87, 178, 176,   7,  74, 174,  75, 104,  43, 137,\n",
              "       173,  41, 145, 171,  24, 175, 134,  93,  76,  56, 165,  12, 146,\n",
              "       147,  77,  32,  37,  80,  42, 180, 116, 109, 170, 159,  40,  90,\n",
              "        95,  94, 106, 172,  99, 113, 164,  57, 148, 110, 103, 117,   6,\n",
              "        10,  51,  79,  92, 181,  25, 102, 163, 128, 161, 135, 114,  88,\n",
              "       111,  91, 108,  58,  89, 124,  31,  16,  38, 167, 160,  62,  39,\n",
              "       162,  46,  14,  15,  85, 112, 169,   9, 101,  86,  83, 100,  48,\n",
              "        13,  63,  65,  78,  59,  60,  96,  54,  26, 168, 118, 119,  81,\n",
              "       120, 125,  61,  84,  73,  97,  47,  98,  11,   8, 107,  66,  50,\n",
              "        49,  64,  70,  69,  82, 126, 121, 189,  68, 192,  67, 127,  53,\n",
              "        30, 188, 187,  71,  27,  29,  72,  52, 190, 191,  28], dtype=int64)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fisherindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "66AGX1LWXnOM",
        "outputId": "a8d556c2-f7f9-49c8-f397-13a886b4a338"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([192, 190, 191, 172,   7, 187, 188, 189,  10,   9,  37,  38,  35,\n",
              "         8, 157, 170,  39, 171, 175,  51,  41, 158,  50,  42,  36,  52,\n",
              "       173, 147,  60, 148, 169,  49,  40,  59,   6,  48,  61,  53,  13,\n",
              "        63,  34,  54,  62,  56, 159, 174,  26,  15, 156, 137,  77,  43,\n",
              "        70,  69,  87, 105,  14,  16, 185, 118,  18, 117,  88, 149,  55,\n",
              "        19, 151,  47,  21, 168,  17,  58,  99, 116, 136,  27, 180,  46,\n",
              "        45, 115, 160, 155, 112, 150,  12,  76,  83,  22,  33, 152, 102,\n",
              "        97,  98,  86,  20,  93,  79,  28, 135,  44,  82,  89,  75, 186,\n",
              "       182, 141, 113, 100,  11, 167,  90,  29,  64,  31,  57,  78, 104,\n",
              "        81, 101,  84, 134, 103,  68, 161, 176, 154,  25,  32, 130, 153,\n",
              "        30, 146, 178, 177, 107,  80,  23, 183,  91, 106, 109,  92, 144,\n",
              "       179, 129, 127, 114, 133, 132,  96, 138, 166,  24,  74,  73, 111,\n",
              "        72,  67, 131, 108, 119,  95, 145,  94, 181, 184,  85, 126, 142,\n",
              "       143, 128, 122, 123, 110,  66,  71,   3, 124,   0, 125,  65, 139,\n",
              "       162,   4,   5, 121, 165, 163, 120, 140,   2,   1, 164])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "oZDhoZEMXnOM"
      },
      "outputs": [],
      "source": [
        "num_fea=125\n",
        "a=[]\n",
        "for i in range(193):\n",
        "    if(fisherindex[i]<num_fea): a.append(fisherindex[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "WMU4aYz5XnOM",
        "outputId": "6e839274-f900-44e4-fd3a-0fbed6239c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 2, 1, 20, 5, 4, 3, 35, 22, 21, 17, 34, 19, 45, 44, 23, 33, 18, 36, 55, 115, 122, 123, 105, 87, 7, 74, 75, 104, 43, 41, 24, 93, 76, 56, 12, 77, 32, 37, 80, 42, 116, 109, 40, 90, 95, 94, 106, 99, 113, 57, 110, 103, 117, 6, 10, 51, 79, 92, 25, 102, 114, 88, 111, 91, 108, 58, 89, 124, 31, 16, 38, 62, 39, 46, 14, 15, 85, 112, 9, 101, 86, 83, 100, 48, 13, 63, 65, 78, 59, 60, 96, 54, 26, 118, 119, 81, 120, 61, 84, 73, 97, 47, 98, 11, 8, 107, 66, 50, 49, 64, 70, 69, 82, 121, 68, 67, 53, 30, 71, 27, 29, 72, 52, 28] 125\n"
          ]
        }
      ],
      "source": [
        "print(a, len(a))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "AM0BSZbHXnOM"
      },
      "outputs": [],
      "source": [
        "selected_features = X2[:,a]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "rV9ukYM7XnOM",
        "outputId": "eb4ea37d-2367-4d0d-dede-2a6cbc78f429"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-6.26065857e+02, -1.45061035e+01,  6.71292114e+01, ...,\n",
              "          5.20714279e-03,  1.10181090e-05,  2.49339175e+00],\n",
              "        [-6.22978882e+02, -1.61552811e+01,  6.16102409e+01, ...,\n",
              "          6.00988371e-03,  1.10060537e-05,  3.10458565e+00],\n",
              "        [-5.94977844e+02, -1.62577801e+01,  6.26938286e+01, ...,\n",
              "          1.35517582e-01,  1.83469856e-05,  2.93323326e+00],\n",
              "        ...,\n",
              "        [-5.17733276e+02, -2.72174416e+01,  4.04596329e+01, ...,\n",
              "          4.28693444e-01,  5.39949360e-05,  6.13196194e-01],\n",
              "        [-4.63998352e+02, -1.42607832e+01,  3.54969254e+01, ...,\n",
              "          9.49792340e-02,  4.08025272e-03, -8.74016881e-01],\n",
              "        [-4.99242126e+02, -8.36169529e+00,  3.95404968e+01, ...,\n",
              "          2.80622661e-01,  1.66671127e-02,  6.73815668e-01]]),\n",
              " (720, 125))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "selected_features, selected_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Qcrlmeq9XnOM",
        "outputId": "6454a357-bc3b-48af-95e5-4cd3cdc8785f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "      <th>119</th>\n",
              "      <th>120</th>\n",
              "      <th>121</th>\n",
              "      <th>122</th>\n",
              "      <th>123</th>\n",
              "      <th>124</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-626.065857</td>\n",
              "      <td>-14.506104</td>\n",
              "      <td>67.129211</td>\n",
              "      <td>-0.492106</td>\n",
              "      <td>-0.597560</td>\n",
              "      <td>-8.915299</td>\n",
              "      <td>13.734784</td>\n",
              "      <td>2.562386</td>\n",
              "      <td>-0.584655</td>\n",
              "      <td>-1.166412</td>\n",
              "      <td>...</td>\n",
              "      <td>0.085684</td>\n",
              "      <td>0.075401</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.957261</td>\n",
              "      <td>0.011911</td>\n",
              "      <td>-1.326098</td>\n",
              "      <td>0.665574</td>\n",
              "      <td>0.005207</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>2.493392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-622.978882</td>\n",
              "      <td>-16.155281</td>\n",
              "      <td>61.610241</td>\n",
              "      <td>-0.757748</td>\n",
              "      <td>-0.012929</td>\n",
              "      <td>-10.515155</td>\n",
              "      <td>17.274385</td>\n",
              "      <td>3.438142</td>\n",
              "      <td>-1.823772</td>\n",
              "      <td>-2.015452</td>\n",
              "      <td>...</td>\n",
              "      <td>0.074816</td>\n",
              "      <td>0.027939</td>\n",
              "      <td>0.000025</td>\n",
              "      <td>1.344043</td>\n",
              "      <td>0.014507</td>\n",
              "      <td>-1.916556</td>\n",
              "      <td>1.728060</td>\n",
              "      <td>0.006010</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>3.104586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-594.977844</td>\n",
              "      <td>-16.257780</td>\n",
              "      <td>62.693829</td>\n",
              "      <td>-0.405246</td>\n",
              "      <td>-0.249130</td>\n",
              "      <td>-9.175509</td>\n",
              "      <td>9.051161</td>\n",
              "      <td>4.458579</td>\n",
              "      <td>-0.620401</td>\n",
              "      <td>-0.516156</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075948</td>\n",
              "      <td>0.028289</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.333440</td>\n",
              "      <td>0.127847</td>\n",
              "      <td>3.007311</td>\n",
              "      <td>2.887468</td>\n",
              "      <td>0.135518</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>2.933233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-612.936279</td>\n",
              "      <td>-15.687172</td>\n",
              "      <td>58.990162</td>\n",
              "      <td>-0.750733</td>\n",
              "      <td>-1.830589</td>\n",
              "      <td>-11.711167</td>\n",
              "      <td>10.080914</td>\n",
              "      <td>5.752499</td>\n",
              "      <td>-2.187827</td>\n",
              "      <td>-2.110827</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048669</td>\n",
              "      <td>0.043064</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>2.611422</td>\n",
              "      <td>0.118308</td>\n",
              "      <td>2.972829</td>\n",
              "      <td>4.853305</td>\n",
              "      <td>0.085326</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>4.017501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-639.557617</td>\n",
              "      <td>-8.859457</td>\n",
              "      <td>64.624420</td>\n",
              "      <td>-2.314848</td>\n",
              "      <td>2.161584</td>\n",
              "      <td>-9.782133</td>\n",
              "      <td>17.944416</td>\n",
              "      <td>2.831547</td>\n",
              "      <td>-1.273513</td>\n",
              "      <td>-2.530665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011124</td>\n",
              "      <td>0.003692</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>4.143136</td>\n",
              "      <td>0.022862</td>\n",
              "      <td>5.464410</td>\n",
              "      <td>5.590356</td>\n",
              "      <td>0.032539</td>\n",
              "      <td>0.000027</td>\n",
              "      <td>8.637901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>-558.443298</td>\n",
              "      <td>-25.876736</td>\n",
              "      <td>34.201637</td>\n",
              "      <td>0.744685</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-2.260234</td>\n",
              "      <td>-0.272697</td>\n",
              "      <td>0.603423</td>\n",
              "      <td>...</td>\n",
              "      <td>0.075476</td>\n",
              "      <td>0.081033</td>\n",
              "      <td>0.000012</td>\n",
              "      <td>-1.084799</td>\n",
              "      <td>0.151665</td>\n",
              "      <td>5.440038</td>\n",
              "      <td>-0.247932</td>\n",
              "      <td>0.148500</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>2.152255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>-509.914642</td>\n",
              "      <td>-22.979485</td>\n",
              "      <td>49.378990</td>\n",
              "      <td>-1.837317</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>0.838848</td>\n",
              "      <td>2.687783</td>\n",
              "      <td>1.452663</td>\n",
              "      <td>...</td>\n",
              "      <td>0.196916</td>\n",
              "      <td>0.130984</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>-1.447214</td>\n",
              "      <td>0.108095</td>\n",
              "      <td>4.673117</td>\n",
              "      <td>-0.465370</td>\n",
              "      <td>0.364397</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>1.931601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>-517.733276</td>\n",
              "      <td>-27.217442</td>\n",
              "      <td>40.459633</td>\n",
              "      <td>-0.603973</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>0.558064</td>\n",
              "      <td>1.165252</td>\n",
              "      <td>3.088328</td>\n",
              "      <td>...</td>\n",
              "      <td>0.370679</td>\n",
              "      <td>0.183584</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>1.011409</td>\n",
              "      <td>0.319389</td>\n",
              "      <td>4.127891</td>\n",
              "      <td>0.341090</td>\n",
              "      <td>0.428693</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.613196</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>-463.998352</td>\n",
              "      <td>-14.260783</td>\n",
              "      <td>35.496925</td>\n",
              "      <td>6.432075</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>0.613665</td>\n",
              "      <td>5.269444</td>\n",
              "      <td>4.869069</td>\n",
              "      <td>...</td>\n",
              "      <td>0.781644</td>\n",
              "      <td>1.285365</td>\n",
              "      <td>0.001498</td>\n",
              "      <td>-0.865850</td>\n",
              "      <td>0.193007</td>\n",
              "      <td>2.376178</td>\n",
              "      <td>0.533465</td>\n",
              "      <td>0.094979</td>\n",
              "      <td>0.004080</td>\n",
              "      <td>-0.874017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>-499.242126</td>\n",
              "      <td>-8.361695</td>\n",
              "      <td>39.540497</td>\n",
              "      <td>2.568863</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>0.821056</td>\n",
              "      <td>2.790621</td>\n",
              "      <td>2.945298</td>\n",
              "      <td>...</td>\n",
              "      <td>1.457756</td>\n",
              "      <td>1.179008</td>\n",
              "      <td>0.004705</td>\n",
              "      <td>0.779745</td>\n",
              "      <td>0.842265</td>\n",
              "      <td>3.116280</td>\n",
              "      <td>2.474865</td>\n",
              "      <td>0.280623</td>\n",
              "      <td>0.016667</td>\n",
              "      <td>0.673816</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 125 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            0          1          2         3          4          5    \\\n",
              "0   -626.065857 -14.506104  67.129211 -0.492106  -0.597560  -8.915299   \n",
              "1   -622.978882 -16.155281  61.610241 -0.757748  -0.012929 -10.515155   \n",
              "2   -594.977844 -16.257780  62.693829 -0.405246  -0.249130  -9.175509   \n",
              "3   -612.936279 -15.687172  58.990162 -0.750733  -1.830589 -11.711167   \n",
              "4   -639.557617  -8.859457  64.624420 -2.314848   2.161584  -9.782133   \n",
              "..          ...        ...        ...       ...        ...        ...   \n",
              "715 -558.443298 -25.876736  34.201637  0.744685  -6.289969 -22.962826   \n",
              "716 -509.914642 -22.979485  49.378990 -1.837317 -10.238819 -23.050257   \n",
              "717 -517.733276 -27.217442  40.459633 -0.603973 -14.189220 -22.611633   \n",
              "718 -463.998352 -14.260783  35.496925  6.432075   0.799514 -19.878208   \n",
              "719 -499.242126  -8.361695  39.540497  2.568863  -1.502927 -10.930555   \n",
              "\n",
              "           6         7         8         9    ...       115       116  \\\n",
              "0    13.734784  2.562386 -0.584655 -1.166412  ...  0.085684  0.075401   \n",
              "1    17.274385  3.438142 -1.823772 -2.015452  ...  0.074816  0.027939   \n",
              "2     9.051161  4.458579 -0.620401 -0.516156  ...  0.075948  0.028289   \n",
              "3    10.080914  5.752499 -2.187827 -2.110827  ...  0.048669  0.043064   \n",
              "4    17.944416  2.831547 -1.273513 -2.530665  ...  0.011124  0.003692   \n",
              "..         ...       ...       ...       ...  ...       ...       ...   \n",
              "715   3.420890 -2.260234 -0.272697  0.603423  ...  0.075476  0.081033   \n",
              "716  -0.832579  0.838848  2.687783  1.452663  ...  0.196916  0.130984   \n",
              "717   2.902560  0.558064  1.165252  3.088328  ...  0.370679  0.183584   \n",
              "718   9.399699  0.613665  5.269444  4.869069  ...  0.781644  1.285365   \n",
              "719   3.750752  0.821056  2.790621  2.945298  ...  1.457756  1.179008   \n",
              "\n",
              "          117       118       119       120       121       122       123  \\\n",
              "0    0.000051  0.957261  0.011911 -1.326098  0.665574  0.005207  0.000011   \n",
              "1    0.000025  1.344043  0.014507 -1.916556  1.728060  0.006010  0.000011   \n",
              "2    0.000060  0.333440  0.127847  3.007311  2.887468  0.135518  0.000018   \n",
              "3    0.000023  2.611422  0.118308  2.972829  4.853305  0.085326  0.000005   \n",
              "4    0.000038  4.143136  0.022862  5.464410  5.590356  0.032539  0.000027   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "715  0.000012 -1.084799  0.151665  5.440038 -0.247932  0.148500  0.000001   \n",
              "716  0.000103 -1.447214  0.108095  4.673117 -0.465370  0.364397  0.000067   \n",
              "717  0.000023  1.011409  0.319389  4.127891  0.341090  0.428693  0.000054   \n",
              "718  0.001498 -0.865850  0.193007  2.376178  0.533465  0.094979  0.004080   \n",
              "719  0.004705  0.779745  0.842265  3.116280  2.474865  0.280623  0.016667   \n",
              "\n",
              "          124  \n",
              "0    2.493392  \n",
              "1    3.104586  \n",
              "2    2.933233  \n",
              "3    4.017501  \n",
              "4    8.637901  \n",
              "..        ...  \n",
              "715  2.152255  \n",
              "716  1.931601  \n",
              "717  0.613196  \n",
              "718 -0.874017  \n",
              "719  0.673816  \n",
              "\n",
              "[720 rows x 125 columns]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X3=pd.DataFrame(selected_features)\n",
        "X3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "Ce22rHCXXnOM",
        "outputId": "cb88abcd-7c51-484d-aae0-0f747df9e110"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>-14.506104</td>\n",
              "      <td>13.734784</td>\n",
              "      <td>-8.915299</td>\n",
              "      <td>-0.597560</td>\n",
              "      <td>-9.627712</td>\n",
              "      <td>-6.697053</td>\n",
              "      <td>-7.643127</td>\n",
              "      <td>1.682984</td>\n",
              "      <td>-7.912409</td>\n",
              "      <td>-0.210760</td>\n",
              "      <td>-7.740003</td>\n",
              "      <td>1.756948</td>\n",
              "      <td>-9.324497</td>\n",
              "      <td>-1.198008</td>\n",
              "      <td>-4.133364</td>\n",
              "      <td>-1.631853</td>\n",
              "      <td>-2.066447</td>\n",
              "      <td>-0.454988</td>\n",
              "      <td>-0.492106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>-16.155281</td>\n",
              "      <td>17.274385</td>\n",
              "      <td>-10.515155</td>\n",
              "      <td>-0.012929</td>\n",
              "      <td>-9.384588</td>\n",
              "      <td>-5.405496</td>\n",
              "      <td>-6.061921</td>\n",
              "      <td>0.427206</td>\n",
              "      <td>-6.152109</td>\n",
              "      <td>-0.615899</td>\n",
              "      <td>-8.214749</td>\n",
              "      <td>1.275640</td>\n",
              "      <td>-8.237226</td>\n",
              "      <td>-2.645824</td>\n",
              "      <td>-3.443796</td>\n",
              "      <td>-0.612220</td>\n",
              "      <td>-2.490293</td>\n",
              "      <td>-0.452201</td>\n",
              "      <td>-0.757748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>-16.257780</td>\n",
              "      <td>9.051161</td>\n",
              "      <td>-9.175509</td>\n",
              "      <td>-0.249130</td>\n",
              "      <td>-9.898236</td>\n",
              "      <td>-7.671722</td>\n",
              "      <td>-8.782819</td>\n",
              "      <td>0.426915</td>\n",
              "      <td>-8.104342</td>\n",
              "      <td>-1.270707</td>\n",
              "      <td>-9.362936</td>\n",
              "      <td>3.294116</td>\n",
              "      <td>-8.703416</td>\n",
              "      <td>-2.625140</td>\n",
              "      <td>-4.680979</td>\n",
              "      <td>-3.360180</td>\n",
              "      <td>-1.953824</td>\n",
              "      <td>0.267930</td>\n",
              "      <td>-0.405246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>-15.687172</td>\n",
              "      <td>10.080914</td>\n",
              "      <td>-11.711167</td>\n",
              "      <td>-1.830589</td>\n",
              "      <td>-11.331991</td>\n",
              "      <td>-8.769240</td>\n",
              "      <td>-10.589375</td>\n",
              "      <td>-0.807020</td>\n",
              "      <td>-9.551315</td>\n",
              "      <td>-1.466953</td>\n",
              "      <td>-12.188832</td>\n",
              "      <td>1.340084</td>\n",
              "      <td>-10.352579</td>\n",
              "      <td>-2.398706</td>\n",
              "      <td>-4.686605</td>\n",
              "      <td>-4.565247</td>\n",
              "      <td>-2.227786</td>\n",
              "      <td>-0.699804</td>\n",
              "      <td>-0.750733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>-8.859457</td>\n",
              "      <td>17.944416</td>\n",
              "      <td>-9.782133</td>\n",
              "      <td>2.161584</td>\n",
              "      <td>-7.936422</td>\n",
              "      <td>-4.958043</td>\n",
              "      <td>-6.853294</td>\n",
              "      <td>0.523445</td>\n",
              "      <td>-6.652872</td>\n",
              "      <td>-2.524537</td>\n",
              "      <td>-7.584999</td>\n",
              "      <td>3.084172</td>\n",
              "      <td>-8.050755</td>\n",
              "      <td>-1.479591</td>\n",
              "      <td>-4.934464</td>\n",
              "      <td>-1.571014</td>\n",
              "      <td>-5.846342</td>\n",
              "      <td>-1.533878</td>\n",
              "      <td>-2.314848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1435</th>\n",
              "      <td>-25.876736</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.845768</td>\n",
              "      <td>-13.475706</td>\n",
              "      <td>-11.609130</td>\n",
              "      <td>-4.602691</td>\n",
              "      <td>-13.470782</td>\n",
              "      <td>-0.407410</td>\n",
              "      <td>-9.948418</td>\n",
              "      <td>5.518756</td>\n",
              "      <td>2.247648</td>\n",
              "      <td>1.531702</td>\n",
              "      <td>-2.982210</td>\n",
              "      <td>0.129457</td>\n",
              "      <td>-4.504814</td>\n",
              "      <td>1.020297</td>\n",
              "      <td>0.744685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1436</th>\n",
              "      <td>-22.979485</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-17.452888</td>\n",
              "      <td>-8.696088</td>\n",
              "      <td>-14.158811</td>\n",
              "      <td>0.367432</td>\n",
              "      <td>-14.131364</td>\n",
              "      <td>8.980473</td>\n",
              "      <td>-5.571723</td>\n",
              "      <td>2.803077</td>\n",
              "      <td>-0.283363</td>\n",
              "      <td>-2.442273</td>\n",
              "      <td>-3.839922</td>\n",
              "      <td>-1.522143</td>\n",
              "      <td>-2.926482</td>\n",
              "      <td>0.365428</td>\n",
              "      <td>-1.837317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>-27.217442</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-19.589163</td>\n",
              "      <td>-8.899709</td>\n",
              "      <td>-12.807209</td>\n",
              "      <td>3.745601</td>\n",
              "      <td>-11.430717</td>\n",
              "      <td>9.099095</td>\n",
              "      <td>-7.937002</td>\n",
              "      <td>1.855414</td>\n",
              "      <td>-1.323820</td>\n",
              "      <td>-2.413804</td>\n",
              "      <td>-1.276750</td>\n",
              "      <td>0.090517</td>\n",
              "      <td>-6.109476</td>\n",
              "      <td>3.518335</td>\n",
              "      <td>-0.603973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438</th>\n",
              "      <td>-14.260783</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-18.052525</td>\n",
              "      <td>-4.351163</td>\n",
              "      <td>-7.299998</td>\n",
              "      <td>0.214021</td>\n",
              "      <td>-11.528538</td>\n",
              "      <td>1.779407</td>\n",
              "      <td>-12.382866</td>\n",
              "      <td>5.248011</td>\n",
              "      <td>-3.515553</td>\n",
              "      <td>-0.067374</td>\n",
              "      <td>-4.443567</td>\n",
              "      <td>4.867039</td>\n",
              "      <td>-2.615891</td>\n",
              "      <td>4.354655</td>\n",
              "      <td>6.432075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1439</th>\n",
              "      <td>-8.361695</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-16.925844</td>\n",
              "      <td>-1.147182</td>\n",
              "      <td>-14.435615</td>\n",
              "      <td>2.066961</td>\n",
              "      <td>-12.347527</td>\n",
              "      <td>-0.258641</td>\n",
              "      <td>-8.657541</td>\n",
              "      <td>2.759387</td>\n",
              "      <td>-0.637586</td>\n",
              "      <td>3.555834</td>\n",
              "      <td>0.016775</td>\n",
              "      <td>8.697381</td>\n",
              "      <td>-0.653415</td>\n",
              "      <td>3.075164</td>\n",
              "      <td>2.568863</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              2          3          4          5          6          7  \\\n",
              "60   -14.506104  13.734784  -8.915299  -0.597560  -9.627712  -6.697053   \n",
              "61   -16.155281  17.274385 -10.515155  -0.012929  -9.384588  -5.405496   \n",
              "62   -16.257780   9.051161  -9.175509  -0.249130  -9.898236  -7.671722   \n",
              "63   -15.687172  10.080914 -11.711167  -1.830589 -11.331991  -8.769240   \n",
              "64    -8.859457  17.944416  -9.782133   2.161584  -7.936422  -4.958043   \n",
              "...         ...        ...        ...        ...        ...        ...   \n",
              "1435 -25.876736   3.420890 -22.962826  -6.289969 -22.845768 -13.475706   \n",
              "1436 -22.979485  -0.832579 -23.050257 -10.238819 -17.452888  -8.696088   \n",
              "1437 -27.217442   2.902560 -22.611633 -14.189220 -19.589163  -8.899709   \n",
              "1438 -14.260783   9.399699 -19.878208   0.799514 -18.052525  -4.351163   \n",
              "1439  -8.361695   3.750752 -10.930555  -1.502927 -16.925844  -1.147182   \n",
              "\n",
              "              8         9         10        11         12        13  \\\n",
              "60    -7.643127  1.682984  -7.912409 -0.210760  -7.740003  1.756948   \n",
              "61    -6.061921  0.427206  -6.152109 -0.615899  -8.214749  1.275640   \n",
              "62    -8.782819  0.426915  -8.104342 -1.270707  -9.362936  3.294116   \n",
              "63   -10.589375 -0.807020  -9.551315 -1.466953 -12.188832  1.340084   \n",
              "64    -6.853294  0.523445  -6.652872 -2.524537  -7.584999  3.084172   \n",
              "...         ...       ...        ...       ...        ...       ...   \n",
              "1435 -11.609130 -4.602691 -13.470782 -0.407410  -9.948418  5.518756   \n",
              "1436 -14.158811  0.367432 -14.131364  8.980473  -5.571723  2.803077   \n",
              "1437 -12.807209  3.745601 -11.430717  9.099095  -7.937002  1.855414   \n",
              "1438  -7.299998  0.214021 -11.528538  1.779407 -12.382866  5.248011   \n",
              "1439 -14.435615  2.066961 -12.347527 -0.258641  -8.657541  2.759387   \n",
              "\n",
              "             14        15        16        17        18        19        20  \n",
              "60    -9.324497 -1.198008 -4.133364 -1.631853 -2.066447 -0.454988 -0.492106  \n",
              "61    -8.237226 -2.645824 -3.443796 -0.612220 -2.490293 -0.452201 -0.757748  \n",
              "62    -8.703416 -2.625140 -4.680979 -3.360180 -1.953824  0.267930 -0.405246  \n",
              "63   -10.352579 -2.398706 -4.686605 -4.565247 -2.227786 -0.699804 -0.750733  \n",
              "64    -8.050755 -1.479591 -4.934464 -1.571014 -5.846342 -1.533878 -2.314848  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "1435   2.247648  1.531702 -2.982210  0.129457 -4.504814  1.020297  0.744685  \n",
              "1436  -0.283363 -2.442273 -3.839922 -1.522143 -2.926482  0.365428 -1.837317  \n",
              "1437  -1.323820 -2.413804 -1.276750  0.090517 -6.109476  3.518335 -0.603973  \n",
              "1438  -3.515553 -0.067374 -4.443567  4.867039 -2.615891  4.354655  6.432075  \n",
              "1439  -0.637586  3.555834  0.016775  8.697381 -0.653415  3.075164  2.568863  \n",
              "\n",
              "[720 rows x 19 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.iloc[:,2:21]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "gxUVe0blXnOM",
        "outputId": "b2d383ec-5b16-45fc-bf37-d834a25675ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>67.129211</td>\n",
              "      <td>-0.492106</td>\n",
              "      <td>-0.597560</td>\n",
              "      <td>-8.915299</td>\n",
              "      <td>13.734784</td>\n",
              "      <td>2.562386</td>\n",
              "      <td>-0.584655</td>\n",
              "      <td>-1.166412</td>\n",
              "      <td>-1.631853</td>\n",
              "      <td>3.165983</td>\n",
              "      <td>-0.454988</td>\n",
              "      <td>0.651949</td>\n",
              "      <td>0.638643</td>\n",
              "      <td>0.817944</td>\n",
              "      <td>4.252230</td>\n",
              "      <td>-2.066447</td>\n",
              "      <td>-1.189286</td>\n",
              "      <td>0.000132</td>\n",
              "      <td>0.002189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>61.610241</td>\n",
              "      <td>-0.757748</td>\n",
              "      <td>-0.012929</td>\n",
              "      <td>-10.515155</td>\n",
              "      <td>17.274385</td>\n",
              "      <td>3.438142</td>\n",
              "      <td>-1.823772</td>\n",
              "      <td>-2.015452</td>\n",
              "      <td>-0.612220</td>\n",
              "      <td>2.389294</td>\n",
              "      <td>-0.452201</td>\n",
              "      <td>0.653383</td>\n",
              "      <td>0.655512</td>\n",
              "      <td>-0.383704</td>\n",
              "      <td>3.642304</td>\n",
              "      <td>-2.490293</td>\n",
              "      <td>-0.030232</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.002831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62.693829</td>\n",
              "      <td>-0.405246</td>\n",
              "      <td>-0.249130</td>\n",
              "      <td>-9.175509</td>\n",
              "      <td>9.051161</td>\n",
              "      <td>4.458579</td>\n",
              "      <td>-0.620401</td>\n",
              "      <td>-0.516156</td>\n",
              "      <td>-3.360180</td>\n",
              "      <td>2.336132</td>\n",
              "      <td>0.267930</td>\n",
              "      <td>0.646533</td>\n",
              "      <td>0.622269</td>\n",
              "      <td>-0.541295</td>\n",
              "      <td>1.528516</td>\n",
              "      <td>-1.953824</td>\n",
              "      <td>-0.867744</td>\n",
              "      <td>0.000136</td>\n",
              "      <td>0.004926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>58.990162</td>\n",
              "      <td>-0.750733</td>\n",
              "      <td>-1.830589</td>\n",
              "      <td>-11.711167</td>\n",
              "      <td>10.080914</td>\n",
              "      <td>5.752499</td>\n",
              "      <td>-2.187827</td>\n",
              "      <td>-2.110827</td>\n",
              "      <td>-4.565247</td>\n",
              "      <td>1.386648</td>\n",
              "      <td>-0.699804</td>\n",
              "      <td>0.693119</td>\n",
              "      <td>0.629015</td>\n",
              "      <td>-1.220224</td>\n",
              "      <td>-0.238860</td>\n",
              "      <td>-2.227786</td>\n",
              "      <td>1.405088</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>0.034047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64.624420</td>\n",
              "      <td>-2.314848</td>\n",
              "      <td>2.161584</td>\n",
              "      <td>-9.782133</td>\n",
              "      <td>17.944416</td>\n",
              "      <td>2.831547</td>\n",
              "      <td>-1.273513</td>\n",
              "      <td>-2.530665</td>\n",
              "      <td>-1.571014</td>\n",
              "      <td>2.817189</td>\n",
              "      <td>-1.533878</td>\n",
              "      <td>0.629772</td>\n",
              "      <td>0.559138</td>\n",
              "      <td>-0.409652</td>\n",
              "      <td>3.705062</td>\n",
              "      <td>-5.846342</td>\n",
              "      <td>-0.415711</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>0.004804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>715</th>\n",
              "      <td>34.201637</td>\n",
              "      <td>0.744685</td>\n",
              "      <td>-6.289969</td>\n",
              "      <td>-22.962826</td>\n",
              "      <td>3.420890</td>\n",
              "      <td>-2.260234</td>\n",
              "      <td>-0.272697</td>\n",
              "      <td>0.603423</td>\n",
              "      <td>0.129457</td>\n",
              "      <td>-1.230022</td>\n",
              "      <td>1.020297</td>\n",
              "      <td>0.590818</td>\n",
              "      <td>0.587434</td>\n",
              "      <td>1.878527</td>\n",
              "      <td>0.438060</td>\n",
              "      <td>-4.504814</td>\n",
              "      <td>-1.394105</td>\n",
              "      <td>0.000083</td>\n",
              "      <td>0.022306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>716</th>\n",
              "      <td>49.378990</td>\n",
              "      <td>-1.837317</td>\n",
              "      <td>-10.238819</td>\n",
              "      <td>-23.050257</td>\n",
              "      <td>-0.832579</td>\n",
              "      <td>0.838848</td>\n",
              "      <td>2.687783</td>\n",
              "      <td>1.452663</td>\n",
              "      <td>-1.522143</td>\n",
              "      <td>-0.432767</td>\n",
              "      <td>0.365428</td>\n",
              "      <td>0.556154</td>\n",
              "      <td>0.579354</td>\n",
              "      <td>4.182149</td>\n",
              "      <td>-0.216449</td>\n",
              "      <td>-2.926482</td>\n",
              "      <td>-1.780653</td>\n",
              "      <td>0.000279</td>\n",
              "      <td>0.048357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>717</th>\n",
              "      <td>40.459633</td>\n",
              "      <td>-0.603973</td>\n",
              "      <td>-14.189220</td>\n",
              "      <td>-22.611633</td>\n",
              "      <td>2.902560</td>\n",
              "      <td>0.558064</td>\n",
              "      <td>1.165252</td>\n",
              "      <td>3.088328</td>\n",
              "      <td>0.090517</td>\n",
              "      <td>-0.588120</td>\n",
              "      <td>3.518335</td>\n",
              "      <td>0.616164</td>\n",
              "      <td>0.572284</td>\n",
              "      <td>2.130498</td>\n",
              "      <td>-0.526071</td>\n",
              "      <td>-6.109476</td>\n",
              "      <td>-0.759211</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>0.026785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>718</th>\n",
              "      <td>35.496925</td>\n",
              "      <td>6.432075</td>\n",
              "      <td>0.799514</td>\n",
              "      <td>-19.878208</td>\n",
              "      <td>9.399699</td>\n",
              "      <td>0.613665</td>\n",
              "      <td>5.269444</td>\n",
              "      <td>4.869069</td>\n",
              "      <td>4.867039</td>\n",
              "      <td>-0.769184</td>\n",
              "      <td>4.354655</td>\n",
              "      <td>0.632247</td>\n",
              "      <td>0.577784</td>\n",
              "      <td>7.263998</td>\n",
              "      <td>-0.638832</td>\n",
              "      <td>-2.615891</td>\n",
              "      <td>0.836838</td>\n",
              "      <td>0.000335</td>\n",
              "      <td>0.145730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>719</th>\n",
              "      <td>39.540497</td>\n",
              "      <td>2.568863</td>\n",
              "      <td>-1.502927</td>\n",
              "      <td>-10.930555</td>\n",
              "      <td>3.750752</td>\n",
              "      <td>0.821056</td>\n",
              "      <td>2.790621</td>\n",
              "      <td>2.945298</td>\n",
              "      <td>8.697381</td>\n",
              "      <td>0.695307</td>\n",
              "      <td>3.075164</td>\n",
              "      <td>0.621623</td>\n",
              "      <td>0.567703</td>\n",
              "      <td>5.864208</td>\n",
              "      <td>0.448777</td>\n",
              "      <td>-0.653415</td>\n",
              "      <td>0.196954</td>\n",
              "      <td>0.000609</td>\n",
              "      <td>0.013531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>720 rows × 19 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            2         3          4          5          6         7         8   \\\n",
              "0    67.129211 -0.492106  -0.597560  -8.915299  13.734784  2.562386 -0.584655   \n",
              "1    61.610241 -0.757748  -0.012929 -10.515155  17.274385  3.438142 -1.823772   \n",
              "2    62.693829 -0.405246  -0.249130  -9.175509   9.051161  4.458579 -0.620401   \n",
              "3    58.990162 -0.750733  -1.830589 -11.711167  10.080914  5.752499 -2.187827   \n",
              "4    64.624420 -2.314848   2.161584  -9.782133  17.944416  2.831547 -1.273513   \n",
              "..         ...       ...        ...        ...        ...       ...       ...   \n",
              "715  34.201637  0.744685  -6.289969 -22.962826   3.420890 -2.260234 -0.272697   \n",
              "716  49.378990 -1.837317 -10.238819 -23.050257  -0.832579  0.838848  2.687783   \n",
              "717  40.459633 -0.603973 -14.189220 -22.611633   2.902560  0.558064  1.165252   \n",
              "718  35.496925  6.432075   0.799514 -19.878208   9.399699  0.613665  5.269444   \n",
              "719  39.540497  2.568863  -1.502927 -10.930555   3.750752  0.821056  2.790621   \n",
              "\n",
              "           9         10        11        12        13        14        15  \\\n",
              "0   -1.166412 -1.631853  3.165983 -0.454988  0.651949  0.638643  0.817944   \n",
              "1   -2.015452 -0.612220  2.389294 -0.452201  0.653383  0.655512 -0.383704   \n",
              "2   -0.516156 -3.360180  2.336132  0.267930  0.646533  0.622269 -0.541295   \n",
              "3   -2.110827 -4.565247  1.386648 -0.699804  0.693119  0.629015 -1.220224   \n",
              "4   -2.530665 -1.571014  2.817189 -1.533878  0.629772  0.559138 -0.409652   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "715  0.603423  0.129457 -1.230022  1.020297  0.590818  0.587434  1.878527   \n",
              "716  1.452663 -1.522143 -0.432767  0.365428  0.556154  0.579354  4.182149   \n",
              "717  3.088328  0.090517 -0.588120  3.518335  0.616164  0.572284  2.130498   \n",
              "718  4.869069  4.867039 -0.769184  4.354655  0.632247  0.577784  7.263998   \n",
              "719  2.945298  8.697381  0.695307  3.075164  0.621623  0.567703  5.864208   \n",
              "\n",
              "           16        17        18        19        20  \n",
              "0    4.252230 -2.066447 -1.189286  0.000132  0.002189  \n",
              "1    3.642304 -2.490293 -0.030232  0.000147  0.002831  \n",
              "2    1.528516 -1.953824 -0.867744  0.000136  0.004926  \n",
              "3   -0.238860 -2.227786  1.405088  0.000063  0.034047  \n",
              "4    3.705062 -5.846342 -0.415711  0.000067  0.004804  \n",
              "..        ...       ...       ...       ...       ...  \n",
              "715  0.438060 -4.504814 -1.394105  0.000083  0.022306  \n",
              "716 -0.216449 -2.926482 -1.780653  0.000279  0.048357  \n",
              "717 -0.526071 -6.109476 -0.759211  0.000695  0.026785  \n",
              "718 -0.638832 -2.615891  0.836838  0.000335  0.145730  \n",
              "719  0.448777 -0.653415  0.196954  0.000609  0.013531  \n",
              "\n",
              "[720 rows x 19 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X3.iloc[:,2:21]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "npr2WvAeXnON"
      },
      "outputs": [],
      "source": [
        "#########"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "R5yJTYVXXnON"
      },
      "outputs": [],
      "source": [
        "### import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import keras\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Activation\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.data_utils import pad_sequences\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Input, Flatten, Dropout#, Activation\n",
        "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "def model1(input_shape1):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv1D(256, 5,padding='same',\n",
        "                     input_shape=(input_shape1,1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "\n",
        "    model.add(Conv1D(256, 5,padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(MaxPooling1D(pool_size=(8)))\n",
        "    model.add(Conv1D(256, 5,padding='same',))\n",
        "\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Conv1D(128, 5,padding='same',))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv1D(128, 5,padding='same',))\n",
        "    model.add(BatchNormalization())\n",
        "\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "\n",
        "    #model.add(Conv1D(128, 5,padding='same',))\n",
        "    #model.add(Activation('relu'))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(8))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    #model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q6g4JJ-qXnON"
      },
      "outputs": [],
      "source": [
        "import random, numpy as np\n",
        "from tensorflow.keras import optimizers\n",
        "kfold=5\n",
        "def create_index(kfold, size):\n",
        "    a = []\n",
        "    for i in range(size):\n",
        "        a.append(i)\n",
        "    random.shuffle(a)\n",
        "    arr = np.array(a)\n",
        "    return arr.reshape(kfold, size//kfold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHYOo3vmXnON",
        "outputId": "b8fe08a9-6ea9-439d-c587-20a50f0dee9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "Epoch 1/700\n",
            "9/9 [==============================] - 2s 101ms/step - loss: 2.4545 - accuracy: 0.1146 - val_loss: 2.8617 - val_accuracy: 0.1597\n",
            "Epoch 2/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 2.3270 - accuracy: 0.1545 - val_loss: 2.6666 - val_accuracy: 0.1597\n",
            "Epoch 3/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 2.2653 - accuracy: 0.1719 - val_loss: 2.5070 - val_accuracy: 0.1597\n",
            "Epoch 4/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 2.1935 - accuracy: 0.2118 - val_loss: 2.4023 - val_accuracy: 0.1597\n",
            "Epoch 5/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 2.2076 - accuracy: 0.1840 - val_loss: 2.3096 - val_accuracy: 0.1597\n",
            "Epoch 6/700\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 2.1792 - accuracy: 0.1840 - val_loss: 2.2330 - val_accuracy: 0.1806\n",
            "Epoch 7/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 2.0609 - accuracy: 0.2205 - val_loss: 2.1719 - val_accuracy: 0.2153\n",
            "Epoch 8/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 2.0589 - accuracy: 0.2222 - val_loss: 2.1267 - val_accuracy: 0.2500\n",
            "Epoch 9/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 2.0424 - accuracy: 0.2153 - val_loss: 2.0940 - val_accuracy: 0.1944\n",
            "Epoch 10/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.9978 - accuracy: 0.2396 - val_loss: 2.0724 - val_accuracy: 0.1667\n",
            "Epoch 11/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.9719 - accuracy: 0.2569 - val_loss: 2.0453 - val_accuracy: 0.1944\n",
            "Epoch 12/700\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 1.9727 - accuracy: 0.2378 - val_loss: 2.0444 - val_accuracy: 0.1944\n",
            "Epoch 13/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.9608 - accuracy: 0.2517 - val_loss: 2.0320 - val_accuracy: 0.1806\n",
            "Epoch 14/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.8660 - accuracy: 0.3038 - val_loss: 2.0133 - val_accuracy: 0.1806\n",
            "Epoch 15/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.8275 - accuracy: 0.2934 - val_loss: 2.0110 - val_accuracy: 0.1875\n",
            "Epoch 16/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.8689 - accuracy: 0.2830 - val_loss: 2.0112 - val_accuracy: 0.1736\n",
            "Epoch 17/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.8033 - accuracy: 0.2986 - val_loss: 2.0083 - val_accuracy: 0.1597\n",
            "Epoch 18/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.8769 - accuracy: 0.3003 - val_loss: 2.0141 - val_accuracy: 0.1597\n",
            "Epoch 19/700\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 1.7845 - accuracy: 0.3368 - val_loss: 2.0162 - val_accuracy: 0.1597\n",
            "Epoch 20/700\n",
            "9/9 [==============================] - 1s 86ms/step - loss: 1.7524 - accuracy: 0.3438 - val_loss: 2.0207 - val_accuracy: 0.1528\n",
            "Epoch 21/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.7504 - accuracy: 0.3594 - val_loss: 2.0360 - val_accuracy: 0.1528\n",
            "Epoch 22/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.7087 - accuracy: 0.3646 - val_loss: 2.0290 - val_accuracy: 0.1528\n",
            "Epoch 23/700\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 1.7474 - accuracy: 0.3403 - val_loss: 2.0420 - val_accuracy: 0.1528\n",
            "Epoch 24/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.7366 - accuracy: 0.3160 - val_loss: 2.0281 - val_accuracy: 0.1528\n",
            "Epoch 25/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.6846 - accuracy: 0.3698 - val_loss: 2.0194 - val_accuracy: 0.1528\n",
            "Epoch 26/700\n",
            "9/9 [==============================] - 1s 84ms/step - loss: 1.6977 - accuracy: 0.3819 - val_loss: 2.0171 - val_accuracy: 0.1528\n",
            "Epoch 27/700\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 1.6747 - accuracy: 0.3663 - val_loss: 2.0144 - val_accuracy: 0.1528\n",
            "Epoch 28/700\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 1.6270 - accuracy: 0.3941 - val_loss: 2.0219 - val_accuracy: 0.1528\n",
            "Epoch 29/700\n",
            "9/9 [==============================] - 1s 87ms/step - loss: 1.6267 - accuracy: 0.4201 - val_loss: 2.0210 - val_accuracy: 0.1528\n",
            "Epoch 30/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.6426 - accuracy: 0.3750 - val_loss: 2.0097 - val_accuracy: 0.1528\n",
            "Epoch 31/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.6021 - accuracy: 0.3976 - val_loss: 1.9980 - val_accuracy: 0.1528\n",
            "Epoch 32/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.5778 - accuracy: 0.4236 - val_loss: 1.9927 - val_accuracy: 0.1528\n",
            "Epoch 33/700\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.6199 - accuracy: 0.3958 - val_loss: 1.9651 - val_accuracy: 0.1597\n",
            "Epoch 34/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.5942 - accuracy: 0.4306 - val_loss: 1.9536 - val_accuracy: 0.1597\n",
            "Epoch 35/700\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 1.5844 - accuracy: 0.4184 - val_loss: 1.9442 - val_accuracy: 0.1597\n",
            "Epoch 36/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.5662 - accuracy: 0.4375 - val_loss: 1.9341 - val_accuracy: 0.1597\n",
            "Epoch 37/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.5308 - accuracy: 0.4618 - val_loss: 1.9315 - val_accuracy: 0.1597\n",
            "Epoch 38/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.5382 - accuracy: 0.4410 - val_loss: 1.9154 - val_accuracy: 0.1597\n",
            "Epoch 39/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.5097 - accuracy: 0.4410 - val_loss: 1.9037 - val_accuracy: 0.1597\n",
            "Epoch 40/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.5074 - accuracy: 0.4479 - val_loss: 1.8845 - val_accuracy: 0.1736\n",
            "Epoch 41/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.4884 - accuracy: 0.4670 - val_loss: 1.8760 - val_accuracy: 0.1736\n",
            "Epoch 42/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.5324 - accuracy: 0.4549 - val_loss: 1.8568 - val_accuracy: 0.1736\n",
            "Epoch 43/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.4705 - accuracy: 0.4722 - val_loss: 1.8561 - val_accuracy: 0.1736\n",
            "Epoch 44/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.4545 - accuracy: 0.4740 - val_loss: 1.8495 - val_accuracy: 0.1736\n",
            "Epoch 45/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.4507 - accuracy: 0.4844 - val_loss: 1.8348 - val_accuracy: 0.1806\n",
            "Epoch 46/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.4551 - accuracy: 0.4792 - val_loss: 1.8116 - val_accuracy: 0.1875\n",
            "Epoch 47/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.4497 - accuracy: 0.4948 - val_loss: 1.7879 - val_accuracy: 0.2014\n",
            "Epoch 48/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.4452 - accuracy: 0.5017 - val_loss: 1.7641 - val_accuracy: 0.2222\n",
            "Epoch 49/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.4517 - accuracy: 0.4826 - val_loss: 1.7413 - val_accuracy: 0.2639\n",
            "Epoch 50/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.4347 - accuracy: 0.5052 - val_loss: 1.7133 - val_accuracy: 0.2778\n",
            "Epoch 51/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.4188 - accuracy: 0.5243 - val_loss: 1.6977 - val_accuracy: 0.2917\n",
            "Epoch 52/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.4092 - accuracy: 0.5052 - val_loss: 1.6716 - val_accuracy: 0.3611\n",
            "Epoch 53/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.4102 - accuracy: 0.5104 - val_loss: 1.6501 - val_accuracy: 0.3542\n",
            "Epoch 54/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.4061 - accuracy: 0.5226 - val_loss: 1.6398 - val_accuracy: 0.3611\n",
            "Epoch 55/700\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.3605 - accuracy: 0.5382 - val_loss: 1.6329 - val_accuracy: 0.3611\n",
            "Epoch 56/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.3653 - accuracy: 0.5451 - val_loss: 1.6349 - val_accuracy: 0.3403\n",
            "Epoch 57/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.3693 - accuracy: 0.5312 - val_loss: 1.6243 - val_accuracy: 0.3472\n",
            "Epoch 58/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.3591 - accuracy: 0.5382 - val_loss: 1.6062 - val_accuracy: 0.3750\n",
            "Epoch 59/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.3606 - accuracy: 0.5278 - val_loss: 1.5878 - val_accuracy: 0.3819\n",
            "Epoch 60/700\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 1.3759 - accuracy: 0.5503 - val_loss: 1.5647 - val_accuracy: 0.4236\n",
            "Epoch 61/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.3561 - accuracy: 0.5365 - val_loss: 1.5415 - val_accuracy: 0.4236\n",
            "Epoch 62/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.3470 - accuracy: 0.5382 - val_loss: 1.5387 - val_accuracy: 0.4306\n",
            "Epoch 63/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.3250 - accuracy: 0.5556 - val_loss: 1.5212 - val_accuracy: 0.4444\n",
            "Epoch 64/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2895 - accuracy: 0.5851 - val_loss: 1.5060 - val_accuracy: 0.4653\n",
            "Epoch 65/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.3189 - accuracy: 0.5503 - val_loss: 1.5071 - val_accuracy: 0.4792\n",
            "Epoch 66/700\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.3244 - accuracy: 0.5694 - val_loss: 1.4907 - val_accuracy: 0.4583\n",
            "Epoch 67/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.2980 - accuracy: 0.5799 - val_loss: 1.4909 - val_accuracy: 0.4861\n",
            "Epoch 68/700\n",
            "9/9 [==============================] - 1s 83ms/step - loss: 1.3317 - accuracy: 0.5729 - val_loss: 1.4731 - val_accuracy: 0.4583\n",
            "Epoch 69/700\n",
            "9/9 [==============================] - 1s 78ms/step - loss: 1.2999 - accuracy: 0.5851 - val_loss: 1.4800 - val_accuracy: 0.4722\n",
            "Epoch 70/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.2974 - accuracy: 0.5764 - val_loss: 1.4609 - val_accuracy: 0.4792\n",
            "Epoch 71/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.2952 - accuracy: 0.5712 - val_loss: 1.4523 - val_accuracy: 0.4931\n",
            "Epoch 72/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.2525 - accuracy: 0.6042 - val_loss: 1.4569 - val_accuracy: 0.4931\n",
            "Epoch 73/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2826 - accuracy: 0.5938 - val_loss: 1.4308 - val_accuracy: 0.5278\n",
            "Epoch 74/700\n",
            "9/9 [==============================] - 1s 80ms/step - loss: 1.2760 - accuracy: 0.6146 - val_loss: 1.4190 - val_accuracy: 0.5278\n",
            "Epoch 75/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.2661 - accuracy: 0.5851 - val_loss: 1.4044 - val_accuracy: 0.5347\n",
            "Epoch 76/700\n",
            "9/9 [==============================] - 1s 82ms/step - loss: 1.2551 - accuracy: 0.5990 - val_loss: 1.3879 - val_accuracy: 0.5347\n",
            "Epoch 77/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2732 - accuracy: 0.5938 - val_loss: 1.3875 - val_accuracy: 0.5486\n",
            "Epoch 78/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.2535 - accuracy: 0.6076 - val_loss: 1.3753 - val_accuracy: 0.5486\n",
            "Epoch 79/700\n",
            "9/9 [==============================] - 1s 81ms/step - loss: 1.2125 - accuracy: 0.6424 - val_loss: 1.3761 - val_accuracy: 0.5764\n",
            "Epoch 80/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2420 - accuracy: 0.6181 - val_loss: 1.3682 - val_accuracy: 0.5556\n",
            "Epoch 81/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2096 - accuracy: 0.6493 - val_loss: 1.3495 - val_accuracy: 0.5556\n",
            "Epoch 82/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2149 - accuracy: 0.6372 - val_loss: 1.3401 - val_accuracy: 0.5903\n",
            "Epoch 83/700\n",
            "9/9 [==============================] - 1s 79ms/step - loss: 1.2102 - accuracy: 0.6059 - val_loss: 1.3390 - val_accuracy: 0.6181\n",
            "Epoch 84/700\n",
            "9/9 [==============================] - 1s 85ms/step - loss: 1.2006 - accuracy: 0.6528 - val_loss: 1.3363 - val_accuracy: 0.5625\n",
            "Epoch 85/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2070 - accuracy: 0.6146 - val_loss: 1.3377 - val_accuracy: 0.5833\n",
            "Epoch 86/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2058 - accuracy: 0.6198 - val_loss: 1.3286 - val_accuracy: 0.5694\n",
            "Epoch 87/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 1.1933 - accuracy: 0.6562 - val_loss: 1.3184 - val_accuracy: 0.5833\n",
            "Epoch 88/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2108 - accuracy: 0.6424 - val_loss: 1.3201 - val_accuracy: 0.6111\n",
            "Epoch 89/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1727 - accuracy: 0.6667 - val_loss: 1.3133 - val_accuracy: 0.6181\n",
            "Epoch 90/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1809 - accuracy: 0.6684 - val_loss: 1.2935 - val_accuracy: 0.6181\n",
            "Epoch 91/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.2107 - accuracy: 0.6267 - val_loss: 1.3072 - val_accuracy: 0.6111\n",
            "Epoch 92/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.1646 - accuracy: 0.6684 - val_loss: 1.3095 - val_accuracy: 0.5972\n",
            "Epoch 93/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1930 - accuracy: 0.6354 - val_loss: 1.2880 - val_accuracy: 0.6181\n",
            "Epoch 94/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1802 - accuracy: 0.6545 - val_loss: 1.2847 - val_accuracy: 0.5972\n",
            "Epoch 95/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1707 - accuracy: 0.6458 - val_loss: 1.2787 - val_accuracy: 0.6042\n",
            "Epoch 96/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 1.1904 - accuracy: 0.6458 - val_loss: 1.2639 - val_accuracy: 0.6250\n",
            "Epoch 97/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1579 - accuracy: 0.6858 - val_loss: 1.2678 - val_accuracy: 0.6111\n",
            "Epoch 98/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1467 - accuracy: 0.6771 - val_loss: 1.2629 - val_accuracy: 0.6181\n",
            "Epoch 99/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1412 - accuracy: 0.6858 - val_loss: 1.2633 - val_accuracy: 0.6250\n",
            "Epoch 100/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1405 - accuracy: 0.6858 - val_loss: 1.2569 - val_accuracy: 0.6458\n",
            "Epoch 101/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1426 - accuracy: 0.6788 - val_loss: 1.2533 - val_accuracy: 0.6319\n",
            "Epoch 102/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.1407 - accuracy: 0.7101 - val_loss: 1.2595 - val_accuracy: 0.6181\n",
            "Epoch 103/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1285 - accuracy: 0.6979 - val_loss: 1.2473 - val_accuracy: 0.6250\n",
            "Epoch 104/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1199 - accuracy: 0.6927 - val_loss: 1.2624 - val_accuracy: 0.6458\n",
            "Epoch 105/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1120 - accuracy: 0.6892 - val_loss: 1.2449 - val_accuracy: 0.6319\n",
            "Epoch 106/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1356 - accuracy: 0.6910 - val_loss: 1.2345 - val_accuracy: 0.6528\n",
            "Epoch 107/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 1.1292 - accuracy: 0.6910 - val_loss: 1.2385 - val_accuracy: 0.6528\n",
            "Epoch 108/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1009 - accuracy: 0.7257 - val_loss: 1.2340 - val_accuracy: 0.6458\n",
            "Epoch 109/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 1.1222 - accuracy: 0.6927 - val_loss: 1.2283 - val_accuracy: 0.6389\n",
            "Epoch 110/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1265 - accuracy: 0.6979 - val_loss: 1.2400 - val_accuracy: 0.6250\n",
            "Epoch 111/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1053 - accuracy: 0.6840 - val_loss: 1.2233 - val_accuracy: 0.6458\n",
            "Epoch 112/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1139 - accuracy: 0.6788 - val_loss: 1.2279 - val_accuracy: 0.6458\n",
            "Epoch 113/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1160 - accuracy: 0.6806 - val_loss: 1.2147 - val_accuracy: 0.6458\n",
            "Epoch 114/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0934 - accuracy: 0.7049 - val_loss: 1.2301 - val_accuracy: 0.6319\n",
            "Epoch 115/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.1072 - accuracy: 0.6875 - val_loss: 1.2234 - val_accuracy: 0.6319\n",
            "Epoch 116/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.1131 - accuracy: 0.6927 - val_loss: 1.2055 - val_accuracy: 0.6667\n",
            "Epoch 117/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0932 - accuracy: 0.6944 - val_loss: 1.1981 - val_accuracy: 0.6458\n",
            "Epoch 118/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0677 - accuracy: 0.7361 - val_loss: 1.2077 - val_accuracy: 0.6597\n",
            "Epoch 119/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0614 - accuracy: 0.7361 - val_loss: 1.1914 - val_accuracy: 0.6875\n",
            "Epoch 120/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0549 - accuracy: 0.7431 - val_loss: 1.2027 - val_accuracy: 0.6667\n",
            "Epoch 121/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0699 - accuracy: 0.7292 - val_loss: 1.2112 - val_accuracy: 0.6806\n",
            "Epoch 122/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.0805 - accuracy: 0.7101 - val_loss: 1.1969 - val_accuracy: 0.6667\n",
            "Epoch 123/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0572 - accuracy: 0.7222 - val_loss: 1.2018 - val_accuracy: 0.6458\n",
            "Epoch 124/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0738 - accuracy: 0.7031 - val_loss: 1.1854 - val_accuracy: 0.7153\n",
            "Epoch 125/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0744 - accuracy: 0.7083 - val_loss: 1.2026 - val_accuracy: 0.6667\n",
            "Epoch 126/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0724 - accuracy: 0.7222 - val_loss: 1.1971 - val_accuracy: 0.6736\n",
            "Epoch 127/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0514 - accuracy: 0.7274 - val_loss: 1.1907 - val_accuracy: 0.7083\n",
            "Epoch 128/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0463 - accuracy: 0.7309 - val_loss: 1.1963 - val_accuracy: 0.6736\n",
            "Epoch 129/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0800 - accuracy: 0.7170 - val_loss: 1.1937 - val_accuracy: 0.6736\n",
            "Epoch 130/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 1.0501 - accuracy: 0.7465 - val_loss: 1.1863 - val_accuracy: 0.6806\n",
            "Epoch 131/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.0323 - accuracy: 0.7465 - val_loss: 1.2002 - val_accuracy: 0.6528\n",
            "Epoch 132/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0482 - accuracy: 0.7326 - val_loss: 1.1903 - val_accuracy: 0.6736\n",
            "Epoch 133/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.0174 - accuracy: 0.7639 - val_loss: 1.1939 - val_accuracy: 0.6528\n",
            "Epoch 134/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0143 - accuracy: 0.7517 - val_loss: 1.1826 - val_accuracy: 0.6806\n",
            "Epoch 135/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0254 - accuracy: 0.7292 - val_loss: 1.1670 - val_accuracy: 0.6875\n",
            "Epoch 136/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0374 - accuracy: 0.7500 - val_loss: 1.1791 - val_accuracy: 0.6528\n",
            "Epoch 137/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0251 - accuracy: 0.7726 - val_loss: 1.1765 - val_accuracy: 0.6736\n",
            "Epoch 138/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9907 - accuracy: 0.7778 - val_loss: 1.1854 - val_accuracy: 0.6806\n",
            "Epoch 139/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0409 - accuracy: 0.7483 - val_loss: 1.1754 - val_accuracy: 0.6667\n",
            "Epoch 140/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0265 - accuracy: 0.7274 - val_loss: 1.1707 - val_accuracy: 0.6667\n",
            "Epoch 141/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.0027 - accuracy: 0.7569 - val_loss: 1.1709 - val_accuracy: 0.6736\n",
            "Epoch 142/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0230 - accuracy: 0.7448 - val_loss: 1.1698 - val_accuracy: 0.6806\n",
            "Epoch 143/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 1.0242 - accuracy: 0.7448 - val_loss: 1.1698 - val_accuracy: 0.6875\n",
            "Epoch 144/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0036 - accuracy: 0.7604 - val_loss: 1.1648 - val_accuracy: 0.6736\n",
            "Epoch 145/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9860 - accuracy: 0.7743 - val_loss: 1.1605 - val_accuracy: 0.7014\n",
            "Epoch 146/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0096 - accuracy: 0.7674 - val_loss: 1.1546 - val_accuracy: 0.7083\n",
            "Epoch 147/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0044 - accuracy: 0.7483 - val_loss: 1.1508 - val_accuracy: 0.6875\n",
            "Epoch 148/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0057 - accuracy: 0.7639 - val_loss: 1.1605 - val_accuracy: 0.7014\n",
            "Epoch 149/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9824 - accuracy: 0.7760 - val_loss: 1.1533 - val_accuracy: 0.6944\n",
            "Epoch 150/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9840 - accuracy: 0.7674 - val_loss: 1.1428 - val_accuracy: 0.7014\n",
            "Epoch 151/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9768 - accuracy: 0.7917 - val_loss: 1.1577 - val_accuracy: 0.7083\n",
            "Epoch 152/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9985 - accuracy: 0.7604 - val_loss: 1.1482 - val_accuracy: 0.7014\n",
            "Epoch 153/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9897 - accuracy: 0.7604 - val_loss: 1.1394 - val_accuracy: 0.6944\n",
            "Epoch 154/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9782 - accuracy: 0.7500 - val_loss: 1.1475 - val_accuracy: 0.6875\n",
            "Epoch 155/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9862 - accuracy: 0.7760 - val_loss: 1.1532 - val_accuracy: 0.6875\n",
            "Epoch 156/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0166 - accuracy: 0.7413 - val_loss: 1.1366 - val_accuracy: 0.6806\n",
            "Epoch 157/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9545 - accuracy: 0.8021 - val_loss: 1.1367 - val_accuracy: 0.6806\n",
            "Epoch 158/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9646 - accuracy: 0.7934 - val_loss: 1.1343 - val_accuracy: 0.6944\n",
            "Epoch 159/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9526 - accuracy: 0.7726 - val_loss: 1.1325 - val_accuracy: 0.6875\n",
            "Epoch 160/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9829 - accuracy: 0.7639 - val_loss: 1.1070 - val_accuracy: 0.6875\n",
            "Epoch 161/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9804 - accuracy: 0.7622 - val_loss: 1.1164 - val_accuracy: 0.7014\n",
            "Epoch 162/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9720 - accuracy: 0.7743 - val_loss: 1.1114 - val_accuracy: 0.7222\n",
            "Epoch 163/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9441 - accuracy: 0.7951 - val_loss: 1.1050 - val_accuracy: 0.7153\n",
            "Epoch 164/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9619 - accuracy: 0.7812 - val_loss: 1.1245 - val_accuracy: 0.7014\n",
            "Epoch 165/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9574 - accuracy: 0.7726 - val_loss: 1.0992 - val_accuracy: 0.7222\n",
            "Epoch 166/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.9581 - accuracy: 0.7778 - val_loss: 1.0998 - val_accuracy: 0.7361\n",
            "Epoch 167/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9366 - accuracy: 0.8160 - val_loss: 1.1191 - val_accuracy: 0.7222\n",
            "Epoch 168/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9382 - accuracy: 0.7934 - val_loss: 1.1280 - val_accuracy: 0.7014\n",
            "Epoch 169/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9591 - accuracy: 0.7656 - val_loss: 1.1077 - val_accuracy: 0.7153\n",
            "Epoch 170/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9512 - accuracy: 0.7760 - val_loss: 1.1162 - val_accuracy: 0.7153\n",
            "Epoch 171/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9433 - accuracy: 0.7934 - val_loss: 1.1095 - val_accuracy: 0.7014\n",
            "Epoch 172/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9616 - accuracy: 0.7882 - val_loss: 1.1185 - val_accuracy: 0.6875\n",
            "Epoch 173/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9467 - accuracy: 0.7760 - val_loss: 1.1079 - val_accuracy: 0.7083\n",
            "Epoch 174/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9295 - accuracy: 0.7812 - val_loss: 1.1035 - val_accuracy: 0.7083\n",
            "Epoch 175/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9269 - accuracy: 0.7830 - val_loss: 1.1127 - val_accuracy: 0.6944\n",
            "Epoch 176/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9277 - accuracy: 0.8177 - val_loss: 1.1201 - val_accuracy: 0.7153\n",
            "Epoch 177/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9223 - accuracy: 0.7917 - val_loss: 1.1194 - val_accuracy: 0.7153\n",
            "Epoch 178/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9363 - accuracy: 0.7917 - val_loss: 1.1158 - val_accuracy: 0.7153\n",
            "Epoch 179/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9062 - accuracy: 0.8125 - val_loss: 1.1215 - val_accuracy: 0.7153\n",
            "Epoch 180/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8959 - accuracy: 0.8351 - val_loss: 1.1204 - val_accuracy: 0.7083\n",
            "Epoch 181/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.9232 - accuracy: 0.8108 - val_loss: 1.1122 - val_accuracy: 0.7292\n",
            "Epoch 182/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9123 - accuracy: 0.8299 - val_loss: 1.1046 - val_accuracy: 0.7222\n",
            "Epoch 183/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.9341 - accuracy: 0.7969 - val_loss: 1.0965 - val_accuracy: 0.7292\n",
            "Epoch 184/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8948 - accuracy: 0.8229 - val_loss: 1.1009 - val_accuracy: 0.7292\n",
            "Epoch 185/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9169 - accuracy: 0.8021 - val_loss: 1.0933 - val_accuracy: 0.7292\n",
            "Epoch 186/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9234 - accuracy: 0.7882 - val_loss: 1.1012 - val_accuracy: 0.7153\n",
            "Epoch 187/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9152 - accuracy: 0.8142 - val_loss: 1.1036 - val_accuracy: 0.7292\n",
            "Epoch 188/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9225 - accuracy: 0.8073 - val_loss: 1.1015 - val_accuracy: 0.7292\n",
            "Epoch 189/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9063 - accuracy: 0.8090 - val_loss: 1.1017 - val_accuracy: 0.7222\n",
            "Epoch 190/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8914 - accuracy: 0.8403 - val_loss: 1.0864 - val_accuracy: 0.7569\n",
            "Epoch 191/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8840 - accuracy: 0.8420 - val_loss: 1.0897 - val_accuracy: 0.7431\n",
            "Epoch 192/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9065 - accuracy: 0.8056 - val_loss: 1.1003 - val_accuracy: 0.7083\n",
            "Epoch 193/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9010 - accuracy: 0.8177 - val_loss: 1.1038 - val_accuracy: 0.7014\n",
            "Epoch 194/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8991 - accuracy: 0.7917 - val_loss: 1.0998 - val_accuracy: 0.7222\n",
            "Epoch 195/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8797 - accuracy: 0.8333 - val_loss: 1.0823 - val_accuracy: 0.7361\n",
            "Epoch 196/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8738 - accuracy: 0.8385 - val_loss: 1.0888 - val_accuracy: 0.7361\n",
            "Epoch 197/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8805 - accuracy: 0.8420 - val_loss: 1.0847 - val_accuracy: 0.7569\n",
            "Epoch 198/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8807 - accuracy: 0.8264 - val_loss: 1.0945 - val_accuracy: 0.7361\n",
            "Epoch 199/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.9053 - accuracy: 0.8090 - val_loss: 1.0932 - val_accuracy: 0.7292\n",
            "Epoch 200/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8725 - accuracy: 0.8420 - val_loss: 1.0786 - val_accuracy: 0.7431\n",
            "Epoch 201/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8867 - accuracy: 0.8160 - val_loss: 1.0893 - val_accuracy: 0.7361\n",
            "Epoch 202/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8565 - accuracy: 0.8455 - val_loss: 1.0831 - val_accuracy: 0.7431\n",
            "Epoch 203/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8672 - accuracy: 0.8403 - val_loss: 1.0751 - val_accuracy: 0.7361\n",
            "Epoch 204/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8840 - accuracy: 0.8403 - val_loss: 1.0736 - val_accuracy: 0.7431\n",
            "Epoch 205/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8757 - accuracy: 0.8420 - val_loss: 1.0750 - val_accuracy: 0.7361\n",
            "Epoch 206/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8823 - accuracy: 0.8090 - val_loss: 1.0666 - val_accuracy: 0.7431\n",
            "Epoch 207/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8661 - accuracy: 0.8368 - val_loss: 1.0733 - val_accuracy: 0.7431\n",
            "Epoch 208/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8719 - accuracy: 0.8403 - val_loss: 1.0704 - val_accuracy: 0.7431\n",
            "Epoch 209/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8637 - accuracy: 0.8264 - val_loss: 1.0596 - val_accuracy: 0.7431\n",
            "Epoch 210/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8545 - accuracy: 0.8368 - val_loss: 1.0620 - val_accuracy: 0.7639\n",
            "Epoch 211/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8725 - accuracy: 0.8368 - val_loss: 1.0643 - val_accuracy: 0.7292\n",
            "Epoch 212/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8631 - accuracy: 0.8351 - val_loss: 1.0712 - val_accuracy: 0.7153\n",
            "Epoch 213/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8612 - accuracy: 0.8351 - val_loss: 1.0813 - val_accuracy: 0.7083\n",
            "Epoch 214/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8660 - accuracy: 0.8542 - val_loss: 1.0719 - val_accuracy: 0.7569\n",
            "Epoch 215/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8513 - accuracy: 0.8490 - val_loss: 1.0879 - val_accuracy: 0.7361\n",
            "Epoch 216/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8477 - accuracy: 0.8628 - val_loss: 1.0420 - val_accuracy: 0.7639\n",
            "Epoch 217/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8374 - accuracy: 0.8333 - val_loss: 1.0583 - val_accuracy: 0.7431\n",
            "Epoch 218/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8464 - accuracy: 0.8403 - val_loss: 1.0526 - val_accuracy: 0.7639\n",
            "Epoch 219/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8517 - accuracy: 0.8542 - val_loss: 1.0511 - val_accuracy: 0.7431\n",
            "Epoch 220/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8443 - accuracy: 0.8385 - val_loss: 1.0631 - val_accuracy: 0.7708\n",
            "Epoch 221/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8348 - accuracy: 0.8542 - val_loss: 1.0503 - val_accuracy: 0.7708\n",
            "Epoch 222/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8291 - accuracy: 0.8611 - val_loss: 1.0590 - val_accuracy: 0.7639\n",
            "Epoch 223/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8442 - accuracy: 0.8472 - val_loss: 1.0609 - val_accuracy: 0.7500\n",
            "Epoch 224/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8483 - accuracy: 0.8490 - val_loss: 1.0664 - val_accuracy: 0.7361\n",
            "Epoch 225/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.8319 - accuracy: 0.8698 - val_loss: 1.0498 - val_accuracy: 0.7569\n",
            "Epoch 226/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8297 - accuracy: 0.8507 - val_loss: 1.0508 - val_accuracy: 0.7569\n",
            "Epoch 227/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8491 - accuracy: 0.8385 - val_loss: 1.0598 - val_accuracy: 0.7500\n",
            "Epoch 228/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8309 - accuracy: 0.8646 - val_loss: 1.0471 - val_accuracy: 0.7639\n",
            "Epoch 229/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8383 - accuracy: 0.8559 - val_loss: 1.0492 - val_accuracy: 0.7222\n",
            "Epoch 230/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8429 - accuracy: 0.8576 - val_loss: 1.0630 - val_accuracy: 0.7361\n",
            "Epoch 231/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8314 - accuracy: 0.8646 - val_loss: 1.0450 - val_accuracy: 0.7431\n",
            "Epoch 232/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8386 - accuracy: 0.8559 - val_loss: 1.0496 - val_accuracy: 0.7361\n",
            "Epoch 233/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8021 - accuracy: 0.8750 - val_loss: 1.0306 - val_accuracy: 0.7500\n",
            "Epoch 234/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8184 - accuracy: 0.8698 - val_loss: 1.0343 - val_accuracy: 0.7639\n",
            "Epoch 235/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8154 - accuracy: 0.8785 - val_loss: 1.0370 - val_accuracy: 0.7500\n",
            "Epoch 236/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8157 - accuracy: 0.8611 - val_loss: 1.0517 - val_accuracy: 0.7500\n",
            "Epoch 237/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8134 - accuracy: 0.8559 - val_loss: 1.0465 - val_accuracy: 0.7708\n",
            "Epoch 238/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8156 - accuracy: 0.8681 - val_loss: 1.0440 - val_accuracy: 0.7639\n",
            "Epoch 239/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8174 - accuracy: 0.8681 - val_loss: 1.0529 - val_accuracy: 0.7361\n",
            "Epoch 240/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.8263 - accuracy: 0.8576 - val_loss: 1.0416 - val_accuracy: 0.7292\n",
            "Epoch 241/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8506 - accuracy: 0.8333 - val_loss: 1.0464 - val_accuracy: 0.7500\n",
            "Epoch 242/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8380 - accuracy: 0.8802 - val_loss: 1.0524 - val_accuracy: 0.7431\n",
            "Epoch 243/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8226 - accuracy: 0.8646 - val_loss: 1.0482 - val_accuracy: 0.7639\n",
            "Epoch 244/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8152 - accuracy: 0.8854 - val_loss: 1.0404 - val_accuracy: 0.7500\n",
            "Epoch 245/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8086 - accuracy: 0.8802 - val_loss: 1.0580 - val_accuracy: 0.7431\n",
            "Epoch 246/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8018 - accuracy: 0.8819 - val_loss: 1.0607 - val_accuracy: 0.7431\n",
            "Epoch 247/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8126 - accuracy: 0.8559 - val_loss: 1.0495 - val_accuracy: 0.7500\n",
            "Epoch 248/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7943 - accuracy: 0.8906 - val_loss: 1.0619 - val_accuracy: 0.7361\n",
            "Epoch 249/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8074 - accuracy: 0.8715 - val_loss: 1.0589 - val_accuracy: 0.7431\n",
            "Epoch 250/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.8149 - accuracy: 0.8663 - val_loss: 1.0434 - val_accuracy: 0.7917\n",
            "Epoch 251/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7955 - accuracy: 0.8646 - val_loss: 1.0642 - val_accuracy: 0.7361\n",
            "Epoch 252/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8010 - accuracy: 0.8837 - val_loss: 1.0495 - val_accuracy: 0.7639\n",
            "Epoch 253/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8002 - accuracy: 0.8906 - val_loss: 1.0537 - val_accuracy: 0.7361\n",
            "Epoch 254/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7939 - accuracy: 0.9010 - val_loss: 1.0389 - val_accuracy: 0.7569\n",
            "Epoch 255/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7755 - accuracy: 0.8889 - val_loss: 1.0550 - val_accuracy: 0.7639\n",
            "Epoch 256/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7912 - accuracy: 0.8837 - val_loss: 1.0403 - val_accuracy: 0.7361\n",
            "Epoch 257/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7879 - accuracy: 0.8906 - val_loss: 1.0538 - val_accuracy: 0.7431\n",
            "Epoch 258/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7948 - accuracy: 0.8698 - val_loss: 1.0461 - val_accuracy: 0.7500\n",
            "Epoch 259/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7781 - accuracy: 0.8819 - val_loss: 1.0379 - val_accuracy: 0.7292\n",
            "Epoch 260/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.8016 - accuracy: 0.8681 - val_loss: 1.0482 - val_accuracy: 0.7292\n",
            "Epoch 261/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7739 - accuracy: 0.8837 - val_loss: 1.0542 - val_accuracy: 0.7431\n",
            "Epoch 262/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7659 - accuracy: 0.8906 - val_loss: 1.0505 - val_accuracy: 0.7431\n",
            "Epoch 263/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7842 - accuracy: 0.8958 - val_loss: 1.0361 - val_accuracy: 0.7500\n",
            "Epoch 264/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7849 - accuracy: 0.8941 - val_loss: 1.0469 - val_accuracy: 0.7292\n",
            "Epoch 265/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7936 - accuracy: 0.8924 - val_loss: 1.0357 - val_accuracy: 0.7361\n",
            "Epoch 266/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7712 - accuracy: 0.8819 - val_loss: 1.0516 - val_accuracy: 0.7569\n",
            "Epoch 267/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7813 - accuracy: 0.8785 - val_loss: 1.0526 - val_accuracy: 0.7500\n",
            "Epoch 268/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7726 - accuracy: 0.8941 - val_loss: 1.0437 - val_accuracy: 0.7431\n",
            "Epoch 269/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7804 - accuracy: 0.8750 - val_loss: 1.0203 - val_accuracy: 0.7569\n",
            "Epoch 270/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7927 - accuracy: 0.8698 - val_loss: 1.0392 - val_accuracy: 0.7708\n",
            "Epoch 271/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7695 - accuracy: 0.8958 - val_loss: 1.0359 - val_accuracy: 0.7569\n",
            "Epoch 272/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7606 - accuracy: 0.8906 - val_loss: 1.0635 - val_accuracy: 0.7153\n",
            "Epoch 273/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7897 - accuracy: 0.8819 - val_loss: 1.0325 - val_accuracy: 0.7361\n",
            "Epoch 274/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7647 - accuracy: 0.8906 - val_loss: 1.0380 - val_accuracy: 0.7500\n",
            "Epoch 275/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7695 - accuracy: 0.8941 - val_loss: 1.0210 - val_accuracy: 0.7708\n",
            "Epoch 276/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7743 - accuracy: 0.8941 - val_loss: 1.0252 - val_accuracy: 0.7569\n",
            "Epoch 277/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7611 - accuracy: 0.8958 - val_loss: 1.0270 - val_accuracy: 0.7569\n",
            "Epoch 278/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7639 - accuracy: 0.8941 - val_loss: 1.0300 - val_accuracy: 0.7500\n",
            "Epoch 279/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7650 - accuracy: 0.8906 - val_loss: 1.0209 - val_accuracy: 0.7569\n",
            "Epoch 280/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7684 - accuracy: 0.8924 - val_loss: 1.0165 - val_accuracy: 0.7917\n",
            "Epoch 281/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7622 - accuracy: 0.9149 - val_loss: 1.0358 - val_accuracy: 0.7639\n",
            "Epoch 282/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7549 - accuracy: 0.8819 - val_loss: 1.0275 - val_accuracy: 0.7778\n",
            "Epoch 283/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7694 - accuracy: 0.8906 - val_loss: 1.0323 - val_accuracy: 0.7708\n",
            "Epoch 284/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7642 - accuracy: 0.9028 - val_loss: 1.0473 - val_accuracy: 0.7500\n",
            "Epoch 285/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7773 - accuracy: 0.8733 - val_loss: 1.0218 - val_accuracy: 0.7361\n",
            "Epoch 286/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7613 - accuracy: 0.8837 - val_loss: 1.0150 - val_accuracy: 0.7639\n",
            "Epoch 287/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7434 - accuracy: 0.9028 - val_loss: 1.0534 - val_accuracy: 0.7222\n",
            "Epoch 288/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7489 - accuracy: 0.9097 - val_loss: 1.0340 - val_accuracy: 0.7431\n",
            "Epoch 289/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7686 - accuracy: 0.8906 - val_loss: 1.0387 - val_accuracy: 0.7361\n",
            "Epoch 290/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7480 - accuracy: 0.9010 - val_loss: 1.0453 - val_accuracy: 0.7361\n",
            "Epoch 291/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7611 - accuracy: 0.8785 - val_loss: 1.0380 - val_accuracy: 0.7500\n",
            "Epoch 292/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.7490 - accuracy: 0.8854 - val_loss: 1.0225 - val_accuracy: 0.7361\n",
            "Epoch 293/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7462 - accuracy: 0.8889 - val_loss: 1.0172 - val_accuracy: 0.7500\n",
            "Epoch 294/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7419 - accuracy: 0.9010 - val_loss: 1.0207 - val_accuracy: 0.7569\n",
            "Epoch 295/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7561 - accuracy: 0.8976 - val_loss: 1.0072 - val_accuracy: 0.7500\n",
            "Epoch 296/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7705 - accuracy: 0.8837 - val_loss: 1.0180 - val_accuracy: 0.7431\n",
            "Epoch 297/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7532 - accuracy: 0.9045 - val_loss: 1.0092 - val_accuracy: 0.7500\n",
            "Epoch 298/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7386 - accuracy: 0.8976 - val_loss: 1.0330 - val_accuracy: 0.7361\n",
            "Epoch 299/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7277 - accuracy: 0.9219 - val_loss: 1.0190 - val_accuracy: 0.7431\n",
            "Epoch 300/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7396 - accuracy: 0.9115 - val_loss: 1.0131 - val_accuracy: 0.7708\n",
            "Epoch 301/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.7447 - accuracy: 0.9080 - val_loss: 1.0163 - val_accuracy: 0.7569\n",
            "Epoch 302/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7420 - accuracy: 0.9132 - val_loss: 1.0170 - val_accuracy: 0.7431\n",
            "Epoch 303/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7299 - accuracy: 0.9167 - val_loss: 1.0287 - val_accuracy: 0.7639\n",
            "Epoch 304/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7376 - accuracy: 0.9045 - val_loss: 1.0330 - val_accuracy: 0.7500\n",
            "Epoch 305/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7322 - accuracy: 0.8958 - val_loss: 1.0285 - val_accuracy: 0.7431\n",
            "Epoch 306/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7322 - accuracy: 0.9201 - val_loss: 1.0192 - val_accuracy: 0.7639\n",
            "Epoch 307/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7207 - accuracy: 0.9306 - val_loss: 1.0166 - val_accuracy: 0.7569\n",
            "Epoch 308/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.7388 - accuracy: 0.9115 - val_loss: 1.0204 - val_accuracy: 0.7847\n",
            "Epoch 309/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7181 - accuracy: 0.9271 - val_loss: 1.0370 - val_accuracy: 0.7500\n",
            "Epoch 310/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7232 - accuracy: 0.9306 - val_loss: 1.0428 - val_accuracy: 0.7569\n",
            "Epoch 311/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7075 - accuracy: 0.9323 - val_loss: 1.0123 - val_accuracy: 0.7778\n",
            "Epoch 312/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7335 - accuracy: 0.9167 - val_loss: 1.0257 - val_accuracy: 0.7569\n",
            "Epoch 313/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7182 - accuracy: 0.9028 - val_loss: 1.0236 - val_accuracy: 0.7639\n",
            "Epoch 314/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7247 - accuracy: 0.9097 - val_loss: 1.0274 - val_accuracy: 0.7500\n",
            "Epoch 315/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7195 - accuracy: 0.9010 - val_loss: 1.0404 - val_accuracy: 0.7569\n",
            "Epoch 316/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7262 - accuracy: 0.9045 - val_loss: 1.0206 - val_accuracy: 0.7778\n",
            "Epoch 317/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7324 - accuracy: 0.8993 - val_loss: 1.0234 - val_accuracy: 0.7778\n",
            "Epoch 318/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7073 - accuracy: 0.9236 - val_loss: 1.0078 - val_accuracy: 0.7917\n",
            "Epoch 319/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7226 - accuracy: 0.9097 - val_loss: 1.0157 - val_accuracy: 0.7639\n",
            "Epoch 320/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7151 - accuracy: 0.9149 - val_loss: 1.0132 - val_accuracy: 0.7500\n",
            "Epoch 321/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7260 - accuracy: 0.9062 - val_loss: 1.0006 - val_accuracy: 0.7708\n",
            "Epoch 322/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7179 - accuracy: 0.9358 - val_loss: 1.0193 - val_accuracy: 0.7431\n",
            "Epoch 323/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6977 - accuracy: 0.9219 - val_loss: 1.0100 - val_accuracy: 0.7500\n",
            "Epoch 324/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7085 - accuracy: 0.9201 - val_loss: 1.0236 - val_accuracy: 0.7778\n",
            "Epoch 325/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7255 - accuracy: 0.9149 - val_loss: 1.0319 - val_accuracy: 0.7361\n",
            "Epoch 326/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7064 - accuracy: 0.9358 - val_loss: 1.0151 - val_accuracy: 0.7639\n",
            "Epoch 327/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.7095 - accuracy: 0.9045 - val_loss: 1.0308 - val_accuracy: 0.7500\n",
            "Epoch 328/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7076 - accuracy: 0.9236 - val_loss: 1.0162 - val_accuracy: 0.7569\n",
            "Epoch 329/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7051 - accuracy: 0.9236 - val_loss: 1.0138 - val_accuracy: 0.7708\n",
            "Epoch 330/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7222 - accuracy: 0.9080 - val_loss: 1.0055 - val_accuracy: 0.7708\n",
            "Epoch 331/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.7073 - accuracy: 0.9080 - val_loss: 1.0127 - val_accuracy: 0.7431\n",
            "Epoch 332/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7017 - accuracy: 0.9271 - val_loss: 1.0085 - val_accuracy: 0.7500\n",
            "Epoch 333/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7233 - accuracy: 0.9115 - val_loss: 1.0205 - val_accuracy: 0.7431\n",
            "Epoch 334/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6817 - accuracy: 0.9375 - val_loss: 1.0134 - val_accuracy: 0.7431\n",
            "Epoch 335/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6966 - accuracy: 0.9253 - val_loss: 1.0115 - val_accuracy: 0.7639\n",
            "Epoch 336/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7071 - accuracy: 0.9253 - val_loss: 1.0265 - val_accuracy: 0.7708\n",
            "Epoch 337/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7123 - accuracy: 0.9184 - val_loss: 1.0187 - val_accuracy: 0.7639\n",
            "Epoch 338/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6996 - accuracy: 0.9271 - val_loss: 1.0194 - val_accuracy: 0.7569\n",
            "Epoch 339/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6975 - accuracy: 0.9271 - val_loss: 1.0037 - val_accuracy: 0.7708\n",
            "Epoch 340/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7009 - accuracy: 0.9184 - val_loss: 1.0131 - val_accuracy: 0.7639\n",
            "Epoch 341/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.6987 - accuracy: 0.9167 - val_loss: 1.0118 - val_accuracy: 0.7778\n",
            "Epoch 342/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6889 - accuracy: 0.9375 - val_loss: 1.0293 - val_accuracy: 0.7847\n",
            "Epoch 343/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6777 - accuracy: 0.9358 - val_loss: 1.0022 - val_accuracy: 0.7708\n",
            "Epoch 344/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6926 - accuracy: 0.9219 - val_loss: 0.9968 - val_accuracy: 0.7847\n",
            "Epoch 345/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6934 - accuracy: 0.9288 - val_loss: 1.0234 - val_accuracy: 0.7639\n",
            "Epoch 346/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6845 - accuracy: 0.9375 - val_loss: 1.0062 - val_accuracy: 0.7847\n",
            "Epoch 347/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6912 - accuracy: 0.9358 - val_loss: 1.0026 - val_accuracy: 0.7778\n",
            "Epoch 348/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6817 - accuracy: 0.9392 - val_loss: 0.9876 - val_accuracy: 0.8056\n",
            "Epoch 349/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6796 - accuracy: 0.9253 - val_loss: 1.0258 - val_accuracy: 0.7847\n",
            "Epoch 350/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6684 - accuracy: 0.9531 - val_loss: 1.0147 - val_accuracy: 0.7639\n",
            "Epoch 351/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6847 - accuracy: 0.9323 - val_loss: 1.0013 - val_accuracy: 0.7778\n",
            "Epoch 352/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6915 - accuracy: 0.9323 - val_loss: 1.0177 - val_accuracy: 0.7708\n",
            "Epoch 353/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7024 - accuracy: 0.9236 - val_loss: 1.0127 - val_accuracy: 0.7569\n",
            "Epoch 354/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6780 - accuracy: 0.9462 - val_loss: 1.0011 - val_accuracy: 0.7778\n",
            "Epoch 355/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6755 - accuracy: 0.9323 - val_loss: 0.9861 - val_accuracy: 0.7847\n",
            "Epoch 356/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6769 - accuracy: 0.9271 - val_loss: 0.9961 - val_accuracy: 0.7778\n",
            "Epoch 357/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6707 - accuracy: 0.9410 - val_loss: 1.0041 - val_accuracy: 0.7778\n",
            "Epoch 358/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6727 - accuracy: 0.9375 - val_loss: 1.0136 - val_accuracy: 0.7778\n",
            "Epoch 359/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6672 - accuracy: 0.9358 - val_loss: 1.0122 - val_accuracy: 0.7361\n",
            "Epoch 360/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6701 - accuracy: 0.9236 - val_loss: 1.0115 - val_accuracy: 0.7500\n",
            "Epoch 361/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6842 - accuracy: 0.9427 - val_loss: 1.0027 - val_accuracy: 0.7708\n",
            "Epoch 362/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6673 - accuracy: 0.9392 - val_loss: 1.0080 - val_accuracy: 0.7708\n",
            "Epoch 363/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6702 - accuracy: 0.9427 - val_loss: 1.0172 - val_accuracy: 0.7569\n",
            "Epoch 364/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6749 - accuracy: 0.9323 - val_loss: 1.0142 - val_accuracy: 0.7708\n",
            "Epoch 365/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6651 - accuracy: 0.9497 - val_loss: 1.0296 - val_accuracy: 0.7639\n",
            "Epoch 366/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6665 - accuracy: 0.9497 - val_loss: 1.0246 - val_accuracy: 0.7569\n",
            "Epoch 367/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6706 - accuracy: 0.9358 - val_loss: 1.0050 - val_accuracy: 0.7639\n",
            "Epoch 368/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6619 - accuracy: 0.9410 - val_loss: 1.0256 - val_accuracy: 0.7500\n",
            "Epoch 369/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6588 - accuracy: 0.9514 - val_loss: 1.0061 - val_accuracy: 0.7847\n",
            "Epoch 370/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6774 - accuracy: 0.9444 - val_loss: 0.9888 - val_accuracy: 0.7708\n",
            "Epoch 371/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6618 - accuracy: 0.9444 - val_loss: 0.9993 - val_accuracy: 0.7708\n",
            "Epoch 372/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6529 - accuracy: 0.9549 - val_loss: 0.9983 - val_accuracy: 0.7986\n",
            "Epoch 373/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6640 - accuracy: 0.9410 - val_loss: 1.0109 - val_accuracy: 0.7708\n",
            "Epoch 374/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6756 - accuracy: 0.9323 - val_loss: 1.0061 - val_accuracy: 0.7639\n",
            "Epoch 375/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6645 - accuracy: 0.9479 - val_loss: 1.0242 - val_accuracy: 0.7500\n",
            "Epoch 376/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6679 - accuracy: 0.9410 - val_loss: 1.0247 - val_accuracy: 0.7500\n",
            "Epoch 377/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6637 - accuracy: 0.9497 - val_loss: 1.0046 - val_accuracy: 0.7639\n",
            "Epoch 378/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6531 - accuracy: 0.9601 - val_loss: 1.0018 - val_accuracy: 0.7639\n",
            "Epoch 379/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6372 - accuracy: 0.9392 - val_loss: 1.0106 - val_accuracy: 0.7708\n",
            "Epoch 380/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6459 - accuracy: 0.9479 - val_loss: 1.0143 - val_accuracy: 0.7778\n",
            "Epoch 381/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6503 - accuracy: 0.9497 - val_loss: 1.0036 - val_accuracy: 0.7639\n",
            "Epoch 382/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6390 - accuracy: 0.9462 - val_loss: 1.0135 - val_accuracy: 0.7569\n",
            "Epoch 383/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6578 - accuracy: 0.9618 - val_loss: 1.0206 - val_accuracy: 0.7431\n",
            "Epoch 384/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6544 - accuracy: 0.9444 - val_loss: 1.0019 - val_accuracy: 0.7500\n",
            "Epoch 385/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6622 - accuracy: 0.9358 - val_loss: 1.0032 - val_accuracy: 0.7361\n",
            "Epoch 386/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6683 - accuracy: 0.9497 - val_loss: 0.9993 - val_accuracy: 0.7500\n",
            "Epoch 387/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6294 - accuracy: 0.9531 - val_loss: 0.9966 - val_accuracy: 0.7708\n",
            "Epoch 388/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6677 - accuracy: 0.9462 - val_loss: 0.9977 - val_accuracy: 0.7847\n",
            "Epoch 389/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6455 - accuracy: 0.9566 - val_loss: 1.0011 - val_accuracy: 0.7708\n",
            "Epoch 390/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6600 - accuracy: 0.9549 - val_loss: 1.0070 - val_accuracy: 0.7917\n",
            "Epoch 391/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6372 - accuracy: 0.9531 - val_loss: 1.0125 - val_accuracy: 0.7500\n",
            "Epoch 392/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6601 - accuracy: 0.9375 - val_loss: 0.9971 - val_accuracy: 0.7986\n",
            "Epoch 393/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6466 - accuracy: 0.9497 - val_loss: 1.0001 - val_accuracy: 0.8125\n",
            "Epoch 394/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6414 - accuracy: 0.9514 - val_loss: 1.0077 - val_accuracy: 0.7778\n",
            "Epoch 395/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6325 - accuracy: 0.9635 - val_loss: 0.9996 - val_accuracy: 0.7917\n",
            "Epoch 396/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6537 - accuracy: 0.9427 - val_loss: 0.9954 - val_accuracy: 0.7917\n",
            "Epoch 397/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6505 - accuracy: 0.9462 - val_loss: 0.9958 - val_accuracy: 0.7917\n",
            "Epoch 398/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6452 - accuracy: 0.9497 - val_loss: 0.9954 - val_accuracy: 0.7639\n",
            "Epoch 399/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6299 - accuracy: 0.9497 - val_loss: 1.0139 - val_accuracy: 0.7569\n",
            "Epoch 400/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6256 - accuracy: 0.9531 - val_loss: 1.0058 - val_accuracy: 0.7639\n",
            "Epoch 401/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6437 - accuracy: 0.9514 - val_loss: 1.0102 - val_accuracy: 0.7569\n",
            "Epoch 402/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6415 - accuracy: 0.9583 - val_loss: 1.0174 - val_accuracy: 0.7639\n",
            "Epoch 403/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6459 - accuracy: 0.9549 - val_loss: 1.0070 - val_accuracy: 0.7708\n",
            "Epoch 404/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6387 - accuracy: 0.9497 - val_loss: 1.0124 - val_accuracy: 0.7639\n",
            "Epoch 405/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6222 - accuracy: 0.9705 - val_loss: 1.0103 - val_accuracy: 0.7778\n",
            "Epoch 406/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6356 - accuracy: 0.9566 - val_loss: 0.9921 - val_accuracy: 0.7917\n",
            "Epoch 407/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6369 - accuracy: 0.9479 - val_loss: 1.0016 - val_accuracy: 0.7639\n",
            "Epoch 408/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6369 - accuracy: 0.9323 - val_loss: 0.9902 - val_accuracy: 0.7708\n",
            "Epoch 409/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6339 - accuracy: 0.9531 - val_loss: 0.9892 - val_accuracy: 0.7986\n",
            "Epoch 410/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6207 - accuracy: 0.9601 - val_loss: 1.0122 - val_accuracy: 0.7986\n",
            "Epoch 411/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6248 - accuracy: 0.9618 - val_loss: 0.9906 - val_accuracy: 0.7778\n",
            "Epoch 412/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6455 - accuracy: 0.9531 - val_loss: 0.9961 - val_accuracy: 0.7847\n",
            "Epoch 413/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6276 - accuracy: 0.9462 - val_loss: 0.9766 - val_accuracy: 0.8056\n",
            "Epoch 414/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6289 - accuracy: 0.9497 - val_loss: 0.9762 - val_accuracy: 0.7917\n",
            "Epoch 415/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6265 - accuracy: 0.9583 - val_loss: 1.0095 - val_accuracy: 0.7708\n",
            "Epoch 416/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6253 - accuracy: 0.9653 - val_loss: 0.9952 - val_accuracy: 0.7847\n",
            "Epoch 417/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6065 - accuracy: 0.9635 - val_loss: 1.0010 - val_accuracy: 0.7708\n",
            "Epoch 418/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6130 - accuracy: 0.9688 - val_loss: 0.9846 - val_accuracy: 0.7917\n",
            "Epoch 419/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6206 - accuracy: 0.9479 - val_loss: 0.9903 - val_accuracy: 0.7917\n",
            "Epoch 420/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6426 - accuracy: 0.9375 - val_loss: 0.9962 - val_accuracy: 0.7986\n",
            "Epoch 421/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6054 - accuracy: 0.9688 - val_loss: 0.9870 - val_accuracy: 0.7778\n",
            "Epoch 422/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6174 - accuracy: 0.9566 - val_loss: 0.9905 - val_accuracy: 0.7778\n",
            "Epoch 423/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6098 - accuracy: 0.9566 - val_loss: 0.9909 - val_accuracy: 0.7847\n",
            "Epoch 424/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6220 - accuracy: 0.9549 - val_loss: 1.0133 - val_accuracy: 0.7708\n",
            "Epoch 425/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6301 - accuracy: 0.9566 - val_loss: 0.9839 - val_accuracy: 0.7917\n",
            "Epoch 426/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6195 - accuracy: 0.9549 - val_loss: 0.9957 - val_accuracy: 0.7917\n",
            "Epoch 427/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6216 - accuracy: 0.9618 - val_loss: 1.0154 - val_accuracy: 0.7639\n",
            "Epoch 428/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6182 - accuracy: 0.9653 - val_loss: 0.9996 - val_accuracy: 0.7708\n",
            "Epoch 429/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6259 - accuracy: 0.9549 - val_loss: 0.9944 - val_accuracy: 0.7778\n",
            "Epoch 430/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6104 - accuracy: 0.9583 - val_loss: 1.0043 - val_accuracy: 0.7917\n",
            "Epoch 431/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6201 - accuracy: 0.9688 - val_loss: 0.9736 - val_accuracy: 0.7986\n",
            "Epoch 432/700\n",
            "9/9 [==============================] - 1s 92ms/step - loss: 0.6037 - accuracy: 0.9618 - val_loss: 0.9947 - val_accuracy: 0.7847\n",
            "Epoch 433/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6261 - accuracy: 0.9549 - val_loss: 0.9887 - val_accuracy: 0.7917\n",
            "Epoch 434/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5983 - accuracy: 0.9722 - val_loss: 0.9876 - val_accuracy: 0.7708\n",
            "Epoch 435/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6151 - accuracy: 0.9670 - val_loss: 0.9865 - val_accuracy: 0.7847\n",
            "Epoch 436/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6170 - accuracy: 0.9601 - val_loss: 0.9804 - val_accuracy: 0.7708\n",
            "Epoch 437/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6249 - accuracy: 0.9583 - val_loss: 0.9868 - val_accuracy: 0.7986\n",
            "Epoch 438/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6088 - accuracy: 0.9653 - val_loss: 0.9841 - val_accuracy: 0.7778\n",
            "Epoch 439/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6118 - accuracy: 0.9688 - val_loss: 0.9978 - val_accuracy: 0.7778\n",
            "Epoch 440/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6174 - accuracy: 0.9635 - val_loss: 0.9844 - val_accuracy: 0.7847\n",
            "Epoch 441/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.6114 - accuracy: 0.9583 - val_loss: 0.9851 - val_accuracy: 0.7917\n",
            "Epoch 442/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6057 - accuracy: 0.9740 - val_loss: 0.9823 - val_accuracy: 0.7917\n",
            "Epoch 443/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5894 - accuracy: 0.9757 - val_loss: 0.9877 - val_accuracy: 0.7917\n",
            "Epoch 444/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5931 - accuracy: 0.9792 - val_loss: 0.9846 - val_accuracy: 0.7708\n",
            "Epoch 445/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6135 - accuracy: 0.9618 - val_loss: 0.9752 - val_accuracy: 0.7986\n",
            "Epoch 446/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5949 - accuracy: 0.9705 - val_loss: 0.9878 - val_accuracy: 0.7917\n",
            "Epoch 447/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5985 - accuracy: 0.9635 - val_loss: 0.9909 - val_accuracy: 0.7917\n",
            "Epoch 448/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6029 - accuracy: 0.9705 - val_loss: 0.9766 - val_accuracy: 0.7986\n",
            "Epoch 449/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6002 - accuracy: 0.9462 - val_loss: 0.9883 - val_accuracy: 0.7986\n",
            "Epoch 450/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6013 - accuracy: 0.9601 - val_loss: 0.9942 - val_accuracy: 0.8056\n",
            "Epoch 451/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6018 - accuracy: 0.9601 - val_loss: 0.9983 - val_accuracy: 0.8056\n",
            "Epoch 452/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6028 - accuracy: 0.9618 - val_loss: 0.9965 - val_accuracy: 0.7986\n",
            "Epoch 453/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6118 - accuracy: 0.9497 - val_loss: 0.9983 - val_accuracy: 0.7986\n",
            "Epoch 454/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5950 - accuracy: 0.9774 - val_loss: 0.9864 - val_accuracy: 0.8194\n",
            "Epoch 455/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6008 - accuracy: 0.9653 - val_loss: 0.9867 - val_accuracy: 0.8125\n",
            "Epoch 456/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5950 - accuracy: 0.9688 - val_loss: 0.9870 - val_accuracy: 0.8125\n",
            "Epoch 457/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5911 - accuracy: 0.9757 - val_loss: 0.9847 - val_accuracy: 0.8056\n",
            "Epoch 458/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5935 - accuracy: 0.9635 - val_loss: 1.0024 - val_accuracy: 0.7847\n",
            "Epoch 459/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5972 - accuracy: 0.9740 - val_loss: 1.0068 - val_accuracy: 0.7778\n",
            "Epoch 460/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5811 - accuracy: 0.9757 - val_loss: 1.0019 - val_accuracy: 0.7708\n",
            "Epoch 461/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5950 - accuracy: 0.9688 - val_loss: 0.9920 - val_accuracy: 0.7847\n",
            "Epoch 462/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5972 - accuracy: 0.9635 - val_loss: 0.9774 - val_accuracy: 0.7986\n",
            "Epoch 463/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5845 - accuracy: 0.9705 - val_loss: 0.9827 - val_accuracy: 0.7986\n",
            "Epoch 464/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5977 - accuracy: 0.9601 - val_loss: 1.0013 - val_accuracy: 0.7708\n",
            "Epoch 465/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6040 - accuracy: 0.9618 - val_loss: 0.9911 - val_accuracy: 0.7847\n",
            "Epoch 466/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5936 - accuracy: 0.9705 - val_loss: 0.9764 - val_accuracy: 0.7847\n",
            "Epoch 467/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5724 - accuracy: 0.9688 - val_loss: 0.9862 - val_accuracy: 0.7986\n",
            "Epoch 468/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5825 - accuracy: 0.9757 - val_loss: 0.9848 - val_accuracy: 0.7986\n",
            "Epoch 469/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5940 - accuracy: 0.9705 - val_loss: 0.9936 - val_accuracy: 0.7847\n",
            "Epoch 470/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5840 - accuracy: 0.9705 - val_loss: 0.9759 - val_accuracy: 0.7639\n",
            "Epoch 471/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5877 - accuracy: 0.9653 - val_loss: 0.9876 - val_accuracy: 0.7569\n",
            "Epoch 472/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5699 - accuracy: 0.9844 - val_loss: 1.0003 - val_accuracy: 0.7778\n",
            "Epoch 473/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5837 - accuracy: 0.9653 - val_loss: 0.9793 - val_accuracy: 0.7778\n",
            "Epoch 474/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5900 - accuracy: 0.9670 - val_loss: 0.9991 - val_accuracy: 0.7639\n",
            "Epoch 475/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5655 - accuracy: 0.9826 - val_loss: 0.9862 - val_accuracy: 0.7917\n",
            "Epoch 476/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5845 - accuracy: 0.9705 - val_loss: 0.9677 - val_accuracy: 0.7986\n",
            "Epoch 477/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5726 - accuracy: 0.9774 - val_loss: 0.9894 - val_accuracy: 0.7847\n",
            "Epoch 478/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5841 - accuracy: 0.9740 - val_loss: 0.9848 - val_accuracy: 0.7917\n",
            "Epoch 479/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5750 - accuracy: 0.9809 - val_loss: 1.0003 - val_accuracy: 0.7847\n",
            "Epoch 480/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5879 - accuracy: 0.9722 - val_loss: 0.9984 - val_accuracy: 0.7917\n",
            "Epoch 481/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5680 - accuracy: 0.9740 - val_loss: 1.0003 - val_accuracy: 0.8056\n",
            "Epoch 482/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5808 - accuracy: 0.9635 - val_loss: 0.9815 - val_accuracy: 0.8056\n",
            "Epoch 483/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5703 - accuracy: 0.9757 - val_loss: 0.9808 - val_accuracy: 0.7986\n",
            "Epoch 484/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5865 - accuracy: 0.9740 - val_loss: 1.0050 - val_accuracy: 0.7569\n",
            "Epoch 485/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5729 - accuracy: 0.9635 - val_loss: 0.9935 - val_accuracy: 0.7778\n",
            "Epoch 486/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5865 - accuracy: 0.9757 - val_loss: 0.9945 - val_accuracy: 0.7708\n",
            "Epoch 487/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5987 - accuracy: 0.9740 - val_loss: 0.9768 - val_accuracy: 0.7986\n",
            "Epoch 488/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5700 - accuracy: 0.9722 - val_loss: 0.9856 - val_accuracy: 0.7847\n",
            "Epoch 489/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5960 - accuracy: 0.9792 - val_loss: 0.9891 - val_accuracy: 0.7847\n",
            "Epoch 490/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5819 - accuracy: 0.9878 - val_loss: 0.9961 - val_accuracy: 0.7917\n",
            "Epoch 491/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5621 - accuracy: 0.9722 - val_loss: 0.9938 - val_accuracy: 0.7917\n",
            "Epoch 492/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5790 - accuracy: 0.9722 - val_loss: 0.9794 - val_accuracy: 0.7708\n",
            "Epoch 493/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5858 - accuracy: 0.9722 - val_loss: 0.9831 - val_accuracy: 0.7778\n",
            "Epoch 494/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5597 - accuracy: 0.9878 - val_loss: 0.9794 - val_accuracy: 0.7986\n",
            "Epoch 495/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5759 - accuracy: 0.9740 - val_loss: 0.9641 - val_accuracy: 0.7986\n",
            "Epoch 496/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5536 - accuracy: 0.9809 - val_loss: 0.9735 - val_accuracy: 0.8056\n",
            "Epoch 497/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5780 - accuracy: 0.9757 - val_loss: 0.9769 - val_accuracy: 0.7847\n",
            "Epoch 498/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5544 - accuracy: 0.9705 - val_loss: 0.9823 - val_accuracy: 0.7847\n",
            "Epoch 499/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5785 - accuracy: 0.9688 - val_loss: 1.0055 - val_accuracy: 0.7778\n",
            "Epoch 500/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5626 - accuracy: 0.9809 - val_loss: 0.9842 - val_accuracy: 0.7986\n",
            "Epoch 501/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5630 - accuracy: 0.9757 - val_loss: 0.9836 - val_accuracy: 0.7778\n",
            "Epoch 502/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5648 - accuracy: 0.9757 - val_loss: 0.9707 - val_accuracy: 0.7778\n",
            "Epoch 503/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5566 - accuracy: 0.9809 - val_loss: 0.9934 - val_accuracy: 0.7917\n",
            "Epoch 504/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5676 - accuracy: 0.9740 - val_loss: 0.9860 - val_accuracy: 0.8056\n",
            "Epoch 505/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5733 - accuracy: 0.9705 - val_loss: 0.9825 - val_accuracy: 0.8056\n",
            "Epoch 506/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5551 - accuracy: 0.9809 - val_loss: 0.9861 - val_accuracy: 0.8056\n",
            "Epoch 507/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5684 - accuracy: 0.9688 - val_loss: 0.9704 - val_accuracy: 0.8125\n",
            "Epoch 508/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5525 - accuracy: 0.9774 - val_loss: 0.9686 - val_accuracy: 0.8056\n",
            "Epoch 509/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5548 - accuracy: 0.9844 - val_loss: 0.9629 - val_accuracy: 0.8125\n",
            "Epoch 510/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5606 - accuracy: 0.9792 - val_loss: 0.9818 - val_accuracy: 0.7917\n",
            "Epoch 511/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5616 - accuracy: 0.9774 - val_loss: 0.9714 - val_accuracy: 0.7917\n",
            "Epoch 512/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5690 - accuracy: 0.9653 - val_loss: 0.9737 - val_accuracy: 0.8264\n",
            "Epoch 513/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5485 - accuracy: 0.9792 - val_loss: 0.9843 - val_accuracy: 0.8056\n",
            "Epoch 514/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5391 - accuracy: 0.9861 - val_loss: 0.9902 - val_accuracy: 0.8056\n",
            "Epoch 515/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5453 - accuracy: 0.9826 - val_loss: 1.0057 - val_accuracy: 0.7917\n",
            "Epoch 516/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5550 - accuracy: 0.9740 - val_loss: 0.9716 - val_accuracy: 0.8056\n",
            "Epoch 517/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5736 - accuracy: 0.9774 - val_loss: 0.9768 - val_accuracy: 0.8056\n",
            "Epoch 518/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5603 - accuracy: 0.9774 - val_loss: 0.9721 - val_accuracy: 0.7986\n",
            "Epoch 519/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5531 - accuracy: 0.9844 - val_loss: 0.9818 - val_accuracy: 0.7847\n",
            "Epoch 520/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5639 - accuracy: 0.9722 - val_loss: 0.9742 - val_accuracy: 0.7847\n",
            "Epoch 521/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5642 - accuracy: 0.9757 - val_loss: 0.9913 - val_accuracy: 0.7847\n",
            "Epoch 522/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5591 - accuracy: 0.9792 - val_loss: 0.9934 - val_accuracy: 0.8125\n",
            "Epoch 523/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5642 - accuracy: 0.9757 - val_loss: 0.9932 - val_accuracy: 0.7917\n",
            "Epoch 524/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5392 - accuracy: 0.9878 - val_loss: 0.9723 - val_accuracy: 0.7917\n",
            "Epoch 525/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5601 - accuracy: 0.9792 - val_loss: 0.9803 - val_accuracy: 0.7917\n",
            "Epoch 526/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5367 - accuracy: 0.9844 - val_loss: 0.9742 - val_accuracy: 0.7917\n",
            "Epoch 527/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5460 - accuracy: 0.9861 - val_loss: 0.9754 - val_accuracy: 0.7986\n",
            "Epoch 528/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5320 - accuracy: 0.9896 - val_loss: 0.9726 - val_accuracy: 0.8194\n",
            "Epoch 529/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5513 - accuracy: 0.9809 - val_loss: 0.9776 - val_accuracy: 0.7986\n",
            "Epoch 530/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5457 - accuracy: 0.9774 - val_loss: 0.9772 - val_accuracy: 0.8194\n",
            "Epoch 531/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5370 - accuracy: 0.9826 - val_loss: 0.9855 - val_accuracy: 0.7986\n",
            "Epoch 532/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5520 - accuracy: 0.9774 - val_loss: 0.9797 - val_accuracy: 0.8056\n",
            "Epoch 533/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5327 - accuracy: 0.9861 - val_loss: 0.9546 - val_accuracy: 0.8194\n",
            "Epoch 534/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5577 - accuracy: 0.9774 - val_loss: 0.9898 - val_accuracy: 0.7847\n",
            "Epoch 535/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5396 - accuracy: 0.9913 - val_loss: 0.9652 - val_accuracy: 0.7986\n",
            "Epoch 536/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5490 - accuracy: 0.9809 - val_loss: 0.9746 - val_accuracy: 0.7986\n",
            "Epoch 537/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5401 - accuracy: 0.9861 - val_loss: 0.9696 - val_accuracy: 0.7986\n",
            "Epoch 538/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5348 - accuracy: 0.9861 - val_loss: 0.9603 - val_accuracy: 0.7847\n",
            "Epoch 539/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5398 - accuracy: 0.9896 - val_loss: 0.9712 - val_accuracy: 0.7917\n",
            "Epoch 540/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5322 - accuracy: 0.9844 - val_loss: 0.9692 - val_accuracy: 0.7986\n",
            "Epoch 541/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5365 - accuracy: 0.9878 - val_loss: 0.9781 - val_accuracy: 0.7847\n",
            "Epoch 542/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5515 - accuracy: 0.9809 - val_loss: 0.9668 - val_accuracy: 0.7986\n",
            "Epoch 543/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5502 - accuracy: 0.9809 - val_loss: 0.9814 - val_accuracy: 0.8056\n",
            "Epoch 544/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5334 - accuracy: 0.9913 - val_loss: 0.9791 - val_accuracy: 0.7917\n",
            "Epoch 545/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5351 - accuracy: 0.9826 - val_loss: 0.9748 - val_accuracy: 0.7917\n",
            "Epoch 546/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5720 - accuracy: 0.9705 - val_loss: 0.9706 - val_accuracy: 0.8056\n",
            "Epoch 547/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5286 - accuracy: 0.9792 - val_loss: 0.9766 - val_accuracy: 0.8194\n",
            "Epoch 548/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5503 - accuracy: 0.9705 - val_loss: 0.9774 - val_accuracy: 0.8125\n",
            "Epoch 549/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5418 - accuracy: 0.9809 - val_loss: 0.9696 - val_accuracy: 0.8194\n",
            "Epoch 550/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5361 - accuracy: 0.9896 - val_loss: 0.9651 - val_accuracy: 0.8264\n",
            "Epoch 551/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5261 - accuracy: 0.9878 - val_loss: 0.9840 - val_accuracy: 0.7917\n",
            "Epoch 552/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5341 - accuracy: 0.9861 - val_loss: 0.9764 - val_accuracy: 0.7847\n",
            "Epoch 553/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5323 - accuracy: 0.9896 - val_loss: 0.9775 - val_accuracy: 0.7917\n",
            "Epoch 554/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5318 - accuracy: 0.9826 - val_loss: 0.9869 - val_accuracy: 0.7847\n",
            "Epoch 555/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5561 - accuracy: 0.9844 - val_loss: 0.9986 - val_accuracy: 0.8056\n",
            "Epoch 556/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5268 - accuracy: 0.9861 - val_loss: 0.9698 - val_accuracy: 0.8056\n",
            "Epoch 557/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5216 - accuracy: 0.9809 - val_loss: 0.9595 - val_accuracy: 0.8194\n",
            "Epoch 558/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5279 - accuracy: 0.9931 - val_loss: 0.9977 - val_accuracy: 0.8264\n",
            "Epoch 559/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5312 - accuracy: 0.9826 - val_loss: 0.9814 - val_accuracy: 0.8056\n",
            "Epoch 560/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5368 - accuracy: 0.9826 - val_loss: 0.9726 - val_accuracy: 0.8194\n",
            "Epoch 561/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5356 - accuracy: 0.9792 - val_loss: 0.9827 - val_accuracy: 0.7847\n",
            "Epoch 562/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5245 - accuracy: 0.9896 - val_loss: 0.9842 - val_accuracy: 0.8056\n",
            "Epoch 563/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5328 - accuracy: 0.9931 - val_loss: 0.9754 - val_accuracy: 0.7986\n",
            "Epoch 564/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5329 - accuracy: 0.9896 - val_loss: 0.9734 - val_accuracy: 0.8056\n",
            "Epoch 565/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5455 - accuracy: 0.9792 - val_loss: 0.9749 - val_accuracy: 0.8056\n",
            "Epoch 566/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5204 - accuracy: 0.9948 - val_loss: 0.9678 - val_accuracy: 0.8194\n",
            "Epoch 567/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5385 - accuracy: 0.9861 - val_loss: 0.9765 - val_accuracy: 0.7917\n",
            "Epoch 568/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5268 - accuracy: 0.9826 - val_loss: 0.9737 - val_accuracy: 0.7917\n",
            "Epoch 569/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5350 - accuracy: 0.9774 - val_loss: 0.9659 - val_accuracy: 0.8194\n",
            "Epoch 570/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5391 - accuracy: 0.9913 - val_loss: 0.9819 - val_accuracy: 0.7847\n",
            "Epoch 571/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5354 - accuracy: 0.9896 - val_loss: 0.9740 - val_accuracy: 0.7847\n",
            "Epoch 572/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5187 - accuracy: 0.9826 - val_loss: 0.9824 - val_accuracy: 0.8056\n",
            "Epoch 573/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5393 - accuracy: 0.9878 - val_loss: 0.9811 - val_accuracy: 0.7986\n",
            "Epoch 574/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5247 - accuracy: 0.9844 - val_loss: 0.9628 - val_accuracy: 0.8125\n",
            "Epoch 575/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5083 - accuracy: 0.9878 - val_loss: 0.9606 - val_accuracy: 0.8194\n",
            "Epoch 576/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5163 - accuracy: 0.9931 - val_loss: 0.9620 - val_accuracy: 0.8194\n",
            "Epoch 577/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5196 - accuracy: 0.9844 - val_loss: 0.9665 - val_accuracy: 0.8194\n",
            "Epoch 578/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5497 - accuracy: 0.9792 - val_loss: 0.9900 - val_accuracy: 0.7847\n",
            "Epoch 579/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5204 - accuracy: 0.9896 - val_loss: 0.9727 - val_accuracy: 0.7986\n",
            "Epoch 580/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5202 - accuracy: 0.9861 - val_loss: 0.9871 - val_accuracy: 0.7917\n",
            "Epoch 581/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5262 - accuracy: 0.9844 - val_loss: 0.9686 - val_accuracy: 0.8056\n",
            "Epoch 582/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5176 - accuracy: 0.9878 - val_loss: 0.9730 - val_accuracy: 0.8056\n",
            "Epoch 583/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.5241 - accuracy: 0.9861 - val_loss: 0.9709 - val_accuracy: 0.7986\n",
            "Epoch 584/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5093 - accuracy: 0.9896 - val_loss: 0.9707 - val_accuracy: 0.8194\n",
            "Epoch 585/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5176 - accuracy: 0.9878 - val_loss: 0.9647 - val_accuracy: 0.7986\n",
            "Epoch 586/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5134 - accuracy: 0.9774 - val_loss: 0.9583 - val_accuracy: 0.8125\n",
            "Epoch 587/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5331 - accuracy: 0.9861 - val_loss: 0.9692 - val_accuracy: 0.8194\n",
            "Epoch 588/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5153 - accuracy: 0.9913 - val_loss: 0.9659 - val_accuracy: 0.8125\n",
            "Epoch 589/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5420 - accuracy: 0.9792 - val_loss: 0.9661 - val_accuracy: 0.8194\n",
            "Epoch 590/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5309 - accuracy: 0.9740 - val_loss: 0.9732 - val_accuracy: 0.8264\n",
            "Epoch 591/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5229 - accuracy: 0.9792 - val_loss: 0.9595 - val_accuracy: 0.8056\n",
            "Epoch 592/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5135 - accuracy: 0.9844 - val_loss: 0.9731 - val_accuracy: 0.8125\n",
            "Epoch 593/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5211 - accuracy: 0.9913 - val_loss: 0.9649 - val_accuracy: 0.8125\n",
            "Epoch 594/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5223 - accuracy: 0.9861 - val_loss: 0.9626 - val_accuracy: 0.8056\n",
            "Epoch 595/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5145 - accuracy: 0.9896 - val_loss: 0.9724 - val_accuracy: 0.7847\n",
            "Epoch 596/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5048 - accuracy: 0.9948 - val_loss: 0.9710 - val_accuracy: 0.7986\n",
            "Epoch 597/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5126 - accuracy: 0.9931 - val_loss: 0.9639 - val_accuracy: 0.8194\n",
            "Epoch 598/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5166 - accuracy: 0.9896 - val_loss: 0.9618 - val_accuracy: 0.8264\n",
            "Epoch 599/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5293 - accuracy: 0.9809 - val_loss: 0.9660 - val_accuracy: 0.8125\n",
            "Epoch 600/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5132 - accuracy: 0.9913 - val_loss: 0.9587 - val_accuracy: 0.8125\n",
            "Epoch 601/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5161 - accuracy: 0.9931 - val_loss: 0.9781 - val_accuracy: 0.7847\n",
            "Epoch 602/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5080 - accuracy: 0.9878 - val_loss: 0.9750 - val_accuracy: 0.7917\n",
            "Epoch 603/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5007 - accuracy: 0.9948 - val_loss: 0.9704 - val_accuracy: 0.8125\n",
            "Epoch 604/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5246 - accuracy: 0.9826 - val_loss: 0.9750 - val_accuracy: 0.7986\n",
            "Epoch 605/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5011 - accuracy: 0.9931 - val_loss: 0.9689 - val_accuracy: 0.8056\n",
            "Epoch 606/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5077 - accuracy: 0.9861 - val_loss: 0.9811 - val_accuracy: 0.7917\n",
            "Epoch 607/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5208 - accuracy: 0.9844 - val_loss: 0.9597 - val_accuracy: 0.8125\n",
            "Epoch 608/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5001 - accuracy: 0.9878 - val_loss: 0.9751 - val_accuracy: 0.7986\n",
            "Epoch 609/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5077 - accuracy: 0.9896 - val_loss: 0.9645 - val_accuracy: 0.8056\n",
            "Epoch 610/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5099 - accuracy: 0.9844 - val_loss: 0.9886 - val_accuracy: 0.7986\n",
            "Epoch 611/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5315 - accuracy: 0.9931 - val_loss: 0.9823 - val_accuracy: 0.8056\n",
            "Epoch 612/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5084 - accuracy: 0.9931 - val_loss: 0.9729 - val_accuracy: 0.7986\n",
            "Epoch 613/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5121 - accuracy: 0.9861 - val_loss: 0.9744 - val_accuracy: 0.8056\n",
            "Epoch 614/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5016 - accuracy: 0.9896 - val_loss: 0.9718 - val_accuracy: 0.8194\n",
            "Epoch 615/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5169 - accuracy: 0.9931 - val_loss: 0.9564 - val_accuracy: 0.8194\n",
            "Epoch 616/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5060 - accuracy: 0.9896 - val_loss: 0.9729 - val_accuracy: 0.7986\n",
            "Epoch 617/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5018 - accuracy: 0.9878 - val_loss: 0.9747 - val_accuracy: 0.7986\n",
            "Epoch 618/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5002 - accuracy: 0.9913 - val_loss: 0.9760 - val_accuracy: 0.8125\n",
            "Epoch 619/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5108 - accuracy: 0.9826 - val_loss: 0.9624 - val_accuracy: 0.7986\n",
            "Epoch 620/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5047 - accuracy: 0.9844 - val_loss: 0.9645 - val_accuracy: 0.7847\n",
            "Epoch 621/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5227 - accuracy: 0.9774 - val_loss: 0.9673 - val_accuracy: 0.8056\n",
            "Epoch 622/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5072 - accuracy: 0.9965 - val_loss: 0.9688 - val_accuracy: 0.7917\n",
            "Epoch 623/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5100 - accuracy: 0.9861 - val_loss: 0.9808 - val_accuracy: 0.7917\n",
            "Epoch 624/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5156 - accuracy: 0.9809 - val_loss: 0.9762 - val_accuracy: 0.7847\n",
            "Epoch 625/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5036 - accuracy: 0.9861 - val_loss: 0.9813 - val_accuracy: 0.7917\n",
            "Epoch 626/700\n",
            "9/9 [==============================] - 1s 93ms/step - loss: 0.4954 - accuracy: 0.9913 - val_loss: 0.9627 - val_accuracy: 0.8194\n",
            "Epoch 627/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4962 - accuracy: 0.9965 - val_loss: 0.9695 - val_accuracy: 0.8125\n",
            "Epoch 628/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4970 - accuracy: 0.9965 - val_loss: 0.9714 - val_accuracy: 0.7986\n",
            "Epoch 629/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5017 - accuracy: 0.9913 - val_loss: 0.9538 - val_accuracy: 0.8125\n",
            "Epoch 630/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4874 - accuracy: 0.9896 - val_loss: 0.9633 - val_accuracy: 0.8056\n",
            "Epoch 631/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4982 - accuracy: 0.9913 - val_loss: 0.9738 - val_accuracy: 0.7917\n",
            "Epoch 632/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5073 - accuracy: 0.9878 - val_loss: 0.9579 - val_accuracy: 0.7986\n",
            "Epoch 633/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5114 - accuracy: 0.9878 - val_loss: 0.9628 - val_accuracy: 0.7917\n",
            "Epoch 634/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5053 - accuracy: 0.9896 - val_loss: 0.9600 - val_accuracy: 0.8125\n",
            "Epoch 635/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4979 - accuracy: 0.9896 - val_loss: 0.9509 - val_accuracy: 0.8125\n",
            "Epoch 636/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5029 - accuracy: 0.9878 - val_loss: 0.9501 - val_accuracy: 0.8333\n",
            "Epoch 637/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4994 - accuracy: 0.9861 - val_loss: 0.9549 - val_accuracy: 0.8125\n",
            "Epoch 638/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5004 - accuracy: 0.9931 - val_loss: 0.9591 - val_accuracy: 0.8194\n",
            "Epoch 639/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4928 - accuracy: 0.9878 - val_loss: 0.9745 - val_accuracy: 0.8194\n",
            "Epoch 640/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5102 - accuracy: 0.9844 - val_loss: 0.9716 - val_accuracy: 0.7986\n",
            "Epoch 641/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5053 - accuracy: 0.9913 - val_loss: 0.9649 - val_accuracy: 0.7986\n",
            "Epoch 642/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4772 - accuracy: 0.9948 - val_loss: 0.9554 - val_accuracy: 0.8194\n",
            "Epoch 643/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4918 - accuracy: 0.9983 - val_loss: 0.9832 - val_accuracy: 0.7847\n",
            "Epoch 644/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4995 - accuracy: 0.9931 - val_loss: 0.9698 - val_accuracy: 0.7986\n",
            "Epoch 645/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4809 - accuracy: 0.9965 - val_loss: 0.9727 - val_accuracy: 0.7986\n",
            "Epoch 646/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5121 - accuracy: 0.9913 - val_loss: 0.9693 - val_accuracy: 0.7917\n",
            "Epoch 647/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4854 - accuracy: 0.9965 - val_loss: 0.9482 - val_accuracy: 0.8125\n",
            "Epoch 648/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5034 - accuracy: 0.9878 - val_loss: 0.9544 - val_accuracy: 0.7847\n",
            "Epoch 649/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4877 - accuracy: 0.9913 - val_loss: 0.9533 - val_accuracy: 0.7986\n",
            "Epoch 650/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4972 - accuracy: 0.9878 - val_loss: 0.9549 - val_accuracy: 0.7986\n",
            "Epoch 651/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4889 - accuracy: 0.9931 - val_loss: 0.9686 - val_accuracy: 0.8056\n",
            "Epoch 652/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4911 - accuracy: 0.9878 - val_loss: 0.9705 - val_accuracy: 0.8194\n",
            "Epoch 653/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4874 - accuracy: 0.9931 - val_loss: 0.9712 - val_accuracy: 0.8056\n",
            "Epoch 654/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4920 - accuracy: 0.9878 - val_loss: 0.9679 - val_accuracy: 0.7986\n",
            "Epoch 655/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4787 - accuracy: 1.0000 - val_loss: 0.9587 - val_accuracy: 0.7986\n",
            "Epoch 656/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4791 - accuracy: 0.9965 - val_loss: 0.9470 - val_accuracy: 0.8125\n",
            "Epoch 657/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4891 - accuracy: 0.9948 - val_loss: 0.9504 - val_accuracy: 0.8125\n",
            "Epoch 658/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4835 - accuracy: 0.9965 - val_loss: 0.9755 - val_accuracy: 0.8056\n",
            "Epoch 659/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4962 - accuracy: 0.9948 - val_loss: 0.9491 - val_accuracy: 0.7986\n",
            "Epoch 660/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4868 - accuracy: 0.9965 - val_loss: 0.9492 - val_accuracy: 0.8194\n",
            "Epoch 661/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5027 - accuracy: 0.9861 - val_loss: 0.9412 - val_accuracy: 0.8194\n",
            "Epoch 662/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4854 - accuracy: 0.9948 - val_loss: 0.9633 - val_accuracy: 0.8125\n",
            "Epoch 663/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4876 - accuracy: 0.9913 - val_loss: 0.9680 - val_accuracy: 0.7986\n",
            "Epoch 664/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4723 - accuracy: 0.9931 - val_loss: 0.9683 - val_accuracy: 0.7917\n",
            "Epoch 665/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4938 - accuracy: 0.9948 - val_loss: 0.9579 - val_accuracy: 0.8125\n",
            "Epoch 666/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4800 - accuracy: 0.9983 - val_loss: 0.9753 - val_accuracy: 0.7986\n",
            "Epoch 667/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5036 - accuracy: 0.9844 - val_loss: 0.9541 - val_accuracy: 0.7847\n",
            "Epoch 668/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4806 - accuracy: 0.9983 - val_loss: 0.9696 - val_accuracy: 0.7986\n",
            "Epoch 669/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4868 - accuracy: 0.9913 - val_loss: 0.9635 - val_accuracy: 0.8056\n",
            "Epoch 670/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4760 - accuracy: 0.9878 - val_loss: 0.9464 - val_accuracy: 0.8333\n",
            "Epoch 671/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4802 - accuracy: 0.9983 - val_loss: 0.9635 - val_accuracy: 0.7917\n",
            "Epoch 672/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4791 - accuracy: 0.9965 - val_loss: 0.9568 - val_accuracy: 0.8056\n",
            "Epoch 673/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5021 - accuracy: 0.9896 - val_loss: 0.9633 - val_accuracy: 0.8125\n",
            "Epoch 674/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4773 - accuracy: 0.9931 - val_loss: 0.9820 - val_accuracy: 0.7917\n",
            "Epoch 675/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4790 - accuracy: 0.9965 - val_loss: 0.9643 - val_accuracy: 0.7986\n",
            "Epoch 676/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4760 - accuracy: 0.9948 - val_loss: 0.9707 - val_accuracy: 0.8194\n",
            "Epoch 677/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4828 - accuracy: 0.9983 - val_loss: 0.9571 - val_accuracy: 0.8056\n",
            "Epoch 678/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4746 - accuracy: 0.9948 - val_loss: 0.9697 - val_accuracy: 0.8194\n",
            "Epoch 679/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4754 - accuracy: 0.9983 - val_loss: 0.9597 - val_accuracy: 0.8056\n",
            "Epoch 680/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4899 - accuracy: 0.9913 - val_loss: 0.9597 - val_accuracy: 0.7847\n",
            "Epoch 681/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4708 - accuracy: 0.9965 - val_loss: 0.9656 - val_accuracy: 0.8264\n",
            "Epoch 682/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4934 - accuracy: 0.9948 - val_loss: 0.9487 - val_accuracy: 0.8194\n",
            "Epoch 683/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4711 - accuracy: 0.9983 - val_loss: 0.9722 - val_accuracy: 0.8125\n",
            "Epoch 684/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4917 - accuracy: 0.9913 - val_loss: 0.9686 - val_accuracy: 0.8333\n",
            "Epoch 685/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4706 - accuracy: 0.9965 - val_loss: 0.9691 - val_accuracy: 0.8056\n",
            "Epoch 686/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.4663 - accuracy: 0.9948 - val_loss: 0.9607 - val_accuracy: 0.8264\n",
            "Epoch 687/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4788 - accuracy: 0.9931 - val_loss: 0.9695 - val_accuracy: 0.8056\n",
            "Epoch 688/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4706 - accuracy: 0.9965 - val_loss: 0.9569 - val_accuracy: 0.8194\n",
            "Epoch 689/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4779 - accuracy: 0.9948 - val_loss: 0.9493 - val_accuracy: 0.8125\n",
            "Epoch 690/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4806 - accuracy: 0.9913 - val_loss: 0.9496 - val_accuracy: 0.8194\n",
            "Epoch 691/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4739 - accuracy: 0.9983 - val_loss: 0.9524 - val_accuracy: 0.8125\n",
            "Epoch 692/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4815 - accuracy: 0.9896 - val_loss: 0.9558 - val_accuracy: 0.8056\n",
            "Epoch 693/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4947 - accuracy: 0.9861 - val_loss: 0.9663 - val_accuracy: 0.8125\n",
            "Epoch 694/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4765 - accuracy: 0.9931 - val_loss: 0.9704 - val_accuracy: 0.8125\n",
            "Epoch 695/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4641 - accuracy: 0.9965 - val_loss: 0.9772 - val_accuracy: 0.7986\n",
            "Epoch 696/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4668 - accuracy: 0.9931 - val_loss: 0.9584 - val_accuracy: 0.8056\n",
            "Epoch 697/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4672 - accuracy: 0.9913 - val_loss: 0.9550 - val_accuracy: 0.8194\n",
            "Epoch 698/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4794 - accuracy: 0.9878 - val_loss: 0.9480 - val_accuracy: 0.8333\n",
            "Epoch 699/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4745 - accuracy: 0.9948 - val_loss: 0.9741 - val_accuracy: 0.7847\n",
            "Epoch 700/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4708 - accuracy: 0.9965 - val_loss: 0.9700 - val_accuracy: 0.8194\n",
            "1\n",
            "Epoch 1/700\n",
            "9/9 [==============================] - 2s 100ms/step - loss: 2.3143 - accuracy: 0.1632 - val_loss: 2.2986 - val_accuracy: 0.1667\n",
            "Epoch 2/700\n",
            "9/9 [==============================] - 1s 88ms/step - loss: 2.2589 - accuracy: 0.1875 - val_loss: 2.2064 - val_accuracy: 0.1458\n",
            "Epoch 3/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 2.2023 - accuracy: 0.1823 - val_loss: 2.1525 - val_accuracy: 0.1458\n",
            "Epoch 4/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 2.0977 - accuracy: 0.2344 - val_loss: 2.1141 - val_accuracy: 0.1528\n",
            "Epoch 5/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 2.0843 - accuracy: 0.2344 - val_loss: 2.0854 - val_accuracy: 0.1528\n",
            "Epoch 6/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 2.0302 - accuracy: 0.2257 - val_loss: 2.0554 - val_accuracy: 0.1528\n",
            "Epoch 7/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 2.0498 - accuracy: 0.2361 - val_loss: 2.0345 - val_accuracy: 0.1736\n",
            "Epoch 8/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.9504 - accuracy: 0.2274 - val_loss: 2.0227 - val_accuracy: 0.2153\n",
            "Epoch 9/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.9285 - accuracy: 0.2569 - val_loss: 2.0125 - val_accuracy: 0.2222\n",
            "Epoch 10/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.9193 - accuracy: 0.2604 - val_loss: 2.0030 - val_accuracy: 0.2361\n",
            "Epoch 11/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.8406 - accuracy: 0.2986 - val_loss: 1.9979 - val_accuracy: 0.2361\n",
            "Epoch 12/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.8499 - accuracy: 0.3038 - val_loss: 1.9921 - val_accuracy: 0.2569\n",
            "Epoch 13/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.8219 - accuracy: 0.3090 - val_loss: 1.9850 - val_accuracy: 0.2292\n",
            "Epoch 14/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.7073 - accuracy: 0.3628 - val_loss: 1.9890 - val_accuracy: 0.2361\n",
            "Epoch 15/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.7652 - accuracy: 0.3281 - val_loss: 1.9880 - val_accuracy: 0.2431\n",
            "Epoch 16/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.7960 - accuracy: 0.3264 - val_loss: 1.9954 - val_accuracy: 0.2639\n",
            "Epoch 17/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.7344 - accuracy: 0.3125 - val_loss: 1.9984 - val_accuracy: 0.2778\n",
            "Epoch 18/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.7115 - accuracy: 0.3542 - val_loss: 1.9945 - val_accuracy: 0.2778\n",
            "Epoch 19/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.7093 - accuracy: 0.3906 - val_loss: 1.9908 - val_accuracy: 0.2500\n",
            "Epoch 20/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.6838 - accuracy: 0.3854 - val_loss: 1.9899 - val_accuracy: 0.2500\n",
            "Epoch 21/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.6914 - accuracy: 0.3750 - val_loss: 1.9974 - val_accuracy: 0.2292\n",
            "Epoch 22/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6718 - accuracy: 0.3594 - val_loss: 1.9952 - val_accuracy: 0.2014\n",
            "Epoch 23/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.6486 - accuracy: 0.3889 - val_loss: 1.9936 - val_accuracy: 0.2222\n",
            "Epoch 24/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6391 - accuracy: 0.3906 - val_loss: 1.9961 - val_accuracy: 0.2222\n",
            "Epoch 25/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.6423 - accuracy: 0.4097 - val_loss: 1.9931 - val_accuracy: 0.2431\n",
            "Epoch 26/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.6203 - accuracy: 0.3872 - val_loss: 1.9905 - val_accuracy: 0.2083\n",
            "Epoch 27/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.5923 - accuracy: 0.4358 - val_loss: 1.9955 - val_accuracy: 0.1528\n",
            "Epoch 28/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6130 - accuracy: 0.3993 - val_loss: 1.9965 - val_accuracy: 0.1597\n",
            "Epoch 29/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6030 - accuracy: 0.4236 - val_loss: 1.9993 - val_accuracy: 0.2361\n",
            "Epoch 30/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6155 - accuracy: 0.4253 - val_loss: 1.9983 - val_accuracy: 0.1806\n",
            "Epoch 31/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.5627 - accuracy: 0.4410 - val_loss: 1.9906 - val_accuracy: 0.2361\n",
            "Epoch 32/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.5702 - accuracy: 0.4358 - val_loss: 1.9852 - val_accuracy: 0.2153\n",
            "Epoch 33/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.5421 - accuracy: 0.4583 - val_loss: 1.9801 - val_accuracy: 0.2569\n",
            "Epoch 34/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.5365 - accuracy: 0.4444 - val_loss: 1.9706 - val_accuracy: 0.2569\n",
            "Epoch 35/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.5519 - accuracy: 0.4236 - val_loss: 1.9853 - val_accuracy: 0.2361\n",
            "Epoch 36/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4833 - accuracy: 0.4774 - val_loss: 1.9777 - val_accuracy: 0.2292\n",
            "Epoch 37/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.5028 - accuracy: 0.4792 - val_loss: 1.9658 - val_accuracy: 0.2708\n",
            "Epoch 38/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.5088 - accuracy: 0.4740 - val_loss: 1.9529 - val_accuracy: 0.2778\n",
            "Epoch 39/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.4537 - accuracy: 0.4896 - val_loss: 1.9451 - val_accuracy: 0.2778\n",
            "Epoch 40/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.4813 - accuracy: 0.4826 - val_loss: 1.9387 - val_accuracy: 0.2986\n",
            "Epoch 41/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.4557 - accuracy: 0.4965 - val_loss: 1.9192 - val_accuracy: 0.3264\n",
            "Epoch 42/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.4398 - accuracy: 0.5069 - val_loss: 1.9035 - val_accuracy: 0.3264\n",
            "Epoch 43/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4235 - accuracy: 0.5122 - val_loss: 1.9052 - val_accuracy: 0.3403\n",
            "Epoch 44/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.4466 - accuracy: 0.5087 - val_loss: 1.8995 - val_accuracy: 0.3056\n",
            "Epoch 45/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4124 - accuracy: 0.5226 - val_loss: 1.8700 - val_accuracy: 0.3472\n",
            "Epoch 46/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4035 - accuracy: 0.5521 - val_loss: 1.8709 - val_accuracy: 0.3333\n",
            "Epoch 47/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4160 - accuracy: 0.5226 - val_loss: 1.8632 - val_accuracy: 0.3194\n",
            "Epoch 48/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.4153 - accuracy: 0.5000 - val_loss: 1.8396 - val_accuracy: 0.3611\n",
            "Epoch 49/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3998 - accuracy: 0.5330 - val_loss: 1.8270 - val_accuracy: 0.3125\n",
            "Epoch 50/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3870 - accuracy: 0.5312 - val_loss: 1.8198 - val_accuracy: 0.3403\n",
            "Epoch 51/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4058 - accuracy: 0.5174 - val_loss: 1.8122 - val_accuracy: 0.3403\n",
            "Epoch 52/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.3671 - accuracy: 0.5295 - val_loss: 1.7978 - val_accuracy: 0.3264\n",
            "Epoch 53/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3032 - accuracy: 0.5660 - val_loss: 1.7784 - val_accuracy: 0.3542\n",
            "Epoch 54/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3430 - accuracy: 0.5608 - val_loss: 1.7654 - val_accuracy: 0.3472\n",
            "Epoch 55/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3538 - accuracy: 0.5486 - val_loss: 1.7579 - val_accuracy: 0.3750\n",
            "Epoch 56/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3542 - accuracy: 0.5503 - val_loss: 1.7502 - val_accuracy: 0.3542\n",
            "Epoch 57/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3449 - accuracy: 0.5642 - val_loss: 1.7479 - val_accuracy: 0.3264\n",
            "Epoch 58/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.3116 - accuracy: 0.5764 - val_loss: 1.7417 - val_accuracy: 0.3194\n",
            "Epoch 59/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.3283 - accuracy: 0.5747 - val_loss: 1.7106 - val_accuracy: 0.3542\n",
            "Epoch 60/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3435 - accuracy: 0.5590 - val_loss: 1.6834 - val_accuracy: 0.3819\n",
            "Epoch 61/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3184 - accuracy: 0.5573 - val_loss: 1.6641 - val_accuracy: 0.4028\n",
            "Epoch 62/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.3198 - accuracy: 0.5712 - val_loss: 1.6346 - val_accuracy: 0.3819\n",
            "Epoch 63/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.3012 - accuracy: 0.5903 - val_loss: 1.6389 - val_accuracy: 0.3889\n",
            "Epoch 64/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2734 - accuracy: 0.5816 - val_loss: 1.6334 - val_accuracy: 0.3681\n",
            "Epoch 65/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2866 - accuracy: 0.5920 - val_loss: 1.5954 - val_accuracy: 0.4167\n",
            "Epoch 66/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2539 - accuracy: 0.6354 - val_loss: 1.5876 - val_accuracy: 0.4514\n",
            "Epoch 67/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2599 - accuracy: 0.6042 - val_loss: 1.5692 - val_accuracy: 0.4583\n",
            "Epoch 68/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3123 - accuracy: 0.5608 - val_loss: 1.5411 - val_accuracy: 0.4792\n",
            "Epoch 69/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2536 - accuracy: 0.5938 - val_loss: 1.5387 - val_accuracy: 0.4931\n",
            "Epoch 70/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2350 - accuracy: 0.6389 - val_loss: 1.5325 - val_accuracy: 0.4722\n",
            "Epoch 71/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2643 - accuracy: 0.6198 - val_loss: 1.5199 - val_accuracy: 0.4861\n",
            "Epoch 72/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.2785 - accuracy: 0.5990 - val_loss: 1.5004 - val_accuracy: 0.4792\n",
            "Epoch 73/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2148 - accuracy: 0.6198 - val_loss: 1.4981 - val_accuracy: 0.4653\n",
            "Epoch 74/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.2539 - accuracy: 0.6163 - val_loss: 1.4755 - val_accuracy: 0.5556\n",
            "Epoch 75/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2407 - accuracy: 0.6389 - val_loss: 1.4638 - val_accuracy: 0.5278\n",
            "Epoch 76/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.2376 - accuracy: 0.5938 - val_loss: 1.4498 - val_accuracy: 0.5556\n",
            "Epoch 77/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2125 - accuracy: 0.6319 - val_loss: 1.4573 - val_accuracy: 0.5000\n",
            "Epoch 78/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2280 - accuracy: 0.6233 - val_loss: 1.4527 - val_accuracy: 0.5069\n",
            "Epoch 79/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1843 - accuracy: 0.6545 - val_loss: 1.4307 - val_accuracy: 0.5694\n",
            "Epoch 80/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2002 - accuracy: 0.6389 - val_loss: 1.4173 - val_accuracy: 0.5833\n",
            "Epoch 81/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2249 - accuracy: 0.6128 - val_loss: 1.4222 - val_accuracy: 0.5694\n",
            "Epoch 82/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1733 - accuracy: 0.6562 - val_loss: 1.4235 - val_accuracy: 0.5694\n",
            "Epoch 83/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2001 - accuracy: 0.6424 - val_loss: 1.4189 - val_accuracy: 0.5694\n",
            "Epoch 84/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1884 - accuracy: 0.6302 - val_loss: 1.4096 - val_accuracy: 0.5764\n",
            "Epoch 85/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1738 - accuracy: 0.6684 - val_loss: 1.3937 - val_accuracy: 0.5972\n",
            "Epoch 86/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1554 - accuracy: 0.6545 - val_loss: 1.3953 - val_accuracy: 0.5903\n",
            "Epoch 87/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1442 - accuracy: 0.6719 - val_loss: 1.4062 - val_accuracy: 0.5694\n",
            "Epoch 88/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1478 - accuracy: 0.6667 - val_loss: 1.4026 - val_accuracy: 0.5903\n",
            "Epoch 89/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2025 - accuracy: 0.6233 - val_loss: 1.3791 - val_accuracy: 0.6319\n",
            "Epoch 90/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1767 - accuracy: 0.6233 - val_loss: 1.3703 - val_accuracy: 0.5972\n",
            "Epoch 91/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1826 - accuracy: 0.6337 - val_loss: 1.3513 - val_accuracy: 0.6111\n",
            "Epoch 92/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1601 - accuracy: 0.6632 - val_loss: 1.3551 - val_accuracy: 0.6250\n",
            "Epoch 93/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1585 - accuracy: 0.6771 - val_loss: 1.3334 - val_accuracy: 0.6181\n",
            "Epoch 94/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1588 - accuracy: 0.6528 - val_loss: 1.3486 - val_accuracy: 0.6319\n",
            "Epoch 95/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1248 - accuracy: 0.6979 - val_loss: 1.3451 - val_accuracy: 0.6250\n",
            "Epoch 96/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1464 - accuracy: 0.6562 - val_loss: 1.3473 - val_accuracy: 0.6319\n",
            "Epoch 97/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1448 - accuracy: 0.6788 - val_loss: 1.3407 - val_accuracy: 0.6111\n",
            "Epoch 98/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1385 - accuracy: 0.6580 - val_loss: 1.3399 - val_accuracy: 0.6042\n",
            "Epoch 99/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1171 - accuracy: 0.6597 - val_loss: 1.3393 - val_accuracy: 0.6042\n",
            "Epoch 100/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1191 - accuracy: 0.6806 - val_loss: 1.3408 - val_accuracy: 0.6181\n",
            "Epoch 101/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0930 - accuracy: 0.6858 - val_loss: 1.3581 - val_accuracy: 0.6181\n",
            "Epoch 102/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1135 - accuracy: 0.7014 - val_loss: 1.3490 - val_accuracy: 0.6181\n",
            "Epoch 103/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1191 - accuracy: 0.6840 - val_loss: 1.3363 - val_accuracy: 0.6319\n",
            "Epoch 104/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0833 - accuracy: 0.6997 - val_loss: 1.3331 - val_accuracy: 0.6458\n",
            "Epoch 105/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0916 - accuracy: 0.7101 - val_loss: 1.3385 - val_accuracy: 0.6181\n",
            "Epoch 106/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0957 - accuracy: 0.6858 - val_loss: 1.3465 - val_accuracy: 0.6458\n",
            "Epoch 107/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0929 - accuracy: 0.7118 - val_loss: 1.3343 - val_accuracy: 0.6250\n",
            "Epoch 108/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 1.0930 - accuracy: 0.6979 - val_loss: 1.3299 - val_accuracy: 0.6111\n",
            "Epoch 109/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0974 - accuracy: 0.7014 - val_loss: 1.3343 - val_accuracy: 0.6181\n",
            "Epoch 110/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0835 - accuracy: 0.6962 - val_loss: 1.3301 - val_accuracy: 0.6389\n",
            "Epoch 111/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0646 - accuracy: 0.7205 - val_loss: 1.3053 - val_accuracy: 0.6458\n",
            "Epoch 112/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0899 - accuracy: 0.7222 - val_loss: 1.3183 - val_accuracy: 0.6597\n",
            "Epoch 113/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0773 - accuracy: 0.7031 - val_loss: 1.3358 - val_accuracy: 0.6319\n",
            "Epoch 114/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0827 - accuracy: 0.7135 - val_loss: 1.3231 - val_accuracy: 0.6458\n",
            "Epoch 115/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0841 - accuracy: 0.7118 - val_loss: 1.3130 - val_accuracy: 0.6458\n",
            "Epoch 116/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0299 - accuracy: 0.7344 - val_loss: 1.3039 - val_accuracy: 0.6319\n",
            "Epoch 117/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0679 - accuracy: 0.7188 - val_loss: 1.3012 - val_accuracy: 0.6458\n",
            "Epoch 118/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0649 - accuracy: 0.7083 - val_loss: 1.2936 - val_accuracy: 0.6528\n",
            "Epoch 119/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0878 - accuracy: 0.6997 - val_loss: 1.2862 - val_accuracy: 0.6736\n",
            "Epoch 120/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0441 - accuracy: 0.7396 - val_loss: 1.2867 - val_accuracy: 0.6319\n",
            "Epoch 121/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0480 - accuracy: 0.7014 - val_loss: 1.2954 - val_accuracy: 0.6806\n",
            "Epoch 122/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0334 - accuracy: 0.7465 - val_loss: 1.2831 - val_accuracy: 0.6597\n",
            "Epoch 123/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0325 - accuracy: 0.7517 - val_loss: 1.2920 - val_accuracy: 0.6597\n",
            "Epoch 124/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0284 - accuracy: 0.7500 - val_loss: 1.2826 - val_accuracy: 0.6667\n",
            "Epoch 125/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0432 - accuracy: 0.7361 - val_loss: 1.2945 - val_accuracy: 0.6528\n",
            "Epoch 126/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0536 - accuracy: 0.7135 - val_loss: 1.3059 - val_accuracy: 0.6458\n",
            "Epoch 127/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0351 - accuracy: 0.7431 - val_loss: 1.2825 - val_accuracy: 0.6806\n",
            "Epoch 128/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0241 - accuracy: 0.7361 - val_loss: 1.2994 - val_accuracy: 0.6597\n",
            "Epoch 129/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.0060 - accuracy: 0.7639 - val_loss: 1.2920 - val_accuracy: 0.6389\n",
            "Epoch 130/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0294 - accuracy: 0.7378 - val_loss: 1.2912 - val_accuracy: 0.6597\n",
            "Epoch 131/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0330 - accuracy: 0.7448 - val_loss: 1.2815 - val_accuracy: 0.6528\n",
            "Epoch 132/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0086 - accuracy: 0.7708 - val_loss: 1.2849 - val_accuracy: 0.6458\n",
            "Epoch 133/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0241 - accuracy: 0.7378 - val_loss: 1.2893 - val_accuracy: 0.6736\n",
            "Epoch 134/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9986 - accuracy: 0.7378 - val_loss: 1.2800 - val_accuracy: 0.6736\n",
            "Epoch 135/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0022 - accuracy: 0.7847 - val_loss: 1.2774 - val_accuracy: 0.6528\n",
            "Epoch 136/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9965 - accuracy: 0.7569 - val_loss: 1.2664 - val_accuracy: 0.6597\n",
            "Epoch 137/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0033 - accuracy: 0.7622 - val_loss: 1.2677 - val_accuracy: 0.6528\n",
            "Epoch 138/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0085 - accuracy: 0.7622 - val_loss: 1.2635 - val_accuracy: 0.6458\n",
            "Epoch 139/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9863 - accuracy: 0.7674 - val_loss: 1.2585 - val_accuracy: 0.6528\n",
            "Epoch 140/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9616 - accuracy: 0.7934 - val_loss: 1.2533 - val_accuracy: 0.6806\n",
            "Epoch 141/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0087 - accuracy: 0.7309 - val_loss: 1.2595 - val_accuracy: 0.6736\n",
            "Epoch 142/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9764 - accuracy: 0.7743 - val_loss: 1.2571 - val_accuracy: 0.6528\n",
            "Epoch 143/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9699 - accuracy: 0.7656 - val_loss: 1.2577 - val_accuracy: 0.6597\n",
            "Epoch 144/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9867 - accuracy: 0.7535 - val_loss: 1.2516 - val_accuracy: 0.6667\n",
            "Epoch 145/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9787 - accuracy: 0.7622 - val_loss: 1.2814 - val_accuracy: 0.6875\n",
            "Epoch 146/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9663 - accuracy: 0.7691 - val_loss: 1.2819 - val_accuracy: 0.6458\n",
            "Epoch 147/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9736 - accuracy: 0.7778 - val_loss: 1.2774 - val_accuracy: 0.6250\n",
            "Epoch 148/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9855 - accuracy: 0.7604 - val_loss: 1.2664 - val_accuracy: 0.6667\n",
            "Epoch 149/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9721 - accuracy: 0.7535 - val_loss: 1.2556 - val_accuracy: 0.6944\n",
            "Epoch 150/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9796 - accuracy: 0.7708 - val_loss: 1.2528 - val_accuracy: 0.6806\n",
            "Epoch 151/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9650 - accuracy: 0.7882 - val_loss: 1.2596 - val_accuracy: 0.6806\n",
            "Epoch 152/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9721 - accuracy: 0.7569 - val_loss: 1.2581 - val_accuracy: 0.6944\n",
            "Epoch 153/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9482 - accuracy: 0.7899 - val_loss: 1.2530 - val_accuracy: 0.6806\n",
            "Epoch 154/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9510 - accuracy: 0.7795 - val_loss: 1.2471 - val_accuracy: 0.6875\n",
            "Epoch 155/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9467 - accuracy: 0.7934 - val_loss: 1.2420 - val_accuracy: 0.6806\n",
            "Epoch 156/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9570 - accuracy: 0.7743 - val_loss: 1.2320 - val_accuracy: 0.6597\n",
            "Epoch 157/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9543 - accuracy: 0.7917 - val_loss: 1.2475 - val_accuracy: 0.6806\n",
            "Epoch 158/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9463 - accuracy: 0.7899 - val_loss: 1.2448 - val_accuracy: 0.6458\n",
            "Epoch 159/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9494 - accuracy: 0.7830 - val_loss: 1.2496 - val_accuracy: 0.6806\n",
            "Epoch 160/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9416 - accuracy: 0.7986 - val_loss: 1.2420 - val_accuracy: 0.6806\n",
            "Epoch 161/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9494 - accuracy: 0.7812 - val_loss: 1.2401 - val_accuracy: 0.6597\n",
            "Epoch 162/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9201 - accuracy: 0.8021 - val_loss: 1.2494 - val_accuracy: 0.6806\n",
            "Epoch 163/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9539 - accuracy: 0.7778 - val_loss: 1.2489 - val_accuracy: 0.6736\n",
            "Epoch 164/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9357 - accuracy: 0.7986 - val_loss: 1.2418 - val_accuracy: 0.6806\n",
            "Epoch 165/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9223 - accuracy: 0.8003 - val_loss: 1.2465 - val_accuracy: 0.6806\n",
            "Epoch 166/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9478 - accuracy: 0.7847 - val_loss: 1.2546 - val_accuracy: 0.6667\n",
            "Epoch 167/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9067 - accuracy: 0.8264 - val_loss: 1.2437 - val_accuracy: 0.6667\n",
            "Epoch 168/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9136 - accuracy: 0.8264 - val_loss: 1.2414 - val_accuracy: 0.6667\n",
            "Epoch 169/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9061 - accuracy: 0.8056 - val_loss: 1.2420 - val_accuracy: 0.6736\n",
            "Epoch 170/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9299 - accuracy: 0.7934 - val_loss: 1.2257 - val_accuracy: 0.6806\n",
            "Epoch 171/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9338 - accuracy: 0.8056 - val_loss: 1.2202 - val_accuracy: 0.6667\n",
            "Epoch 172/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9409 - accuracy: 0.7830 - val_loss: 1.2272 - val_accuracy: 0.6875\n",
            "Epoch 173/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9031 - accuracy: 0.8247 - val_loss: 1.2473 - val_accuracy: 0.6806\n",
            "Epoch 174/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9405 - accuracy: 0.7882 - val_loss: 1.2099 - val_accuracy: 0.6806\n",
            "Epoch 175/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9278 - accuracy: 0.8038 - val_loss: 1.2066 - val_accuracy: 0.7083\n",
            "Epoch 176/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.9239 - accuracy: 0.8021 - val_loss: 1.2266 - val_accuracy: 0.6944\n",
            "Epoch 177/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9177 - accuracy: 0.8038 - val_loss: 1.2264 - val_accuracy: 0.6806\n",
            "Epoch 178/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9093 - accuracy: 0.8212 - val_loss: 1.2256 - val_accuracy: 0.6875\n",
            "Epoch 179/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9214 - accuracy: 0.8108 - val_loss: 1.2290 - val_accuracy: 0.6875\n",
            "Epoch 180/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9143 - accuracy: 0.8108 - val_loss: 1.2089 - val_accuracy: 0.7083\n",
            "Epoch 181/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8988 - accuracy: 0.8247 - val_loss: 1.2178 - val_accuracy: 0.6875\n",
            "Epoch 182/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9286 - accuracy: 0.8021 - val_loss: 1.2135 - val_accuracy: 0.7083\n",
            "Epoch 183/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9087 - accuracy: 0.8125 - val_loss: 1.2034 - val_accuracy: 0.7153\n",
            "Epoch 184/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8960 - accuracy: 0.8229 - val_loss: 1.2101 - val_accuracy: 0.6875\n",
            "Epoch 185/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8960 - accuracy: 0.8281 - val_loss: 1.2132 - val_accuracy: 0.7083\n",
            "Epoch 186/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8926 - accuracy: 0.8333 - val_loss: 1.2072 - val_accuracy: 0.6944\n",
            "Epoch 187/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8836 - accuracy: 0.8385 - val_loss: 1.2136 - val_accuracy: 0.6806\n",
            "Epoch 188/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8857 - accuracy: 0.8160 - val_loss: 1.2271 - val_accuracy: 0.7014\n",
            "Epoch 189/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9079 - accuracy: 0.8003 - val_loss: 1.2298 - val_accuracy: 0.6875\n",
            "Epoch 190/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8789 - accuracy: 0.8177 - val_loss: 1.2135 - val_accuracy: 0.6944\n",
            "Epoch 191/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8640 - accuracy: 0.8333 - val_loss: 1.2094 - val_accuracy: 0.7014\n",
            "Epoch 192/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8838 - accuracy: 0.8194 - val_loss: 1.2111 - val_accuracy: 0.6875\n",
            "Epoch 193/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8769 - accuracy: 0.8559 - val_loss: 1.2193 - val_accuracy: 0.6597\n",
            "Epoch 194/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8726 - accuracy: 0.8438 - val_loss: 1.2271 - val_accuracy: 0.6597\n",
            "Epoch 195/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8651 - accuracy: 0.8299 - val_loss: 1.2269 - val_accuracy: 0.6736\n",
            "Epoch 196/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8903 - accuracy: 0.8125 - val_loss: 1.2297 - val_accuracy: 0.6806\n",
            "Epoch 197/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8611 - accuracy: 0.8576 - val_loss: 1.2203 - val_accuracy: 0.7014\n",
            "Epoch 198/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8613 - accuracy: 0.8490 - val_loss: 1.2236 - val_accuracy: 0.6944\n",
            "Epoch 199/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8749 - accuracy: 0.8368 - val_loss: 1.2165 - val_accuracy: 0.6736\n",
            "Epoch 200/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9028 - accuracy: 0.8177 - val_loss: 1.2193 - val_accuracy: 0.6597\n",
            "Epoch 201/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8651 - accuracy: 0.8385 - val_loss: 1.2175 - val_accuracy: 0.6875\n",
            "Epoch 202/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8581 - accuracy: 0.8472 - val_loss: 1.2256 - val_accuracy: 0.6944\n",
            "Epoch 203/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8519 - accuracy: 0.8524 - val_loss: 1.2061 - val_accuracy: 0.6944\n",
            "Epoch 204/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8732 - accuracy: 0.8472 - val_loss: 1.2044 - val_accuracy: 0.7014\n",
            "Epoch 205/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8568 - accuracy: 0.8281 - val_loss: 1.1895 - val_accuracy: 0.7014\n",
            "Epoch 206/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8343 - accuracy: 0.8420 - val_loss: 1.1950 - val_accuracy: 0.6944\n",
            "Epoch 207/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8736 - accuracy: 0.8125 - val_loss: 1.1779 - val_accuracy: 0.7222\n",
            "Epoch 208/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8458 - accuracy: 0.8576 - val_loss: 1.1934 - val_accuracy: 0.7014\n",
            "Epoch 209/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8434 - accuracy: 0.8576 - val_loss: 1.1946 - val_accuracy: 0.7014\n",
            "Epoch 210/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8597 - accuracy: 0.8316 - val_loss: 1.1997 - val_accuracy: 0.6944\n",
            "Epoch 211/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8363 - accuracy: 0.8524 - val_loss: 1.1971 - val_accuracy: 0.6944\n",
            "Epoch 212/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8281 - accuracy: 0.8559 - val_loss: 1.1891 - val_accuracy: 0.6944\n",
            "Epoch 213/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8340 - accuracy: 0.8559 - val_loss: 1.2014 - val_accuracy: 0.6806\n",
            "Epoch 214/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8432 - accuracy: 0.8490 - val_loss: 1.1861 - val_accuracy: 0.6875\n",
            "Epoch 215/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8478 - accuracy: 0.8455 - val_loss: 1.1804 - val_accuracy: 0.6944\n",
            "Epoch 216/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8478 - accuracy: 0.8403 - val_loss: 1.1929 - val_accuracy: 0.6944\n",
            "Epoch 217/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8260 - accuracy: 0.8698 - val_loss: 1.1937 - val_accuracy: 0.7083\n",
            "Epoch 218/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8319 - accuracy: 0.8524 - val_loss: 1.1869 - val_accuracy: 0.6875\n",
            "Epoch 219/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8469 - accuracy: 0.8420 - val_loss: 1.1835 - val_accuracy: 0.6806\n",
            "Epoch 220/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8503 - accuracy: 0.8385 - val_loss: 1.1796 - val_accuracy: 0.6944\n",
            "Epoch 221/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8045 - accuracy: 0.8802 - val_loss: 1.1853 - val_accuracy: 0.6875\n",
            "Epoch 222/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8325 - accuracy: 0.8628 - val_loss: 1.1898 - val_accuracy: 0.6875\n",
            "Epoch 223/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8404 - accuracy: 0.8438 - val_loss: 1.1877 - val_accuracy: 0.7014\n",
            "Epoch 224/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8365 - accuracy: 0.8455 - val_loss: 1.1781 - val_accuracy: 0.7014\n",
            "Epoch 225/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8269 - accuracy: 0.8351 - val_loss: 1.1714 - val_accuracy: 0.6944\n",
            "Epoch 226/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8161 - accuracy: 0.8559 - val_loss: 1.1894 - val_accuracy: 0.7014\n",
            "Epoch 227/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8210 - accuracy: 0.8542 - val_loss: 1.1839 - val_accuracy: 0.7014\n",
            "Epoch 228/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8004 - accuracy: 0.8976 - val_loss: 1.1820 - val_accuracy: 0.7083\n",
            "Epoch 229/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7994 - accuracy: 0.8837 - val_loss: 1.1927 - val_accuracy: 0.6736\n",
            "Epoch 230/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8195 - accuracy: 0.8733 - val_loss: 1.1954 - val_accuracy: 0.6736\n",
            "Epoch 231/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8176 - accuracy: 0.8681 - val_loss: 1.2154 - val_accuracy: 0.6875\n",
            "Epoch 232/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8191 - accuracy: 0.8681 - val_loss: 1.1992 - val_accuracy: 0.7153\n",
            "Epoch 233/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7998 - accuracy: 0.8889 - val_loss: 1.1916 - val_accuracy: 0.6875\n",
            "Epoch 234/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8311 - accuracy: 0.8611 - val_loss: 1.1781 - val_accuracy: 0.6944\n",
            "Epoch 235/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.8225 - accuracy: 0.8681 - val_loss: 1.2000 - val_accuracy: 0.6806\n",
            "Epoch 236/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8047 - accuracy: 0.8715 - val_loss: 1.1751 - val_accuracy: 0.6875\n",
            "Epoch 237/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8090 - accuracy: 0.8646 - val_loss: 1.1916 - val_accuracy: 0.6875\n",
            "Epoch 238/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8119 - accuracy: 0.8698 - val_loss: 1.1895 - val_accuracy: 0.6736\n",
            "Epoch 239/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8319 - accuracy: 0.8576 - val_loss: 1.1809 - val_accuracy: 0.6944\n",
            "Epoch 240/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8059 - accuracy: 0.8646 - val_loss: 1.1970 - val_accuracy: 0.6736\n",
            "Epoch 241/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8174 - accuracy: 0.8663 - val_loss: 1.1685 - val_accuracy: 0.6806\n",
            "Epoch 242/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7995 - accuracy: 0.8750 - val_loss: 1.1716 - val_accuracy: 0.7083\n",
            "Epoch 243/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7823 - accuracy: 0.8924 - val_loss: 1.1840 - val_accuracy: 0.6806\n",
            "Epoch 244/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7917 - accuracy: 0.8872 - val_loss: 1.1806 - val_accuracy: 0.6667\n",
            "Epoch 245/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7906 - accuracy: 0.8733 - val_loss: 1.1832 - val_accuracy: 0.7014\n",
            "Epoch 246/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8006 - accuracy: 0.8698 - val_loss: 1.1851 - val_accuracy: 0.6875\n",
            "Epoch 247/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7743 - accuracy: 0.8958 - val_loss: 1.1748 - val_accuracy: 0.6875\n",
            "Epoch 248/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7690 - accuracy: 0.8872 - val_loss: 1.1823 - val_accuracy: 0.7083\n",
            "Epoch 249/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7986 - accuracy: 0.8767 - val_loss: 1.1716 - val_accuracy: 0.6944\n",
            "Epoch 250/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7810 - accuracy: 0.8924 - val_loss: 1.1778 - val_accuracy: 0.6944\n",
            "Epoch 251/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7821 - accuracy: 0.8889 - val_loss: 1.1636 - val_accuracy: 0.7083\n",
            "Epoch 252/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7679 - accuracy: 0.9028 - val_loss: 1.1683 - val_accuracy: 0.7222\n",
            "Epoch 253/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7944 - accuracy: 0.8646 - val_loss: 1.1697 - val_accuracy: 0.7083\n",
            "Epoch 254/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7701 - accuracy: 0.8993 - val_loss: 1.1779 - val_accuracy: 0.7014\n",
            "Epoch 255/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7720 - accuracy: 0.8837 - val_loss: 1.1626 - val_accuracy: 0.7083\n",
            "Epoch 256/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7741 - accuracy: 0.8767 - val_loss: 1.1660 - val_accuracy: 0.6667\n",
            "Epoch 257/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7856 - accuracy: 0.8733 - val_loss: 1.1580 - val_accuracy: 0.6944\n",
            "Epoch 258/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7711 - accuracy: 0.8993 - val_loss: 1.1513 - val_accuracy: 0.7153\n",
            "Epoch 259/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7773 - accuracy: 0.8819 - val_loss: 1.1438 - val_accuracy: 0.7083\n",
            "Epoch 260/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7667 - accuracy: 0.8993 - val_loss: 1.1559 - val_accuracy: 0.7153\n",
            "Epoch 261/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7674 - accuracy: 0.8941 - val_loss: 1.1621 - val_accuracy: 0.6944\n",
            "Epoch 262/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7701 - accuracy: 0.8837 - val_loss: 1.1672 - val_accuracy: 0.7153\n",
            "Epoch 263/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7620 - accuracy: 0.8854 - val_loss: 1.1724 - val_accuracy: 0.7153\n",
            "Epoch 264/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7874 - accuracy: 0.8837 - val_loss: 1.1769 - val_accuracy: 0.6736\n",
            "Epoch 265/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8051 - accuracy: 0.8698 - val_loss: 1.1525 - val_accuracy: 0.7083\n",
            "Epoch 266/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7698 - accuracy: 0.8924 - val_loss: 1.1764 - val_accuracy: 0.6944\n",
            "Epoch 267/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7797 - accuracy: 0.8958 - val_loss: 1.1728 - val_accuracy: 0.7083\n",
            "Epoch 268/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7616 - accuracy: 0.8958 - val_loss: 1.1524 - val_accuracy: 0.7014\n",
            "Epoch 269/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7485 - accuracy: 0.9080 - val_loss: 1.1519 - val_accuracy: 0.7083\n",
            "Epoch 270/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7634 - accuracy: 0.8941 - val_loss: 1.1611 - val_accuracy: 0.6944\n",
            "Epoch 271/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7688 - accuracy: 0.9010 - val_loss: 1.1500 - val_accuracy: 0.7083\n",
            "Epoch 272/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7901 - accuracy: 0.8698 - val_loss: 1.1579 - val_accuracy: 0.7153\n",
            "Epoch 273/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7680 - accuracy: 0.8819 - val_loss: 1.1457 - val_accuracy: 0.6944\n",
            "Epoch 274/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7285 - accuracy: 0.9219 - val_loss: 1.1483 - val_accuracy: 0.7083\n",
            "Epoch 275/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7585 - accuracy: 0.9028 - val_loss: 1.1495 - val_accuracy: 0.7014\n",
            "Epoch 276/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7547 - accuracy: 0.8872 - val_loss: 1.1539 - val_accuracy: 0.7292\n",
            "Epoch 277/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7390 - accuracy: 0.9080 - val_loss: 1.1653 - val_accuracy: 0.6944\n",
            "Epoch 278/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7732 - accuracy: 0.8715 - val_loss: 1.1409 - val_accuracy: 0.7153\n",
            "Epoch 279/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.7470 - accuracy: 0.9028 - val_loss: 1.1457 - val_accuracy: 0.7014\n",
            "Epoch 280/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7383 - accuracy: 0.9097 - val_loss: 1.1441 - val_accuracy: 0.7014\n",
            "Epoch 281/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7275 - accuracy: 0.9219 - val_loss: 1.1421 - val_accuracy: 0.7083\n",
            "Epoch 282/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7554 - accuracy: 0.9010 - val_loss: 1.1582 - val_accuracy: 0.7222\n",
            "Epoch 283/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7461 - accuracy: 0.9219 - val_loss: 1.1723 - val_accuracy: 0.6944\n",
            "Epoch 284/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7492 - accuracy: 0.9010 - val_loss: 1.1594 - val_accuracy: 0.7083\n",
            "Epoch 285/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7573 - accuracy: 0.8715 - val_loss: 1.1600 - val_accuracy: 0.7083\n",
            "Epoch 286/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7527 - accuracy: 0.8906 - val_loss: 1.1573 - val_accuracy: 0.6944\n",
            "Epoch 287/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7481 - accuracy: 0.9028 - val_loss: 1.1459 - val_accuracy: 0.6944\n",
            "Epoch 288/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7598 - accuracy: 0.9010 - val_loss: 1.1431 - val_accuracy: 0.7014\n",
            "Epoch 289/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7522 - accuracy: 0.9010 - val_loss: 1.1602 - val_accuracy: 0.6944\n",
            "Epoch 290/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7543 - accuracy: 0.8976 - val_loss: 1.1495 - val_accuracy: 0.7014\n",
            "Epoch 291/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7553 - accuracy: 0.8941 - val_loss: 1.1550 - val_accuracy: 0.7153\n",
            "Epoch 292/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7240 - accuracy: 0.9115 - val_loss: 1.1383 - val_accuracy: 0.7014\n",
            "Epoch 293/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7234 - accuracy: 0.9201 - val_loss: 1.1633 - val_accuracy: 0.7014\n",
            "Epoch 294/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7418 - accuracy: 0.9010 - val_loss: 1.1388 - val_accuracy: 0.7153\n",
            "Epoch 295/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7299 - accuracy: 0.9149 - val_loss: 1.1357 - val_accuracy: 0.7222\n",
            "Epoch 296/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7191 - accuracy: 0.9097 - val_loss: 1.1436 - val_accuracy: 0.7083\n",
            "Epoch 297/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7184 - accuracy: 0.9253 - val_loss: 1.1403 - val_accuracy: 0.7153\n",
            "Epoch 298/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7154 - accuracy: 0.9375 - val_loss: 1.1438 - val_accuracy: 0.7083\n",
            "Epoch 299/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7382 - accuracy: 0.9115 - val_loss: 1.1575 - val_accuracy: 0.7014\n",
            "Epoch 300/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6969 - accuracy: 0.9375 - val_loss: 1.1485 - val_accuracy: 0.7014\n",
            "Epoch 301/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7247 - accuracy: 0.9080 - val_loss: 1.1597 - val_accuracy: 0.6875\n",
            "Epoch 302/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7206 - accuracy: 0.9167 - val_loss: 1.1434 - val_accuracy: 0.7083\n",
            "Epoch 303/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7098 - accuracy: 0.9219 - val_loss: 1.1349 - val_accuracy: 0.7083\n",
            "Epoch 304/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7088 - accuracy: 0.9115 - val_loss: 1.1453 - val_accuracy: 0.7153\n",
            "Epoch 305/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7285 - accuracy: 0.9115 - val_loss: 1.1343 - val_accuracy: 0.6944\n",
            "Epoch 306/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7453 - accuracy: 0.9080 - val_loss: 1.1409 - val_accuracy: 0.7083\n",
            "Epoch 307/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7251 - accuracy: 0.9062 - val_loss: 1.1445 - val_accuracy: 0.7083\n",
            "Epoch 308/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7159 - accuracy: 0.9149 - val_loss: 1.1374 - val_accuracy: 0.7153\n",
            "Epoch 309/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7464 - accuracy: 0.9062 - val_loss: 1.1260 - val_accuracy: 0.7153\n",
            "Epoch 310/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7104 - accuracy: 0.9253 - val_loss: 1.1428 - val_accuracy: 0.6944\n",
            "Epoch 311/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7026 - accuracy: 0.9236 - val_loss: 1.1301 - val_accuracy: 0.7222\n",
            "Epoch 312/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7130 - accuracy: 0.9358 - val_loss: 1.1314 - val_accuracy: 0.7014\n",
            "Epoch 313/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7277 - accuracy: 0.9097 - val_loss: 1.1512 - val_accuracy: 0.7292\n",
            "Epoch 314/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7317 - accuracy: 0.9097 - val_loss: 1.1260 - val_accuracy: 0.7153\n",
            "Epoch 315/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7264 - accuracy: 0.9236 - val_loss: 1.1434 - val_accuracy: 0.6944\n",
            "Epoch 316/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6877 - accuracy: 0.9288 - val_loss: 1.1384 - val_accuracy: 0.7014\n",
            "Epoch 317/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7042 - accuracy: 0.9340 - val_loss: 1.1507 - val_accuracy: 0.7153\n",
            "Epoch 318/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7345 - accuracy: 0.9062 - val_loss: 1.1394 - val_accuracy: 0.7222\n",
            "Epoch 319/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6990 - accuracy: 0.9271 - val_loss: 1.1504 - val_accuracy: 0.7222\n",
            "Epoch 320/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6967 - accuracy: 0.9253 - val_loss: 1.1350 - val_accuracy: 0.7222\n",
            "Epoch 321/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6876 - accuracy: 0.9375 - val_loss: 1.1640 - val_accuracy: 0.7222\n",
            "Epoch 322/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7069 - accuracy: 0.9132 - val_loss: 1.1631 - val_accuracy: 0.6875\n",
            "Epoch 323/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6958 - accuracy: 0.9306 - val_loss: 1.1391 - val_accuracy: 0.7222\n",
            "Epoch 324/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7095 - accuracy: 0.9219 - val_loss: 1.1221 - val_accuracy: 0.7083\n",
            "Epoch 325/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7021 - accuracy: 0.9288 - val_loss: 1.1380 - val_accuracy: 0.7292\n",
            "Epoch 326/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7150 - accuracy: 0.9132 - val_loss: 1.1284 - val_accuracy: 0.7222\n",
            "Epoch 327/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6878 - accuracy: 0.9392 - val_loss: 1.1138 - val_accuracy: 0.7083\n",
            "Epoch 328/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6883 - accuracy: 0.9236 - val_loss: 1.1240 - val_accuracy: 0.7083\n",
            "Epoch 329/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6867 - accuracy: 0.9392 - val_loss: 1.1153 - val_accuracy: 0.6806\n",
            "Epoch 330/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7176 - accuracy: 0.9184 - val_loss: 1.1133 - val_accuracy: 0.7222\n",
            "Epoch 331/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7025 - accuracy: 0.9410 - val_loss: 1.1361 - val_accuracy: 0.7153\n",
            "Epoch 332/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6879 - accuracy: 0.9271 - val_loss: 1.1154 - val_accuracy: 0.6944\n",
            "Epoch 333/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6945 - accuracy: 0.9340 - val_loss: 1.1173 - val_accuracy: 0.7014\n",
            "Epoch 334/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6845 - accuracy: 0.9375 - val_loss: 1.1200 - val_accuracy: 0.7153\n",
            "Epoch 335/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6955 - accuracy: 0.9219 - val_loss: 1.1143 - val_accuracy: 0.7153\n",
            "Epoch 336/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6937 - accuracy: 0.9358 - val_loss: 1.1232 - val_accuracy: 0.7222\n",
            "Epoch 337/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.7211 - accuracy: 0.8906 - val_loss: 1.1207 - val_accuracy: 0.7153\n",
            "Epoch 338/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7009 - accuracy: 0.9236 - val_loss: 1.1164 - val_accuracy: 0.7153\n",
            "Epoch 339/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6909 - accuracy: 0.9306 - val_loss: 1.1310 - val_accuracy: 0.7153\n",
            "Epoch 340/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6926 - accuracy: 0.9201 - val_loss: 1.1288 - val_accuracy: 0.7014\n",
            "Epoch 341/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6771 - accuracy: 0.9375 - val_loss: 1.1302 - val_accuracy: 0.7153\n",
            "Epoch 342/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6969 - accuracy: 0.9201 - val_loss: 1.1262 - val_accuracy: 0.7222\n",
            "Epoch 343/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6907 - accuracy: 0.9201 - val_loss: 1.1284 - val_accuracy: 0.7361\n",
            "Epoch 344/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6898 - accuracy: 0.9253 - val_loss: 1.1296 - val_accuracy: 0.7222\n",
            "Epoch 345/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6774 - accuracy: 0.9340 - val_loss: 1.1304 - val_accuracy: 0.7153\n",
            "Epoch 346/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6830 - accuracy: 0.9375 - val_loss: 1.1374 - val_accuracy: 0.7083\n",
            "Epoch 347/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6812 - accuracy: 0.9306 - val_loss: 1.1334 - val_accuracy: 0.7014\n",
            "Epoch 348/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6889 - accuracy: 0.9184 - val_loss: 1.1255 - val_accuracy: 0.7014\n",
            "Epoch 349/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6883 - accuracy: 0.9340 - val_loss: 1.1245 - val_accuracy: 0.6875\n",
            "Epoch 350/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6780 - accuracy: 0.9288 - val_loss: 1.1203 - val_accuracy: 0.7083\n",
            "Epoch 351/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6648 - accuracy: 0.9410 - val_loss: 1.1298 - val_accuracy: 0.7083\n",
            "Epoch 352/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6845 - accuracy: 0.9340 - val_loss: 1.1294 - val_accuracy: 0.7083\n",
            "Epoch 353/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6909 - accuracy: 0.9358 - val_loss: 1.1141 - val_accuracy: 0.7153\n",
            "Epoch 354/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6815 - accuracy: 0.9375 - val_loss: 1.1212 - val_accuracy: 0.7083\n",
            "Epoch 355/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6822 - accuracy: 0.9323 - val_loss: 1.1271 - val_accuracy: 0.7222\n",
            "Epoch 356/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6634 - accuracy: 0.9549 - val_loss: 1.1171 - val_accuracy: 0.7292\n",
            "Epoch 357/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6936 - accuracy: 0.9097 - val_loss: 1.1259 - val_accuracy: 0.7222\n",
            "Epoch 358/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6717 - accuracy: 0.9392 - val_loss: 1.1241 - val_accuracy: 0.6944\n",
            "Epoch 359/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6661 - accuracy: 0.9479 - val_loss: 1.1162 - val_accuracy: 0.7014\n",
            "Epoch 360/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6771 - accuracy: 0.9253 - val_loss: 1.1357 - val_accuracy: 0.7014\n",
            "Epoch 361/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6753 - accuracy: 0.9462 - val_loss: 1.1139 - val_accuracy: 0.7222\n",
            "Epoch 362/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6623 - accuracy: 0.9375 - val_loss: 1.1175 - val_accuracy: 0.7014\n",
            "Epoch 363/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6556 - accuracy: 0.9427 - val_loss: 1.1302 - val_accuracy: 0.7153\n",
            "Epoch 364/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6665 - accuracy: 0.9358 - val_loss: 1.1416 - val_accuracy: 0.6944\n",
            "Epoch 365/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6531 - accuracy: 0.9549 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
            "Epoch 366/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6505 - accuracy: 0.9444 - val_loss: 1.1301 - val_accuracy: 0.7222\n",
            "Epoch 367/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6692 - accuracy: 0.9375 - val_loss: 1.1112 - val_accuracy: 0.7222\n",
            "Epoch 368/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6607 - accuracy: 0.9514 - val_loss: 1.1093 - val_accuracy: 0.7083\n",
            "Epoch 369/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6551 - accuracy: 0.9427 - val_loss: 1.1238 - val_accuracy: 0.7153\n",
            "Epoch 370/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6415 - accuracy: 0.9583 - val_loss: 1.1224 - val_accuracy: 0.7083\n",
            "Epoch 371/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6552 - accuracy: 0.9531 - val_loss: 1.1220 - val_accuracy: 0.7083\n",
            "Epoch 372/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6423 - accuracy: 0.9410 - val_loss: 1.1121 - val_accuracy: 0.6875\n",
            "Epoch 373/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6590 - accuracy: 0.9392 - val_loss: 1.1099 - val_accuracy: 0.7083\n",
            "Epoch 374/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6589 - accuracy: 0.9444 - val_loss: 1.1254 - val_accuracy: 0.7083\n",
            "Epoch 375/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6462 - accuracy: 0.9549 - val_loss: 1.1212 - val_accuracy: 0.7222\n",
            "Epoch 376/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6442 - accuracy: 0.9479 - val_loss: 1.1180 - val_accuracy: 0.6806\n",
            "Epoch 377/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6349 - accuracy: 0.9566 - val_loss: 1.1308 - val_accuracy: 0.7222\n",
            "Epoch 378/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6628 - accuracy: 0.9375 - val_loss: 1.1087 - val_accuracy: 0.7014\n",
            "Epoch 379/700\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.6526 - accuracy: 0.9566 - val_loss: 1.1037 - val_accuracy: 0.7014\n",
            "Epoch 380/700\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.6517 - accuracy: 0.9549 - val_loss: 1.0970 - val_accuracy: 0.7083\n",
            "Epoch 381/700\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.6415 - accuracy: 0.9514 - val_loss: 1.1343 - val_accuracy: 0.7083\n",
            "Epoch 382/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6575 - accuracy: 0.9531 - val_loss: 1.1239 - val_accuracy: 0.7083\n",
            "Epoch 383/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6323 - accuracy: 0.9462 - val_loss: 1.1241 - val_accuracy: 0.7153\n",
            "Epoch 384/700\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.6271 - accuracy: 0.9670 - val_loss: 1.1130 - val_accuracy: 0.6944\n",
            "Epoch 385/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6628 - accuracy: 0.9462 - val_loss: 1.1208 - val_accuracy: 0.7222\n",
            "Epoch 386/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6433 - accuracy: 0.9392 - val_loss: 1.1216 - val_accuracy: 0.6875\n",
            "Epoch 387/700\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.6328 - accuracy: 0.9497 - val_loss: 1.1165 - val_accuracy: 0.7153\n",
            "Epoch 388/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6312 - accuracy: 0.9670 - val_loss: 1.1119 - val_accuracy: 0.7014\n",
            "Epoch 389/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6541 - accuracy: 0.9444 - val_loss: 1.1111 - val_accuracy: 0.7014\n",
            "Epoch 390/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6512 - accuracy: 0.9444 - val_loss: 1.1009 - val_accuracy: 0.6944\n",
            "Epoch 391/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6426 - accuracy: 0.9479 - val_loss: 1.1028 - val_accuracy: 0.6875\n",
            "Epoch 392/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6232 - accuracy: 0.9566 - val_loss: 1.1151 - val_accuracy: 0.7153\n",
            "Epoch 393/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6438 - accuracy: 0.9444 - val_loss: 1.1072 - val_accuracy: 0.7222\n",
            "Epoch 394/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6365 - accuracy: 0.9497 - val_loss: 1.0915 - val_accuracy: 0.7014\n",
            "Epoch 395/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6177 - accuracy: 0.9601 - val_loss: 1.0879 - val_accuracy: 0.7292\n",
            "Epoch 396/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6367 - accuracy: 0.9514 - val_loss: 1.1219 - val_accuracy: 0.7153\n",
            "Epoch 397/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6233 - accuracy: 0.9531 - val_loss: 1.1130 - val_accuracy: 0.6875\n",
            "Epoch 398/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6383 - accuracy: 0.9618 - val_loss: 1.1012 - val_accuracy: 0.7083\n",
            "Epoch 399/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6267 - accuracy: 0.9618 - val_loss: 1.0929 - val_accuracy: 0.7153\n",
            "Epoch 400/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6165 - accuracy: 0.9583 - val_loss: 1.1045 - val_accuracy: 0.7153\n",
            "Epoch 401/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6480 - accuracy: 0.9549 - val_loss: 1.1123 - val_accuracy: 0.7222\n",
            "Epoch 402/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6290 - accuracy: 0.9531 - val_loss: 1.0956 - val_accuracy: 0.7014\n",
            "Epoch 403/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6309 - accuracy: 0.9392 - val_loss: 1.1086 - val_accuracy: 0.6944\n",
            "Epoch 404/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6302 - accuracy: 0.9479 - val_loss: 1.1162 - val_accuracy: 0.7083\n",
            "Epoch 405/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6188 - accuracy: 0.9601 - val_loss: 1.0912 - val_accuracy: 0.7361\n",
            "Epoch 406/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6384 - accuracy: 0.9549 - val_loss: 1.0924 - val_accuracy: 0.7083\n",
            "Epoch 407/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6410 - accuracy: 0.9549 - val_loss: 1.1032 - val_accuracy: 0.7083\n",
            "Epoch 408/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6218 - accuracy: 0.9618 - val_loss: 1.0956 - val_accuracy: 0.7153\n",
            "Epoch 409/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6306 - accuracy: 0.9531 - val_loss: 1.1109 - val_accuracy: 0.7222\n",
            "Epoch 410/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6159 - accuracy: 0.9549 - val_loss: 1.0966 - val_accuracy: 0.7222\n",
            "Epoch 411/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6108 - accuracy: 0.9670 - val_loss: 1.1081 - val_accuracy: 0.7083\n",
            "Epoch 412/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6312 - accuracy: 0.9514 - val_loss: 1.0871 - val_accuracy: 0.7361\n",
            "Epoch 413/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6194 - accuracy: 0.9583 - val_loss: 1.0984 - val_accuracy: 0.7014\n",
            "Epoch 414/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6345 - accuracy: 0.9618 - val_loss: 1.0956 - val_accuracy: 0.7153\n",
            "Epoch 415/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6234 - accuracy: 0.9497 - val_loss: 1.0935 - val_accuracy: 0.7153\n",
            "Epoch 416/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6120 - accuracy: 0.9670 - val_loss: 1.1037 - val_accuracy: 0.7153\n",
            "Epoch 417/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6212 - accuracy: 0.9444 - val_loss: 1.1124 - val_accuracy: 0.7083\n",
            "Epoch 418/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6265 - accuracy: 0.9549 - val_loss: 1.1079 - val_accuracy: 0.7153\n",
            "Epoch 419/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5986 - accuracy: 0.9653 - val_loss: 1.1035 - val_accuracy: 0.7222\n",
            "Epoch 420/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5989 - accuracy: 0.9635 - val_loss: 1.0861 - val_accuracy: 0.7222\n",
            "Epoch 421/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5977 - accuracy: 0.9722 - val_loss: 1.0921 - val_accuracy: 0.7222\n",
            "Epoch 422/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6027 - accuracy: 0.9653 - val_loss: 1.0933 - val_accuracy: 0.7222\n",
            "Epoch 423/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6099 - accuracy: 0.9601 - val_loss: 1.0942 - val_accuracy: 0.7222\n",
            "Epoch 424/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6119 - accuracy: 0.9635 - val_loss: 1.1008 - val_accuracy: 0.7014\n",
            "Epoch 425/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6051 - accuracy: 0.9705 - val_loss: 1.1055 - val_accuracy: 0.7014\n",
            "Epoch 426/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6025 - accuracy: 0.9722 - val_loss: 1.0996 - val_accuracy: 0.7083\n",
            "Epoch 427/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6277 - accuracy: 0.9549 - val_loss: 1.1198 - val_accuracy: 0.6806\n",
            "Epoch 428/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6054 - accuracy: 0.9635 - val_loss: 1.1055 - val_accuracy: 0.7083\n",
            "Epoch 429/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6048 - accuracy: 0.9653 - val_loss: 1.1035 - val_accuracy: 0.7014\n",
            "Epoch 430/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6104 - accuracy: 0.9601 - val_loss: 1.1060 - val_accuracy: 0.7222\n",
            "Epoch 431/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6139 - accuracy: 0.9653 - val_loss: 1.1167 - val_accuracy: 0.7222\n",
            "Epoch 432/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6088 - accuracy: 0.9670 - val_loss: 1.1036 - val_accuracy: 0.7292\n",
            "Epoch 433/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6188 - accuracy: 0.9705 - val_loss: 1.1109 - val_accuracy: 0.7153\n",
            "Epoch 434/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5950 - accuracy: 0.9635 - val_loss: 1.0976 - val_accuracy: 0.7083\n",
            "Epoch 435/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6303 - accuracy: 0.9549 - val_loss: 1.0966 - val_accuracy: 0.6806\n",
            "Epoch 436/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6038 - accuracy: 0.9722 - val_loss: 1.1105 - val_accuracy: 0.7083\n",
            "Epoch 437/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6044 - accuracy: 0.9688 - val_loss: 1.0907 - val_accuracy: 0.7153\n",
            "Epoch 438/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6002 - accuracy: 0.9688 - val_loss: 1.1016 - val_accuracy: 0.7153\n",
            "Epoch 439/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6016 - accuracy: 0.9670 - val_loss: 1.1143 - val_accuracy: 0.7153\n",
            "Epoch 440/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6128 - accuracy: 0.9635 - val_loss: 1.0873 - val_accuracy: 0.7153\n",
            "Epoch 441/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6100 - accuracy: 0.9653 - val_loss: 1.0941 - val_accuracy: 0.7014\n",
            "Epoch 442/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6126 - accuracy: 0.9601 - val_loss: 1.0848 - val_accuracy: 0.7222\n",
            "Epoch 443/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6146 - accuracy: 0.9653 - val_loss: 1.0729 - val_accuracy: 0.6944\n",
            "Epoch 444/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6155 - accuracy: 0.9583 - val_loss: 1.0784 - val_accuracy: 0.7222\n",
            "Epoch 445/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5999 - accuracy: 0.9688 - val_loss: 1.0955 - val_accuracy: 0.6944\n",
            "Epoch 446/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6141 - accuracy: 0.9618 - val_loss: 1.0948 - val_accuracy: 0.7222\n",
            "Epoch 447/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6047 - accuracy: 0.9635 - val_loss: 1.0977 - val_accuracy: 0.7222\n",
            "Epoch 448/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5830 - accuracy: 0.9774 - val_loss: 1.0910 - val_accuracy: 0.6944\n",
            "Epoch 449/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6111 - accuracy: 0.9549 - val_loss: 1.0931 - val_accuracy: 0.7222\n",
            "Epoch 450/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.6180 - accuracy: 0.9531 - val_loss: 1.0891 - val_accuracy: 0.7292\n",
            "Epoch 451/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5855 - accuracy: 0.9792 - val_loss: 1.0972 - val_accuracy: 0.7014\n",
            "Epoch 452/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5864 - accuracy: 0.9757 - val_loss: 1.0885 - val_accuracy: 0.7222\n",
            "Epoch 453/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5934 - accuracy: 0.9653 - val_loss: 1.0813 - val_accuracy: 0.7083\n",
            "Epoch 454/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6038 - accuracy: 0.9688 - val_loss: 1.0726 - val_accuracy: 0.7222\n",
            "Epoch 455/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5845 - accuracy: 0.9705 - val_loss: 1.0766 - val_accuracy: 0.7014\n",
            "Epoch 456/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6007 - accuracy: 0.9740 - val_loss: 1.0952 - val_accuracy: 0.7083\n",
            "Epoch 457/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5909 - accuracy: 0.9583 - val_loss: 1.0907 - val_accuracy: 0.7153\n",
            "Epoch 458/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5894 - accuracy: 0.9705 - val_loss: 1.0841 - val_accuracy: 0.7014\n",
            "Epoch 459/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5916 - accuracy: 0.9670 - val_loss: 1.0858 - val_accuracy: 0.6944\n",
            "Epoch 460/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5927 - accuracy: 0.9809 - val_loss: 1.0948 - val_accuracy: 0.7083\n",
            "Epoch 461/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5917 - accuracy: 0.9705 - val_loss: 1.0975 - val_accuracy: 0.7014\n",
            "Epoch 462/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5770 - accuracy: 0.9722 - val_loss: 1.0952 - val_accuracy: 0.6806\n",
            "Epoch 463/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5886 - accuracy: 0.9670 - val_loss: 1.0998 - val_accuracy: 0.7083\n",
            "Epoch 464/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5741 - accuracy: 0.9844 - val_loss: 1.0799 - val_accuracy: 0.7083\n",
            "Epoch 465/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5865 - accuracy: 0.9670 - val_loss: 1.0923 - val_accuracy: 0.7153\n",
            "Epoch 466/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5920 - accuracy: 0.9653 - val_loss: 1.0901 - val_accuracy: 0.6944\n",
            "Epoch 467/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5829 - accuracy: 0.9722 - val_loss: 1.0899 - val_accuracy: 0.7153\n",
            "Epoch 468/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5820 - accuracy: 0.9826 - val_loss: 1.0872 - val_accuracy: 0.7153\n",
            "Epoch 469/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5732 - accuracy: 0.9809 - val_loss: 1.1023 - val_accuracy: 0.7083\n",
            "Epoch 470/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5791 - accuracy: 0.9774 - val_loss: 1.0898 - val_accuracy: 0.7083\n",
            "Epoch 471/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5812 - accuracy: 0.9740 - val_loss: 1.0889 - val_accuracy: 0.7014\n",
            "Epoch 472/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5636 - accuracy: 0.9757 - val_loss: 1.0958 - val_accuracy: 0.7431\n",
            "Epoch 473/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5957 - accuracy: 0.9549 - val_loss: 1.0902 - val_accuracy: 0.7153\n",
            "Epoch 474/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5821 - accuracy: 0.9757 - val_loss: 1.0856 - val_accuracy: 0.7153\n",
            "Epoch 475/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5576 - accuracy: 0.9896 - val_loss: 1.0892 - val_accuracy: 0.7083\n",
            "Epoch 476/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5732 - accuracy: 0.9618 - val_loss: 1.0947 - val_accuracy: 0.7014\n",
            "Epoch 477/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5870 - accuracy: 0.9722 - val_loss: 1.0779 - val_accuracy: 0.6944\n",
            "Epoch 478/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5755 - accuracy: 0.9566 - val_loss: 1.0742 - val_accuracy: 0.7014\n",
            "Epoch 479/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5787 - accuracy: 0.9688 - val_loss: 1.0873 - val_accuracy: 0.7014\n",
            "Epoch 480/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5813 - accuracy: 0.9670 - val_loss: 1.0830 - val_accuracy: 0.7153\n",
            "Epoch 481/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5898 - accuracy: 0.9670 - val_loss: 1.0768 - val_accuracy: 0.6944\n",
            "Epoch 482/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5825 - accuracy: 0.9705 - val_loss: 1.0885 - val_accuracy: 0.6736\n",
            "Epoch 483/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5845 - accuracy: 0.9844 - val_loss: 1.0654 - val_accuracy: 0.6944\n",
            "Epoch 484/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5759 - accuracy: 0.9635 - val_loss: 1.0796 - val_accuracy: 0.6806\n",
            "Epoch 485/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5787 - accuracy: 0.9740 - val_loss: 1.0603 - val_accuracy: 0.7014\n",
            "Epoch 486/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5745 - accuracy: 0.9705 - val_loss: 1.0707 - val_accuracy: 0.6944\n",
            "Epoch 487/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5612 - accuracy: 0.9757 - val_loss: 1.0842 - val_accuracy: 0.7014\n",
            "Epoch 488/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5550 - accuracy: 0.9740 - val_loss: 1.0997 - val_accuracy: 0.6944\n",
            "Epoch 489/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5712 - accuracy: 0.9774 - val_loss: 1.0876 - val_accuracy: 0.6944\n",
            "Epoch 490/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5668 - accuracy: 0.9757 - val_loss: 1.1162 - val_accuracy: 0.6875\n",
            "Epoch 491/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5769 - accuracy: 0.9774 - val_loss: 1.0758 - val_accuracy: 0.6944\n",
            "Epoch 492/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5690 - accuracy: 0.9740 - val_loss: 1.0945 - val_accuracy: 0.6944\n",
            "Epoch 493/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5608 - accuracy: 0.9757 - val_loss: 1.0751 - val_accuracy: 0.7083\n",
            "Epoch 494/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5635 - accuracy: 0.9740 - val_loss: 1.0696 - val_accuracy: 0.7014\n",
            "Epoch 495/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5514 - accuracy: 0.9878 - val_loss: 1.0981 - val_accuracy: 0.6944\n",
            "Epoch 496/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5692 - accuracy: 0.9705 - val_loss: 1.0741 - val_accuracy: 0.7014\n",
            "Epoch 497/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5789 - accuracy: 0.9635 - val_loss: 1.0655 - val_accuracy: 0.6944\n",
            "Epoch 498/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5644 - accuracy: 0.9861 - val_loss: 1.0939 - val_accuracy: 0.6875\n",
            "Epoch 499/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5589 - accuracy: 0.9809 - val_loss: 1.0931 - val_accuracy: 0.6944\n",
            "Epoch 500/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5570 - accuracy: 0.9792 - val_loss: 1.0723 - val_accuracy: 0.7014\n",
            "Epoch 501/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5745 - accuracy: 0.9861 - val_loss: 1.0799 - val_accuracy: 0.6944\n",
            "Epoch 502/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5593 - accuracy: 0.9774 - val_loss: 1.0955 - val_accuracy: 0.6944\n",
            "Epoch 503/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5727 - accuracy: 0.9774 - val_loss: 1.0885 - val_accuracy: 0.7153\n",
            "Epoch 504/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5633 - accuracy: 0.9705 - val_loss: 1.0913 - val_accuracy: 0.7014\n",
            "Epoch 505/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5644 - accuracy: 0.9774 - val_loss: 1.0910 - val_accuracy: 0.7153\n",
            "Epoch 506/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5731 - accuracy: 0.9653 - val_loss: 1.0643 - val_accuracy: 0.7083\n",
            "Epoch 507/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5701 - accuracy: 0.9722 - val_loss: 1.0782 - val_accuracy: 0.6944\n",
            "Epoch 508/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5435 - accuracy: 0.9896 - val_loss: 1.0887 - val_accuracy: 0.6875\n",
            "Epoch 509/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5483 - accuracy: 0.9844 - val_loss: 1.0786 - val_accuracy: 0.7083\n",
            "Epoch 510/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5656 - accuracy: 0.9757 - val_loss: 1.0659 - val_accuracy: 0.7083\n",
            "Epoch 511/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5615 - accuracy: 0.9722 - val_loss: 1.0692 - val_accuracy: 0.7153\n",
            "Epoch 512/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5479 - accuracy: 0.9878 - val_loss: 1.0660 - val_accuracy: 0.7153\n",
            "Epoch 513/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5620 - accuracy: 0.9757 - val_loss: 1.0693 - val_accuracy: 0.6806\n",
            "Epoch 514/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5683 - accuracy: 0.9688 - val_loss: 1.0745 - val_accuracy: 0.7014\n",
            "Epoch 515/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5523 - accuracy: 0.9861 - val_loss: 1.0870 - val_accuracy: 0.7153\n",
            "Epoch 516/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5382 - accuracy: 0.9844 - val_loss: 1.0860 - val_accuracy: 0.7014\n",
            "Epoch 517/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5490 - accuracy: 0.9826 - val_loss: 1.0799 - val_accuracy: 0.7083\n",
            "Epoch 518/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5330 - accuracy: 0.9878 - val_loss: 1.0861 - val_accuracy: 0.6875\n",
            "Epoch 519/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5561 - accuracy: 0.9861 - val_loss: 1.0695 - val_accuracy: 0.6944\n",
            "Epoch 520/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5628 - accuracy: 0.9722 - val_loss: 1.0703 - val_accuracy: 0.7222\n",
            "Epoch 521/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5602 - accuracy: 0.9705 - val_loss: 1.0714 - val_accuracy: 0.7222\n",
            "Epoch 522/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5520 - accuracy: 0.9809 - val_loss: 1.0766 - val_accuracy: 0.7153\n",
            "Epoch 523/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5670 - accuracy: 0.9826 - val_loss: 1.0803 - val_accuracy: 0.7153\n",
            "Epoch 524/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5456 - accuracy: 0.9792 - val_loss: 1.0653 - val_accuracy: 0.6944\n",
            "Epoch 525/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5473 - accuracy: 0.9792 - val_loss: 1.0625 - val_accuracy: 0.7153\n",
            "Epoch 526/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5546 - accuracy: 0.9757 - val_loss: 1.0655 - val_accuracy: 0.6875\n",
            "Epoch 527/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5588 - accuracy: 0.9826 - val_loss: 1.0745 - val_accuracy: 0.7222\n",
            "Epoch 528/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5399 - accuracy: 0.9792 - val_loss: 1.0763 - val_accuracy: 0.6875\n",
            "Epoch 529/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5295 - accuracy: 0.9896 - val_loss: 1.0938 - val_accuracy: 0.7153\n",
            "Epoch 530/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5397 - accuracy: 0.9809 - val_loss: 1.0720 - val_accuracy: 0.7014\n",
            "Epoch 531/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5365 - accuracy: 0.9861 - val_loss: 1.0773 - val_accuracy: 0.7014\n",
            "Epoch 532/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5499 - accuracy: 0.9792 - val_loss: 1.0641 - val_accuracy: 0.7153\n",
            "Epoch 533/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5474 - accuracy: 0.9861 - val_loss: 1.0796 - val_accuracy: 0.7153\n",
            "Epoch 534/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5551 - accuracy: 0.9757 - val_loss: 1.0697 - val_accuracy: 0.7222\n",
            "Epoch 535/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5379 - accuracy: 0.9826 - val_loss: 1.0746 - val_accuracy: 0.7083\n",
            "Epoch 536/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5562 - accuracy: 0.9809 - val_loss: 1.0850 - val_accuracy: 0.6944\n",
            "Epoch 537/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5551 - accuracy: 0.9809 - val_loss: 1.0949 - val_accuracy: 0.7153\n",
            "Epoch 538/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5416 - accuracy: 0.9792 - val_loss: 1.0725 - val_accuracy: 0.7083\n",
            "Epoch 539/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5311 - accuracy: 0.9913 - val_loss: 1.0629 - val_accuracy: 0.7014\n",
            "Epoch 540/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5582 - accuracy: 0.9844 - val_loss: 1.0697 - val_accuracy: 0.7222\n",
            "Epoch 541/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5536 - accuracy: 0.9722 - val_loss: 1.0808 - val_accuracy: 0.7153\n",
            "Epoch 542/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5487 - accuracy: 0.9826 - val_loss: 1.0673 - val_accuracy: 0.7083\n",
            "Epoch 543/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5493 - accuracy: 0.9878 - val_loss: 1.0717 - val_accuracy: 0.6875\n",
            "Epoch 544/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5440 - accuracy: 0.9826 - val_loss: 1.0615 - val_accuracy: 0.6944\n",
            "Epoch 545/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5432 - accuracy: 0.9774 - val_loss: 1.0722 - val_accuracy: 0.6875\n",
            "Epoch 546/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5375 - accuracy: 0.9757 - val_loss: 1.0758 - val_accuracy: 0.7014\n",
            "Epoch 547/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5205 - accuracy: 0.9896 - val_loss: 1.0821 - val_accuracy: 0.7014\n",
            "Epoch 548/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5372 - accuracy: 0.9826 - val_loss: 1.0701 - val_accuracy: 0.6806\n",
            "Epoch 549/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5338 - accuracy: 0.9896 - val_loss: 1.0547 - val_accuracy: 0.7153\n",
            "Epoch 550/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5433 - accuracy: 0.9844 - val_loss: 1.0728 - val_accuracy: 0.7014\n",
            "Epoch 551/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5444 - accuracy: 0.9757 - val_loss: 1.0629 - val_accuracy: 0.7222\n",
            "Epoch 552/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5516 - accuracy: 0.9844 - val_loss: 1.0629 - val_accuracy: 0.7292\n",
            "Epoch 553/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5098 - accuracy: 0.9844 - val_loss: 1.0703 - val_accuracy: 0.7222\n",
            "Epoch 554/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5383 - accuracy: 0.9913 - val_loss: 1.0535 - val_accuracy: 0.7222\n",
            "Epoch 555/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5350 - accuracy: 0.9878 - val_loss: 1.0702 - val_accuracy: 0.7153\n",
            "Epoch 556/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5390 - accuracy: 0.9878 - val_loss: 1.0755 - val_accuracy: 0.6944\n",
            "Epoch 557/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5340 - accuracy: 0.9826 - val_loss: 1.0647 - val_accuracy: 0.7222\n",
            "Epoch 558/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5248 - accuracy: 0.9861 - val_loss: 1.0775 - val_accuracy: 0.7153\n",
            "Epoch 559/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5334 - accuracy: 0.9896 - val_loss: 1.0705 - val_accuracy: 0.7083\n",
            "Epoch 560/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5368 - accuracy: 0.9844 - val_loss: 1.0769 - val_accuracy: 0.7153\n",
            "Epoch 561/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5391 - accuracy: 0.9844 - val_loss: 1.0771 - val_accuracy: 0.7083\n",
            "Epoch 562/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5453 - accuracy: 0.9740 - val_loss: 1.0710 - val_accuracy: 0.6944\n",
            "Epoch 563/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5239 - accuracy: 0.9861 - val_loss: 1.0556 - val_accuracy: 0.7083\n",
            "Epoch 564/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5174 - accuracy: 0.9896 - val_loss: 1.0472 - val_accuracy: 0.6944\n",
            "Epoch 565/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5276 - accuracy: 0.9809 - val_loss: 1.0753 - val_accuracy: 0.7083\n",
            "Epoch 566/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5233 - accuracy: 0.9878 - val_loss: 1.0632 - val_accuracy: 0.7153\n",
            "Epoch 567/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5449 - accuracy: 0.9809 - val_loss: 1.0683 - val_accuracy: 0.7083\n",
            "Epoch 568/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5312 - accuracy: 0.9774 - val_loss: 1.0658 - val_accuracy: 0.6944\n",
            "Epoch 569/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5285 - accuracy: 0.9878 - val_loss: 1.0726 - val_accuracy: 0.7083\n",
            "Epoch 570/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5338 - accuracy: 0.9826 - val_loss: 1.0632 - val_accuracy: 0.7222\n",
            "Epoch 571/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5322 - accuracy: 0.9931 - val_loss: 1.0779 - val_accuracy: 0.6875\n",
            "Epoch 572/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5390 - accuracy: 0.9809 - val_loss: 1.0693 - val_accuracy: 0.7083\n",
            "Epoch 573/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.5246 - accuracy: 0.9913 - val_loss: 1.0606 - val_accuracy: 0.7153\n",
            "Epoch 574/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5254 - accuracy: 0.9913 - val_loss: 1.0762 - val_accuracy: 0.7292\n",
            "Epoch 575/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5278 - accuracy: 0.9826 - val_loss: 1.0713 - val_accuracy: 0.7153\n",
            "Epoch 576/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5256 - accuracy: 0.9844 - val_loss: 1.0655 - val_accuracy: 0.7014\n",
            "Epoch 577/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5102 - accuracy: 0.9826 - val_loss: 1.0759 - val_accuracy: 0.7153\n",
            "Epoch 578/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5177 - accuracy: 0.9861 - val_loss: 1.0716 - val_accuracy: 0.7153\n",
            "Epoch 579/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5282 - accuracy: 0.9757 - val_loss: 1.0622 - val_accuracy: 0.7222\n",
            "Epoch 580/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5222 - accuracy: 0.9896 - val_loss: 1.0780 - val_accuracy: 0.7014\n",
            "Epoch 581/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5173 - accuracy: 0.9913 - val_loss: 1.0543 - val_accuracy: 0.7222\n",
            "Epoch 582/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5163 - accuracy: 0.9809 - val_loss: 1.0707 - val_accuracy: 0.7153\n",
            "Epoch 583/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5057 - accuracy: 0.9878 - val_loss: 1.0548 - val_accuracy: 0.7083\n",
            "Epoch 584/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5221 - accuracy: 0.9896 - val_loss: 1.0645 - val_accuracy: 0.7083\n",
            "Epoch 585/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5282 - accuracy: 0.9896 - val_loss: 1.0593 - val_accuracy: 0.6944\n",
            "Epoch 586/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5144 - accuracy: 0.9896 - val_loss: 1.0659 - val_accuracy: 0.7083\n",
            "Epoch 587/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5171 - accuracy: 0.9861 - val_loss: 1.0783 - val_accuracy: 0.7014\n",
            "Epoch 588/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5221 - accuracy: 0.9896 - val_loss: 1.0631 - val_accuracy: 0.7083\n",
            "Epoch 589/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5260 - accuracy: 0.9878 - val_loss: 1.0760 - val_accuracy: 0.7083\n",
            "Epoch 590/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5184 - accuracy: 0.9878 - val_loss: 1.0693 - val_accuracy: 0.7083\n",
            "Epoch 591/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5370 - accuracy: 0.9826 - val_loss: 1.0679 - val_accuracy: 0.7222\n",
            "Epoch 592/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5173 - accuracy: 0.9878 - val_loss: 1.0760 - val_accuracy: 0.7292\n",
            "Epoch 593/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5056 - accuracy: 0.9878 - val_loss: 1.0690 - val_accuracy: 0.7083\n",
            "Epoch 594/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5222 - accuracy: 0.9931 - val_loss: 1.0687 - val_accuracy: 0.7083\n",
            "Epoch 595/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5206 - accuracy: 0.9948 - val_loss: 1.0616 - val_accuracy: 0.7083\n",
            "Epoch 596/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5257 - accuracy: 0.9913 - val_loss: 1.0683 - val_accuracy: 0.7153\n",
            "Epoch 597/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5274 - accuracy: 0.9878 - val_loss: 1.0669 - val_accuracy: 0.7014\n",
            "Epoch 598/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4964 - accuracy: 0.9896 - val_loss: 1.0631 - val_accuracy: 0.7083\n",
            "Epoch 599/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5254 - accuracy: 0.9826 - val_loss: 1.0743 - val_accuracy: 0.7153\n",
            "Epoch 600/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5143 - accuracy: 0.9896 - val_loss: 1.0641 - val_accuracy: 0.7014\n",
            "Epoch 601/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5097 - accuracy: 0.9878 - val_loss: 1.0693 - val_accuracy: 0.6806\n",
            "Epoch 602/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5190 - accuracy: 0.9774 - val_loss: 1.0657 - val_accuracy: 0.7153\n",
            "Epoch 603/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5133 - accuracy: 0.9757 - val_loss: 1.0470 - val_accuracy: 0.7153\n",
            "Epoch 604/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5077 - accuracy: 0.9896 - val_loss: 1.0483 - val_accuracy: 0.7153\n",
            "Epoch 605/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5127 - accuracy: 0.9826 - val_loss: 1.0508 - val_accuracy: 0.7083\n",
            "Epoch 606/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4881 - accuracy: 0.9948 - val_loss: 1.0453 - val_accuracy: 0.7361\n",
            "Epoch 607/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5138 - accuracy: 0.9774 - val_loss: 1.0505 - val_accuracy: 0.7083\n",
            "Epoch 608/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4951 - accuracy: 0.9913 - val_loss: 1.0489 - val_accuracy: 0.7083\n",
            "Epoch 609/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5064 - accuracy: 0.9948 - val_loss: 1.0586 - val_accuracy: 0.6806\n",
            "Epoch 610/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5110 - accuracy: 0.9931 - val_loss: 1.0581 - val_accuracy: 0.6806\n",
            "Epoch 611/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5067 - accuracy: 0.9844 - val_loss: 1.0541 - val_accuracy: 0.7014\n",
            "Epoch 612/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5067 - accuracy: 0.9861 - val_loss: 1.0713 - val_accuracy: 0.7014\n",
            "Epoch 613/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5028 - accuracy: 0.9878 - val_loss: 1.0622 - val_accuracy: 0.7083\n",
            "Epoch 614/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5067 - accuracy: 0.9861 - val_loss: 1.0798 - val_accuracy: 0.6806\n",
            "Epoch 615/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5081 - accuracy: 0.9826 - val_loss: 1.0862 - val_accuracy: 0.7014\n",
            "Epoch 616/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4998 - accuracy: 0.9965 - val_loss: 1.0559 - val_accuracy: 0.7083\n",
            "Epoch 617/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.5056 - accuracy: 0.9948 - val_loss: 1.0649 - val_accuracy: 0.6875\n",
            "Epoch 618/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4996 - accuracy: 0.9931 - val_loss: 1.0549 - val_accuracy: 0.7222\n",
            "Epoch 619/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5042 - accuracy: 0.9896 - val_loss: 1.0619 - val_accuracy: 0.7014\n",
            "Epoch 620/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5059 - accuracy: 0.9896 - val_loss: 1.0672 - val_accuracy: 0.6875\n",
            "Epoch 621/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4959 - accuracy: 0.9931 - val_loss: 1.0515 - val_accuracy: 0.7014\n",
            "Epoch 622/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4966 - accuracy: 0.9913 - val_loss: 1.0702 - val_accuracy: 0.7014\n",
            "Epoch 623/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5089 - accuracy: 0.9896 - val_loss: 1.0726 - val_accuracy: 0.7153\n",
            "Epoch 624/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5137 - accuracy: 0.9878 - val_loss: 1.0700 - val_accuracy: 0.7014\n",
            "Epoch 625/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5097 - accuracy: 0.9878 - val_loss: 1.0800 - val_accuracy: 0.6944\n",
            "Epoch 626/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4984 - accuracy: 0.9913 - val_loss: 1.0481 - val_accuracy: 0.7014\n",
            "Epoch 627/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5041 - accuracy: 0.9861 - val_loss: 1.0754 - val_accuracy: 0.7083\n",
            "Epoch 628/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4981 - accuracy: 0.9826 - val_loss: 1.0532 - val_accuracy: 0.6944\n",
            "Epoch 629/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5001 - accuracy: 0.9913 - val_loss: 1.0490 - val_accuracy: 0.7014\n",
            "Epoch 630/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4856 - accuracy: 0.9896 - val_loss: 1.0575 - val_accuracy: 0.7153\n",
            "Epoch 631/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5156 - accuracy: 0.9896 - val_loss: 1.0575 - val_accuracy: 0.6875\n",
            "Epoch 632/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5035 - accuracy: 0.9913 - val_loss: 1.0600 - val_accuracy: 0.6806\n",
            "Epoch 633/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4926 - accuracy: 0.9896 - val_loss: 1.0647 - val_accuracy: 0.7083\n",
            "Epoch 634/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4956 - accuracy: 0.9861 - val_loss: 1.0565 - val_accuracy: 0.6875\n",
            "Epoch 635/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4988 - accuracy: 0.9931 - val_loss: 1.0574 - val_accuracy: 0.7014\n",
            "Epoch 636/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4857 - accuracy: 0.9948 - val_loss: 1.0679 - val_accuracy: 0.6875\n",
            "Epoch 637/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5036 - accuracy: 0.9878 - val_loss: 1.0777 - val_accuracy: 0.6806\n",
            "Epoch 638/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5041 - accuracy: 0.9826 - val_loss: 1.0573 - val_accuracy: 0.6944\n",
            "Epoch 639/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5015 - accuracy: 0.9878 - val_loss: 1.0591 - val_accuracy: 0.6875\n",
            "Epoch 640/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4838 - accuracy: 0.9948 - val_loss: 1.0483 - val_accuracy: 0.7222\n",
            "Epoch 641/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4862 - accuracy: 0.9983 - val_loss: 1.0667 - val_accuracy: 0.6875\n",
            "Epoch 642/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4977 - accuracy: 0.9861 - val_loss: 1.0456 - val_accuracy: 0.7014\n",
            "Epoch 643/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4882 - accuracy: 0.9931 - val_loss: 1.0475 - val_accuracy: 0.7014\n",
            "Epoch 644/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4969 - accuracy: 0.9878 - val_loss: 1.0522 - val_accuracy: 0.6944\n",
            "Epoch 645/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4923 - accuracy: 0.9965 - val_loss: 1.0484 - val_accuracy: 0.7014\n",
            "Epoch 646/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5016 - accuracy: 0.9913 - val_loss: 1.0465 - val_accuracy: 0.6875\n",
            "Epoch 647/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4962 - accuracy: 0.9931 - val_loss: 1.0517 - val_accuracy: 0.6944\n",
            "Epoch 648/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4827 - accuracy: 0.9931 - val_loss: 1.0427 - val_accuracy: 0.7083\n",
            "Epoch 649/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4892 - accuracy: 0.9965 - val_loss: 1.0565 - val_accuracy: 0.7083\n",
            "Epoch 650/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4915 - accuracy: 0.9913 - val_loss: 1.0562 - val_accuracy: 0.7014\n",
            "Epoch 651/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4859 - accuracy: 0.9931 - val_loss: 1.0743 - val_accuracy: 0.7014\n",
            "Epoch 652/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4943 - accuracy: 0.9844 - val_loss: 1.0708 - val_accuracy: 0.7014\n",
            "Epoch 653/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4884 - accuracy: 0.9913 - val_loss: 1.0640 - val_accuracy: 0.7014\n",
            "Epoch 654/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4783 - accuracy: 0.9913 - val_loss: 1.0558 - val_accuracy: 0.7083\n",
            "Epoch 655/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4817 - accuracy: 0.9913 - val_loss: 1.0603 - val_accuracy: 0.7014\n",
            "Epoch 656/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4948 - accuracy: 0.9844 - val_loss: 1.0671 - val_accuracy: 0.7083\n",
            "Epoch 657/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4767 - accuracy: 1.0000 - val_loss: 1.0637 - val_accuracy: 0.6875\n",
            "Epoch 658/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4840 - accuracy: 0.9948 - val_loss: 1.0638 - val_accuracy: 0.7083\n",
            "Epoch 659/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4739 - accuracy: 0.9948 - val_loss: 1.0638 - val_accuracy: 0.6875\n",
            "Epoch 660/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4897 - accuracy: 0.9878 - val_loss: 1.0663 - val_accuracy: 0.6875\n",
            "Epoch 661/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4853 - accuracy: 0.9983 - val_loss: 1.0657 - val_accuracy: 0.7153\n",
            "Epoch 662/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4925 - accuracy: 0.9878 - val_loss: 1.0665 - val_accuracy: 0.7083\n",
            "Epoch 663/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4883 - accuracy: 0.9931 - val_loss: 1.0662 - val_accuracy: 0.6875\n",
            "Epoch 664/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4846 - accuracy: 0.9878 - val_loss: 1.0703 - val_accuracy: 0.7014\n",
            "Epoch 665/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4753 - accuracy: 0.9913 - val_loss: 1.0571 - val_accuracy: 0.7014\n",
            "Epoch 666/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4906 - accuracy: 0.9931 - val_loss: 1.0414 - val_accuracy: 0.6944\n",
            "Epoch 667/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4702 - accuracy: 0.9983 - val_loss: 1.0560 - val_accuracy: 0.6944\n",
            "Epoch 668/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4928 - accuracy: 0.9913 - val_loss: 1.0745 - val_accuracy: 0.6944\n",
            "Epoch 669/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4936 - accuracy: 0.9896 - val_loss: 1.0739 - val_accuracy: 0.7083\n",
            "Epoch 670/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5012 - accuracy: 0.9861 - val_loss: 1.0732 - val_accuracy: 0.7014\n",
            "Epoch 671/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4819 - accuracy: 0.9913 - val_loss: 1.0641 - val_accuracy: 0.7222\n",
            "Epoch 672/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4865 - accuracy: 0.9983 - val_loss: 1.0611 - val_accuracy: 0.7014\n",
            "Epoch 673/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4771 - accuracy: 0.9931 - val_loss: 1.0493 - val_accuracy: 0.7153\n",
            "Epoch 674/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4960 - accuracy: 0.9861 - val_loss: 1.0577 - val_accuracy: 0.7014\n",
            "Epoch 675/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4760 - accuracy: 0.9861 - val_loss: 1.0739 - val_accuracy: 0.6944\n",
            "Epoch 676/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4907 - accuracy: 0.9844 - val_loss: 1.0505 - val_accuracy: 0.7153\n",
            "Epoch 677/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 0.4920 - accuracy: 0.9896 - val_loss: 1.0512 - val_accuracy: 0.7083\n",
            "Epoch 678/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4864 - accuracy: 0.9948 - val_loss: 1.0443 - val_accuracy: 0.6875\n",
            "Epoch 679/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4830 - accuracy: 0.9913 - val_loss: 1.0341 - val_accuracy: 0.7153\n",
            "Epoch 680/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4682 - accuracy: 0.9896 - val_loss: 1.0483 - val_accuracy: 0.7014\n",
            "Epoch 681/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4887 - accuracy: 0.9931 - val_loss: 1.0500 - val_accuracy: 0.7014\n",
            "Epoch 682/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4800 - accuracy: 0.9983 - val_loss: 1.0552 - val_accuracy: 0.7083\n",
            "Epoch 683/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4693 - accuracy: 0.9965 - val_loss: 1.0645 - val_accuracy: 0.7083\n",
            "Epoch 684/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4728 - accuracy: 0.9931 - val_loss: 1.0571 - val_accuracy: 0.7083\n",
            "Epoch 685/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4793 - accuracy: 0.9913 - val_loss: 1.0338 - val_accuracy: 0.7153\n",
            "Epoch 686/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4817 - accuracy: 0.9965 - val_loss: 1.0444 - val_accuracy: 0.7083\n",
            "Epoch 687/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4715 - accuracy: 0.9965 - val_loss: 1.0457 - val_accuracy: 0.7153\n",
            "Epoch 688/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4812 - accuracy: 1.0000 - val_loss: 1.0529 - val_accuracy: 0.7153\n",
            "Epoch 689/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4712 - accuracy: 0.9896 - val_loss: 1.0332 - val_accuracy: 0.7222\n",
            "Epoch 690/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4780 - accuracy: 0.9896 - val_loss: 1.0471 - val_accuracy: 0.7153\n",
            "Epoch 691/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4879 - accuracy: 0.9896 - val_loss: 1.0460 - val_accuracy: 0.7014\n",
            "Epoch 692/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4870 - accuracy: 0.9913 - val_loss: 1.0444 - val_accuracy: 0.6944\n",
            "Epoch 693/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4750 - accuracy: 0.9965 - val_loss: 1.0448 - val_accuracy: 0.6875\n",
            "Epoch 694/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4736 - accuracy: 0.9965 - val_loss: 1.0547 - val_accuracy: 0.6736\n",
            "Epoch 695/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4669 - accuracy: 0.9931 - val_loss: 1.0500 - val_accuracy: 0.7222\n",
            "Epoch 696/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4795 - accuracy: 0.9948 - val_loss: 1.0580 - val_accuracy: 0.6875\n",
            "Epoch 697/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4836 - accuracy: 0.9965 - val_loss: 1.0492 - val_accuracy: 0.7083\n",
            "Epoch 698/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4662 - accuracy: 0.9948 - val_loss: 1.0408 - val_accuracy: 0.7083\n",
            "Epoch 699/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4636 - accuracy: 0.9983 - val_loss: 1.0479 - val_accuracy: 0.6875\n",
            "Epoch 700/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4625 - accuracy: 0.9983 - val_loss: 1.0651 - val_accuracy: 0.7014\n",
            "2\n",
            "Epoch 1/700\n",
            "9/9 [==============================] - 2s 101ms/step - loss: 2.3847 - accuracy: 0.1476 - val_loss: 2.2229 - val_accuracy: 0.1181\n",
            "Epoch 2/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 2.2957 - accuracy: 0.1736 - val_loss: 2.1620 - val_accuracy: 0.1250\n",
            "Epoch 3/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 2.2215 - accuracy: 0.1979 - val_loss: 2.1200 - val_accuracy: 0.1319\n",
            "Epoch 4/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 2.1982 - accuracy: 0.1944 - val_loss: 2.0917 - val_accuracy: 0.1181\n",
            "Epoch 5/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 2.1468 - accuracy: 0.2049 - val_loss: 2.0676 - val_accuracy: 0.0903\n",
            "Epoch 6/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 2.0372 - accuracy: 0.2344 - val_loss: 2.0426 - val_accuracy: 0.0903\n",
            "Epoch 7/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 2.0850 - accuracy: 0.2240 - val_loss: 2.0221 - val_accuracy: 0.1319\n",
            "Epoch 8/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 2.0038 - accuracy: 0.2656 - val_loss: 2.0075 - val_accuracy: 0.1875\n",
            "Epoch 9/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.9803 - accuracy: 0.2448 - val_loss: 1.9996 - val_accuracy: 0.1736\n",
            "Epoch 10/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.8753 - accuracy: 0.3194 - val_loss: 1.9965 - val_accuracy: 0.1667\n",
            "Epoch 11/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.8905 - accuracy: 0.2986 - val_loss: 2.0000 - val_accuracy: 0.2014\n",
            "Epoch 12/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.8391 - accuracy: 0.3038 - val_loss: 2.0020 - val_accuracy: 0.2014\n",
            "Epoch 13/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.8918 - accuracy: 0.2778 - val_loss: 2.0014 - val_accuracy: 0.1528\n",
            "Epoch 14/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.8029 - accuracy: 0.3403 - val_loss: 2.0054 - val_accuracy: 0.1528\n",
            "Epoch 15/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.7636 - accuracy: 0.3264 - val_loss: 2.0112 - val_accuracy: 0.1528\n",
            "Epoch 16/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.7304 - accuracy: 0.3385 - val_loss: 2.0120 - val_accuracy: 0.1597\n",
            "Epoch 17/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.7616 - accuracy: 0.3611 - val_loss: 2.0125 - val_accuracy: 0.1528\n",
            "Epoch 18/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.7489 - accuracy: 0.3542 - val_loss: 2.0207 - val_accuracy: 0.1528\n",
            "Epoch 19/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.7188 - accuracy: 0.3507 - val_loss: 2.0255 - val_accuracy: 0.1458\n",
            "Epoch 20/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.7369 - accuracy: 0.3524 - val_loss: 2.0207 - val_accuracy: 0.1389\n",
            "Epoch 21/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6691 - accuracy: 0.4028 - val_loss: 2.0147 - val_accuracy: 0.1389\n",
            "Epoch 22/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6431 - accuracy: 0.3854 - val_loss: 2.0172 - val_accuracy: 0.1389\n",
            "Epoch 23/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6625 - accuracy: 0.3524 - val_loss: 2.0064 - val_accuracy: 0.1389\n",
            "Epoch 24/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6309 - accuracy: 0.3906 - val_loss: 2.0094 - val_accuracy: 0.1389\n",
            "Epoch 25/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.6485 - accuracy: 0.3889 - val_loss: 2.0201 - val_accuracy: 0.1389\n",
            "Epoch 26/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.5996 - accuracy: 0.3854 - val_loss: 2.0132 - val_accuracy: 0.1389\n",
            "Epoch 27/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.6110 - accuracy: 0.4219 - val_loss: 2.0069 - val_accuracy: 0.1389\n",
            "Epoch 28/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.5934 - accuracy: 0.3993 - val_loss: 2.0010 - val_accuracy: 0.1389\n",
            "Epoch 29/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.5411 - accuracy: 0.4444 - val_loss: 1.9874 - val_accuracy: 0.1389\n",
            "Epoch 30/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.5260 - accuracy: 0.4826 - val_loss: 1.9833 - val_accuracy: 0.1389\n",
            "Epoch 31/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.5166 - accuracy: 0.4688 - val_loss: 1.9770 - val_accuracy: 0.1389\n",
            "Epoch 32/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.5352 - accuracy: 0.4375 - val_loss: 1.9656 - val_accuracy: 0.1389\n",
            "Epoch 33/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.4917 - accuracy: 0.4757 - val_loss: 1.9744 - val_accuracy: 0.1389\n",
            "Epoch 34/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4804 - accuracy: 0.4635 - val_loss: 1.9581 - val_accuracy: 0.1389\n",
            "Epoch 35/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.4685 - accuracy: 0.4913 - val_loss: 1.9592 - val_accuracy: 0.1389\n",
            "Epoch 36/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.5072 - accuracy: 0.4601 - val_loss: 1.9536 - val_accuracy: 0.1389\n",
            "Epoch 37/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4798 - accuracy: 0.4549 - val_loss: 1.9399 - val_accuracy: 0.1458\n",
            "Epoch 38/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.4691 - accuracy: 0.4861 - val_loss: 1.9265 - val_accuracy: 0.1458\n",
            "Epoch 39/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4764 - accuracy: 0.4670 - val_loss: 1.9034 - val_accuracy: 0.1458\n",
            "Epoch 40/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.4596 - accuracy: 0.4913 - val_loss: 1.9019 - val_accuracy: 0.1458\n",
            "Epoch 41/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4196 - accuracy: 0.4861 - val_loss: 1.8666 - val_accuracy: 0.1597\n",
            "Epoch 42/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4128 - accuracy: 0.5226 - val_loss: 1.8559 - val_accuracy: 0.1736\n",
            "Epoch 43/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3972 - accuracy: 0.5260 - val_loss: 1.8432 - val_accuracy: 0.1736\n",
            "Epoch 44/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3787 - accuracy: 0.5260 - val_loss: 1.8550 - val_accuracy: 0.1667\n",
            "Epoch 45/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.4105 - accuracy: 0.5035 - val_loss: 1.8196 - val_accuracy: 0.1806\n",
            "Epoch 46/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3958 - accuracy: 0.5104 - val_loss: 1.8194 - val_accuracy: 0.1875\n",
            "Epoch 47/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.3528 - accuracy: 0.5451 - val_loss: 1.7984 - val_accuracy: 0.1875\n",
            "Epoch 48/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3893 - accuracy: 0.5174 - val_loss: 1.8010 - val_accuracy: 0.1875\n",
            "Epoch 49/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3346 - accuracy: 0.5521 - val_loss: 1.7573 - val_accuracy: 0.2083\n",
            "Epoch 50/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.3434 - accuracy: 0.5417 - val_loss: 1.7350 - val_accuracy: 0.2361\n",
            "Epoch 51/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3417 - accuracy: 0.5486 - val_loss: 1.7463 - val_accuracy: 0.2361\n",
            "Epoch 52/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.3575 - accuracy: 0.5642 - val_loss: 1.7225 - val_accuracy: 0.2778\n",
            "Epoch 53/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3234 - accuracy: 0.5764 - val_loss: 1.6788 - val_accuracy: 0.3333\n",
            "Epoch 54/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3577 - accuracy: 0.5260 - val_loss: 1.6907 - val_accuracy: 0.2986\n",
            "Epoch 55/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.3370 - accuracy: 0.5747 - val_loss: 1.6563 - val_accuracy: 0.3472\n",
            "Epoch 56/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3144 - accuracy: 0.5816 - val_loss: 1.6443 - val_accuracy: 0.3750\n",
            "Epoch 57/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.3017 - accuracy: 0.5660 - val_loss: 1.6174 - val_accuracy: 0.3750\n",
            "Epoch 58/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.3037 - accuracy: 0.5781 - val_loss: 1.6355 - val_accuracy: 0.3333\n",
            "Epoch 59/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2711 - accuracy: 0.5938 - val_loss: 1.6233 - val_accuracy: 0.3611\n",
            "Epoch 60/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2665 - accuracy: 0.5712 - val_loss: 1.5959 - val_accuracy: 0.3889\n",
            "Epoch 61/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2751 - accuracy: 0.6146 - val_loss: 1.5839 - val_accuracy: 0.3958\n",
            "Epoch 62/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2566 - accuracy: 0.5955 - val_loss: 1.5590 - val_accuracy: 0.4306\n",
            "Epoch 63/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2766 - accuracy: 0.6111 - val_loss: 1.5384 - val_accuracy: 0.4444\n",
            "Epoch 64/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2650 - accuracy: 0.5972 - val_loss: 1.5305 - val_accuracy: 0.4583\n",
            "Epoch 65/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2560 - accuracy: 0.5833 - val_loss: 1.5423 - val_accuracy: 0.4167\n",
            "Epoch 66/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2594 - accuracy: 0.6146 - val_loss: 1.5226 - val_accuracy: 0.4583\n",
            "Epoch 67/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2162 - accuracy: 0.6302 - val_loss: 1.5043 - val_accuracy: 0.5208\n",
            "Epoch 68/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2391 - accuracy: 0.6128 - val_loss: 1.4896 - val_accuracy: 0.5069\n",
            "Epoch 69/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2501 - accuracy: 0.6163 - val_loss: 1.4700 - val_accuracy: 0.5417\n",
            "Epoch 70/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2217 - accuracy: 0.6337 - val_loss: 1.4776 - val_accuracy: 0.5208\n",
            "Epoch 71/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2323 - accuracy: 0.6493 - val_loss: 1.4650 - val_accuracy: 0.5278\n",
            "Epoch 72/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.2495 - accuracy: 0.6181 - val_loss: 1.4410 - val_accuracy: 0.5556\n",
            "Epoch 73/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2302 - accuracy: 0.6285 - val_loss: 1.4555 - val_accuracy: 0.5486\n",
            "Epoch 74/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.2069 - accuracy: 0.6354 - val_loss: 1.4249 - val_accuracy: 0.5625\n",
            "Epoch 75/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1917 - accuracy: 0.6302 - val_loss: 1.4174 - val_accuracy: 0.5486\n",
            "Epoch 76/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2338 - accuracy: 0.6215 - val_loss: 1.4335 - val_accuracy: 0.5486\n",
            "Epoch 77/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1833 - accuracy: 0.6372 - val_loss: 1.4272 - val_accuracy: 0.5347\n",
            "Epoch 78/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1682 - accuracy: 0.6771 - val_loss: 1.4143 - val_accuracy: 0.5556\n",
            "Epoch 79/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1813 - accuracy: 0.6701 - val_loss: 1.3907 - val_accuracy: 0.5556\n",
            "Epoch 80/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2155 - accuracy: 0.6267 - val_loss: 1.3961 - val_accuracy: 0.5417\n",
            "Epoch 81/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1771 - accuracy: 0.6424 - val_loss: 1.3822 - val_accuracy: 0.5694\n",
            "Epoch 82/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1751 - accuracy: 0.6476 - val_loss: 1.3681 - val_accuracy: 0.5972\n",
            "Epoch 83/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1883 - accuracy: 0.6632 - val_loss: 1.3696 - val_accuracy: 0.5694\n",
            "Epoch 84/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.1712 - accuracy: 0.6632 - val_loss: 1.3808 - val_accuracy: 0.5833\n",
            "Epoch 85/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1705 - accuracy: 0.6389 - val_loss: 1.3559 - val_accuracy: 0.5764\n",
            "Epoch 86/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1643 - accuracy: 0.6458 - val_loss: 1.3438 - val_accuracy: 0.5833\n",
            "Epoch 87/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1582 - accuracy: 0.6615 - val_loss: 1.3488 - val_accuracy: 0.5694\n",
            "Epoch 88/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1292 - accuracy: 0.6806 - val_loss: 1.3485 - val_accuracy: 0.5764\n",
            "Epoch 89/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.1320 - accuracy: 0.6823 - val_loss: 1.3334 - val_accuracy: 0.5764\n",
            "Epoch 90/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1517 - accuracy: 0.6753 - val_loss: 1.3425 - val_accuracy: 0.5764\n",
            "Epoch 91/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1369 - accuracy: 0.6806 - val_loss: 1.3305 - val_accuracy: 0.5833\n",
            "Epoch 92/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1226 - accuracy: 0.6667 - val_loss: 1.3364 - val_accuracy: 0.5833\n",
            "Epoch 93/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1834 - accuracy: 0.6528 - val_loss: 1.3329 - val_accuracy: 0.5903\n",
            "Epoch 94/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1230 - accuracy: 0.7083 - val_loss: 1.3302 - val_accuracy: 0.5764\n",
            "Epoch 95/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1555 - accuracy: 0.6788 - val_loss: 1.3270 - val_accuracy: 0.5972\n",
            "Epoch 96/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1285 - accuracy: 0.6840 - val_loss: 1.3160 - val_accuracy: 0.5903\n",
            "Epoch 97/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0908 - accuracy: 0.7049 - val_loss: 1.3140 - val_accuracy: 0.5625\n",
            "Epoch 98/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0947 - accuracy: 0.6997 - val_loss: 1.3085 - val_accuracy: 0.5903\n",
            "Epoch 99/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1216 - accuracy: 0.6788 - val_loss: 1.2993 - val_accuracy: 0.6042\n",
            "Epoch 100/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.1162 - accuracy: 0.7135 - val_loss: 1.3044 - val_accuracy: 0.5833\n",
            "Epoch 101/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1078 - accuracy: 0.6997 - val_loss: 1.3090 - val_accuracy: 0.5764\n",
            "Epoch 102/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0872 - accuracy: 0.7135 - val_loss: 1.2857 - val_accuracy: 0.6250\n",
            "Epoch 103/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1131 - accuracy: 0.7049 - val_loss: 1.2973 - val_accuracy: 0.6042\n",
            "Epoch 104/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0906 - accuracy: 0.6979 - val_loss: 1.3027 - val_accuracy: 0.5764\n",
            "Epoch 105/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0994 - accuracy: 0.7344 - val_loss: 1.2897 - val_accuracy: 0.6111\n",
            "Epoch 106/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0867 - accuracy: 0.7292 - val_loss: 1.2825 - val_accuracy: 0.6111\n",
            "Epoch 107/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.0832 - accuracy: 0.7101 - val_loss: 1.2862 - val_accuracy: 0.6181\n",
            "Epoch 108/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1002 - accuracy: 0.6927 - val_loss: 1.2827 - val_accuracy: 0.5694\n",
            "Epoch 109/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0689 - accuracy: 0.7031 - val_loss: 1.2859 - val_accuracy: 0.6042\n",
            "Epoch 110/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0775 - accuracy: 0.7101 - val_loss: 1.2884 - val_accuracy: 0.5903\n",
            "Epoch 111/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0450 - accuracy: 0.7344 - val_loss: 1.2766 - val_accuracy: 0.5972\n",
            "Epoch 112/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0671 - accuracy: 0.7205 - val_loss: 1.2774 - val_accuracy: 0.6250\n",
            "Epoch 113/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0518 - accuracy: 0.7326 - val_loss: 1.2660 - val_accuracy: 0.6250\n",
            "Epoch 114/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0428 - accuracy: 0.7326 - val_loss: 1.2631 - val_accuracy: 0.6250\n",
            "Epoch 115/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0382 - accuracy: 0.7535 - val_loss: 1.2909 - val_accuracy: 0.6181\n",
            "Epoch 116/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0398 - accuracy: 0.7240 - val_loss: 1.2796 - val_accuracy: 0.6181\n",
            "Epoch 117/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0436 - accuracy: 0.7413 - val_loss: 1.2694 - val_accuracy: 0.5903\n",
            "Epoch 118/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0595 - accuracy: 0.7326 - val_loss: 1.2649 - val_accuracy: 0.6319\n",
            "Epoch 119/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0206 - accuracy: 0.7535 - val_loss: 1.2762 - val_accuracy: 0.6111\n",
            "Epoch 120/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0432 - accuracy: 0.7309 - val_loss: 1.2662 - val_accuracy: 0.6181\n",
            "Epoch 121/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0239 - accuracy: 0.7431 - val_loss: 1.2610 - val_accuracy: 0.6181\n",
            "Epoch 122/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0267 - accuracy: 0.7378 - val_loss: 1.2472 - val_accuracy: 0.6111\n",
            "Epoch 123/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0140 - accuracy: 0.7743 - val_loss: 1.2644 - val_accuracy: 0.6319\n",
            "Epoch 124/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0353 - accuracy: 0.7483 - val_loss: 1.2431 - val_accuracy: 0.6319\n",
            "Epoch 125/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0436 - accuracy: 0.7135 - val_loss: 1.2354 - val_accuracy: 0.6181\n",
            "Epoch 126/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9994 - accuracy: 0.7760 - val_loss: 1.2385 - val_accuracy: 0.6319\n",
            "Epoch 127/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0207 - accuracy: 0.7465 - val_loss: 1.2523 - val_accuracy: 0.6250\n",
            "Epoch 128/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0179 - accuracy: 0.7517 - val_loss: 1.2505 - val_accuracy: 0.6181\n",
            "Epoch 129/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0123 - accuracy: 0.7604 - val_loss: 1.2516 - val_accuracy: 0.6458\n",
            "Epoch 130/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9828 - accuracy: 0.7726 - val_loss: 1.2399 - val_accuracy: 0.6389\n",
            "Epoch 131/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0014 - accuracy: 0.7674 - val_loss: 1.2404 - val_accuracy: 0.6389\n",
            "Epoch 132/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0054 - accuracy: 0.7535 - val_loss: 1.2397 - val_accuracy: 0.6250\n",
            "Epoch 133/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9832 - accuracy: 0.7847 - val_loss: 1.2526 - val_accuracy: 0.6111\n",
            "Epoch 134/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9895 - accuracy: 0.7674 - val_loss: 1.2628 - val_accuracy: 0.6250\n",
            "Epoch 135/700\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.9926 - accuracy: 0.7795 - val_loss: 1.2299 - val_accuracy: 0.6389\n",
            "Epoch 136/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0170 - accuracy: 0.7552 - val_loss: 1.2213 - val_accuracy: 0.6250\n",
            "Epoch 137/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9902 - accuracy: 0.7882 - val_loss: 1.2396 - val_accuracy: 0.6250\n",
            "Epoch 138/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9701 - accuracy: 0.7865 - val_loss: 1.2393 - val_accuracy: 0.6319\n",
            "Epoch 139/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9787 - accuracy: 0.8056 - val_loss: 1.2404 - val_accuracy: 0.6042\n",
            "Epoch 140/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9916 - accuracy: 0.7656 - val_loss: 1.2209 - val_accuracy: 0.6111\n",
            "Epoch 141/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9995 - accuracy: 0.7535 - val_loss: 1.2123 - val_accuracy: 0.6111\n",
            "Epoch 142/700\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.9987 - accuracy: 0.7639 - val_loss: 1.2197 - val_accuracy: 0.6111\n",
            "Epoch 143/700\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.9943 - accuracy: 0.7569 - val_loss: 1.2291 - val_accuracy: 0.6181\n",
            "Epoch 144/700\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.9754 - accuracy: 0.7656 - val_loss: 1.2304 - val_accuracy: 0.6319\n",
            "Epoch 145/700\n",
            "9/9 [==============================] - 1s 114ms/step - loss: 0.9589 - accuracy: 0.7934 - val_loss: 1.2006 - val_accuracy: 0.6250\n",
            "Epoch 146/700\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.9555 - accuracy: 0.7899 - val_loss: 1.2207 - val_accuracy: 0.6250\n",
            "Epoch 147/700\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.9642 - accuracy: 0.7795 - val_loss: 1.2238 - val_accuracy: 0.6181\n",
            "Epoch 148/700\n",
            "9/9 [==============================] - 1s 112ms/step - loss: 0.9812 - accuracy: 0.7847 - val_loss: 1.2115 - val_accuracy: 0.6597\n",
            "Epoch 149/700\n",
            "9/9 [==============================] - 1s 111ms/step - loss: 0.9345 - accuracy: 0.8038 - val_loss: 1.2103 - val_accuracy: 0.6528\n",
            "Epoch 150/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9420 - accuracy: 0.7986 - val_loss: 1.2068 - val_accuracy: 0.6458\n",
            "Epoch 151/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9584 - accuracy: 0.7812 - val_loss: 1.2230 - val_accuracy: 0.6250\n",
            "Epoch 152/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9742 - accuracy: 0.7882 - val_loss: 1.2250 - val_accuracy: 0.6389\n",
            "Epoch 153/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9446 - accuracy: 0.7917 - val_loss: 1.2084 - val_accuracy: 0.6389\n",
            "Epoch 154/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.9431 - accuracy: 0.7986 - val_loss: 1.2070 - val_accuracy: 0.6389\n",
            "Epoch 155/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9420 - accuracy: 0.7934 - val_loss: 1.2165 - val_accuracy: 0.6389\n",
            "Epoch 156/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9664 - accuracy: 0.7726 - val_loss: 1.2181 - val_accuracy: 0.6250\n",
            "Epoch 157/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9516 - accuracy: 0.8038 - val_loss: 1.1937 - val_accuracy: 0.6458\n",
            "Epoch 158/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9316 - accuracy: 0.8038 - val_loss: 1.2011 - val_accuracy: 0.6597\n",
            "Epoch 159/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9425 - accuracy: 0.8160 - val_loss: 1.1804 - val_accuracy: 0.6667\n",
            "Epoch 160/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9258 - accuracy: 0.8212 - val_loss: 1.1788 - val_accuracy: 0.6597\n",
            "Epoch 161/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9457 - accuracy: 0.7899 - val_loss: 1.1883 - val_accuracy: 0.6597\n",
            "Epoch 162/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9256 - accuracy: 0.7882 - val_loss: 1.2032 - val_accuracy: 0.6458\n",
            "Epoch 163/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8973 - accuracy: 0.8299 - val_loss: 1.2025 - val_accuracy: 0.6458\n",
            "Epoch 164/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9354 - accuracy: 0.7934 - val_loss: 1.2000 - val_accuracy: 0.6597\n",
            "Epoch 165/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9081 - accuracy: 0.8299 - val_loss: 1.1771 - val_accuracy: 0.6458\n",
            "Epoch 166/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9446 - accuracy: 0.7986 - val_loss: 1.1857 - val_accuracy: 0.6319\n",
            "Epoch 167/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9201 - accuracy: 0.8073 - val_loss: 1.1763 - val_accuracy: 0.6667\n",
            "Epoch 168/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9078 - accuracy: 0.8125 - val_loss: 1.1775 - val_accuracy: 0.6667\n",
            "Epoch 169/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9285 - accuracy: 0.8264 - val_loss: 1.1796 - val_accuracy: 0.6389\n",
            "Epoch 170/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9372 - accuracy: 0.8073 - val_loss: 1.2060 - val_accuracy: 0.6458\n",
            "Epoch 171/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8997 - accuracy: 0.8281 - val_loss: 1.1790 - val_accuracy: 0.6806\n",
            "Epoch 172/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8947 - accuracy: 0.8351 - val_loss: 1.2033 - val_accuracy: 0.6597\n",
            "Epoch 173/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9052 - accuracy: 0.8438 - val_loss: 1.1770 - val_accuracy: 0.6597\n",
            "Epoch 174/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9161 - accuracy: 0.8142 - val_loss: 1.1951 - val_accuracy: 0.6667\n",
            "Epoch 175/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8959 - accuracy: 0.8385 - val_loss: 1.2112 - val_accuracy: 0.6389\n",
            "Epoch 176/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9202 - accuracy: 0.8212 - val_loss: 1.1856 - val_accuracy: 0.6389\n",
            "Epoch 177/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.9131 - accuracy: 0.8160 - val_loss: 1.1891 - val_accuracy: 0.6458\n",
            "Epoch 178/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9032 - accuracy: 0.8368 - val_loss: 1.1850 - val_accuracy: 0.6667\n",
            "Epoch 179/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8743 - accuracy: 0.8420 - val_loss: 1.1661 - val_accuracy: 0.6667\n",
            "Epoch 180/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8948 - accuracy: 0.8229 - val_loss: 1.1687 - val_accuracy: 0.6875\n",
            "Epoch 181/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8920 - accuracy: 0.8490 - val_loss: 1.1828 - val_accuracy: 0.6736\n",
            "Epoch 182/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9013 - accuracy: 0.8299 - val_loss: 1.1743 - val_accuracy: 0.6667\n",
            "Epoch 183/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8888 - accuracy: 0.8142 - val_loss: 1.1607 - val_accuracy: 0.6736\n",
            "Epoch 184/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8875 - accuracy: 0.8229 - val_loss: 1.1581 - val_accuracy: 0.6736\n",
            "Epoch 185/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8737 - accuracy: 0.8420 - val_loss: 1.1828 - val_accuracy: 0.6667\n",
            "Epoch 186/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8927 - accuracy: 0.8247 - val_loss: 1.1701 - val_accuracy: 0.6597\n",
            "Epoch 187/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8897 - accuracy: 0.8090 - val_loss: 1.1628 - val_accuracy: 0.6597\n",
            "Epoch 188/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8843 - accuracy: 0.8299 - val_loss: 1.1800 - val_accuracy: 0.6458\n",
            "Epoch 189/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8791 - accuracy: 0.8333 - val_loss: 1.1754 - val_accuracy: 0.6597\n",
            "Epoch 190/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8884 - accuracy: 0.8368 - val_loss: 1.1583 - val_accuracy: 0.6736\n",
            "Epoch 191/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8846 - accuracy: 0.8281 - val_loss: 1.1652 - val_accuracy: 0.6667\n",
            "Epoch 192/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8631 - accuracy: 0.8559 - val_loss: 1.1716 - val_accuracy: 0.6667\n",
            "Epoch 193/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8813 - accuracy: 0.8299 - val_loss: 1.1603 - val_accuracy: 0.6806\n",
            "Epoch 194/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8762 - accuracy: 0.8333 - val_loss: 1.1647 - val_accuracy: 0.6806\n",
            "Epoch 195/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8662 - accuracy: 0.8385 - val_loss: 1.1828 - val_accuracy: 0.6806\n",
            "Epoch 196/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8648 - accuracy: 0.8472 - val_loss: 1.1621 - val_accuracy: 0.6806\n",
            "Epoch 197/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8700 - accuracy: 0.8299 - val_loss: 1.1615 - val_accuracy: 0.6597\n",
            "Epoch 198/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8672 - accuracy: 0.8524 - val_loss: 1.1659 - val_accuracy: 0.6806\n",
            "Epoch 199/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8572 - accuracy: 0.8576 - val_loss: 1.1644 - val_accuracy: 0.6736\n",
            "Epoch 200/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8497 - accuracy: 0.8559 - val_loss: 1.1460 - val_accuracy: 0.7014\n",
            "Epoch 201/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8415 - accuracy: 0.8733 - val_loss: 1.1646 - val_accuracy: 0.6667\n",
            "Epoch 202/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8592 - accuracy: 0.8333 - val_loss: 1.1744 - val_accuracy: 0.6806\n",
            "Epoch 203/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8615 - accuracy: 0.8490 - val_loss: 1.1576 - val_accuracy: 0.6528\n",
            "Epoch 204/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8614 - accuracy: 0.8351 - val_loss: 1.1551 - val_accuracy: 0.6944\n",
            "Epoch 205/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8540 - accuracy: 0.8507 - val_loss: 1.1559 - val_accuracy: 0.6806\n",
            "Epoch 206/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8421 - accuracy: 0.8559 - val_loss: 1.1450 - val_accuracy: 0.6875\n",
            "Epoch 207/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8306 - accuracy: 0.8906 - val_loss: 1.1515 - val_accuracy: 0.6806\n",
            "Epoch 208/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8424 - accuracy: 0.8628 - val_loss: 1.1602 - val_accuracy: 0.6736\n",
            "Epoch 209/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8642 - accuracy: 0.8351 - val_loss: 1.1399 - val_accuracy: 0.6736\n",
            "Epoch 210/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8216 - accuracy: 0.8698 - val_loss: 1.1472 - val_accuracy: 0.6597\n",
            "Epoch 211/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8145 - accuracy: 0.8785 - val_loss: 1.1448 - val_accuracy: 0.6875\n",
            "Epoch 212/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8494 - accuracy: 0.8646 - val_loss: 1.1512 - val_accuracy: 0.6736\n",
            "Epoch 213/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8202 - accuracy: 0.8872 - val_loss: 1.1576 - val_accuracy: 0.6597\n",
            "Epoch 214/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8390 - accuracy: 0.8663 - val_loss: 1.1314 - val_accuracy: 0.7083\n",
            "Epoch 215/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8307 - accuracy: 0.8767 - val_loss: 1.1488 - val_accuracy: 0.6736\n",
            "Epoch 216/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8286 - accuracy: 0.8628 - val_loss: 1.1445 - val_accuracy: 0.6944\n",
            "Epoch 217/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8330 - accuracy: 0.8663 - val_loss: 1.1434 - val_accuracy: 0.7083\n",
            "Epoch 218/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8295 - accuracy: 0.8628 - val_loss: 1.1446 - val_accuracy: 0.6736\n",
            "Epoch 219/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8253 - accuracy: 0.8576 - val_loss: 1.1398 - val_accuracy: 0.6875\n",
            "Epoch 220/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8239 - accuracy: 0.8733 - val_loss: 1.1338 - val_accuracy: 0.6875\n",
            "Epoch 221/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8332 - accuracy: 0.8628 - val_loss: 1.1375 - val_accuracy: 0.6736\n",
            "Epoch 222/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8271 - accuracy: 0.8628 - val_loss: 1.1387 - val_accuracy: 0.6944\n",
            "Epoch 223/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8091 - accuracy: 0.8594 - val_loss: 1.1420 - val_accuracy: 0.6806\n",
            "Epoch 224/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8160 - accuracy: 0.8872 - val_loss: 1.1368 - val_accuracy: 0.6944\n",
            "Epoch 225/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8155 - accuracy: 0.8733 - val_loss: 1.1365 - val_accuracy: 0.6806\n",
            "Epoch 226/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8146 - accuracy: 0.8559 - val_loss: 1.1316 - val_accuracy: 0.6875\n",
            "Epoch 227/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8133 - accuracy: 0.8767 - val_loss: 1.1316 - val_accuracy: 0.6736\n",
            "Epoch 228/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8037 - accuracy: 0.8611 - val_loss: 1.1282 - val_accuracy: 0.6944\n",
            "Epoch 229/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8331 - accuracy: 0.8472 - val_loss: 1.1345 - val_accuracy: 0.6944\n",
            "Epoch 230/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7987 - accuracy: 0.8854 - val_loss: 1.1468 - val_accuracy: 0.6944\n",
            "Epoch 231/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8287 - accuracy: 0.8403 - val_loss: 1.1445 - val_accuracy: 0.6667\n",
            "Epoch 232/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7934 - accuracy: 0.8889 - val_loss: 1.1261 - val_accuracy: 0.6875\n",
            "Epoch 233/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8000 - accuracy: 0.8802 - val_loss: 1.1407 - val_accuracy: 0.6736\n",
            "Epoch 234/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7924 - accuracy: 0.8941 - val_loss: 1.1442 - val_accuracy: 0.6875\n",
            "Epoch 235/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7971 - accuracy: 0.8819 - val_loss: 1.1258 - val_accuracy: 0.6944\n",
            "Epoch 236/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8098 - accuracy: 0.8681 - val_loss: 1.1284 - val_accuracy: 0.6944\n",
            "Epoch 237/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7799 - accuracy: 0.8976 - val_loss: 1.1222 - val_accuracy: 0.7292\n",
            "Epoch 238/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7838 - accuracy: 0.8872 - val_loss: 1.1242 - val_accuracy: 0.6806\n",
            "Epoch 239/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7962 - accuracy: 0.8785 - val_loss: 1.1234 - val_accuracy: 0.6944\n",
            "Epoch 240/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8126 - accuracy: 0.8785 - val_loss: 1.1301 - val_accuracy: 0.7014\n",
            "Epoch 241/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8016 - accuracy: 0.8802 - val_loss: 1.1247 - val_accuracy: 0.7153\n",
            "Epoch 242/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7855 - accuracy: 0.8785 - val_loss: 1.1356 - val_accuracy: 0.6736\n",
            "Epoch 243/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7918 - accuracy: 0.8681 - val_loss: 1.1241 - val_accuracy: 0.7014\n",
            "Epoch 244/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7851 - accuracy: 0.8750 - val_loss: 1.1393 - val_accuracy: 0.7014\n",
            "Epoch 245/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7657 - accuracy: 0.9080 - val_loss: 1.1197 - val_accuracy: 0.6875\n",
            "Epoch 246/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7763 - accuracy: 0.8889 - val_loss: 1.1209 - val_accuracy: 0.6944\n",
            "Epoch 247/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7852 - accuracy: 0.8958 - val_loss: 1.1151 - val_accuracy: 0.7014\n",
            "Epoch 248/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7747 - accuracy: 0.8958 - val_loss: 1.1189 - val_accuracy: 0.6944\n",
            "Epoch 249/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7658 - accuracy: 0.8941 - val_loss: 1.1341 - val_accuracy: 0.7014\n",
            "Epoch 250/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7897 - accuracy: 0.9045 - val_loss: 1.1330 - val_accuracy: 0.6944\n",
            "Epoch 251/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7650 - accuracy: 0.9045 - val_loss: 1.1259 - val_accuracy: 0.7014\n",
            "Epoch 252/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7740 - accuracy: 0.9080 - val_loss: 1.1116 - val_accuracy: 0.7361\n",
            "Epoch 253/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7796 - accuracy: 0.8941 - val_loss: 1.1206 - val_accuracy: 0.7083\n",
            "Epoch 254/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7730 - accuracy: 0.8889 - val_loss: 1.1196 - val_accuracy: 0.6875\n",
            "Epoch 255/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7700 - accuracy: 0.8941 - val_loss: 1.1211 - val_accuracy: 0.6806\n",
            "Epoch 256/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7698 - accuracy: 0.9080 - val_loss: 1.1219 - val_accuracy: 0.6944\n",
            "Epoch 257/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7762 - accuracy: 0.8889 - val_loss: 1.1227 - val_accuracy: 0.7083\n",
            "Epoch 258/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7697 - accuracy: 0.9028 - val_loss: 1.1352 - val_accuracy: 0.6944\n",
            "Epoch 259/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7489 - accuracy: 0.9062 - val_loss: 1.1261 - val_accuracy: 0.7083\n",
            "Epoch 260/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7487 - accuracy: 0.9010 - val_loss: 1.1309 - val_accuracy: 0.7014\n",
            "Epoch 261/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7687 - accuracy: 0.8958 - val_loss: 1.1320 - val_accuracy: 0.7083\n",
            "Epoch 262/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7761 - accuracy: 0.8785 - val_loss: 1.1266 - val_accuracy: 0.7083\n",
            "Epoch 263/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7742 - accuracy: 0.8802 - val_loss: 1.1111 - val_accuracy: 0.7083\n",
            "Epoch 264/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7653 - accuracy: 0.9010 - val_loss: 1.1231 - val_accuracy: 0.6944\n",
            "Epoch 265/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7754 - accuracy: 0.8802 - val_loss: 1.1271 - val_accuracy: 0.7222\n",
            "Epoch 266/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7735 - accuracy: 0.8906 - val_loss: 1.0994 - val_accuracy: 0.7361\n",
            "Epoch 267/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7356 - accuracy: 0.9167 - val_loss: 1.1179 - val_accuracy: 0.7083\n",
            "Epoch 268/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7425 - accuracy: 0.8941 - val_loss: 1.0977 - val_accuracy: 0.7153\n",
            "Epoch 269/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7503 - accuracy: 0.9010 - val_loss: 1.1156 - val_accuracy: 0.7083\n",
            "Epoch 270/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7653 - accuracy: 0.9010 - val_loss: 1.1076 - val_accuracy: 0.7222\n",
            "Epoch 271/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7599 - accuracy: 0.8976 - val_loss: 1.1093 - val_accuracy: 0.7222\n",
            "Epoch 272/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7471 - accuracy: 0.8993 - val_loss: 1.0903 - val_accuracy: 0.7431\n",
            "Epoch 273/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7427 - accuracy: 0.9201 - val_loss: 1.1008 - val_accuracy: 0.7222\n",
            "Epoch 274/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7441 - accuracy: 0.9167 - val_loss: 1.1071 - val_accuracy: 0.7222\n",
            "Epoch 275/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7598 - accuracy: 0.9062 - val_loss: 1.1099 - val_accuracy: 0.7153\n",
            "Epoch 276/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7370 - accuracy: 0.9045 - val_loss: 1.1074 - val_accuracy: 0.7222\n",
            "Epoch 277/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7518 - accuracy: 0.8976 - val_loss: 1.1047 - val_accuracy: 0.7222\n",
            "Epoch 278/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7245 - accuracy: 0.9236 - val_loss: 1.1048 - val_accuracy: 0.7083\n",
            "Epoch 279/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7490 - accuracy: 0.8976 - val_loss: 1.1199 - val_accuracy: 0.7153\n",
            "Epoch 280/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7265 - accuracy: 0.9149 - val_loss: 1.1096 - val_accuracy: 0.6875\n",
            "Epoch 281/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7172 - accuracy: 0.9167 - val_loss: 1.0993 - val_accuracy: 0.7153\n",
            "Epoch 282/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7645 - accuracy: 0.9010 - val_loss: 1.1078 - val_accuracy: 0.6875\n",
            "Epoch 283/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7291 - accuracy: 0.9184 - val_loss: 1.1078 - val_accuracy: 0.7083\n",
            "Epoch 284/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7184 - accuracy: 0.9358 - val_loss: 1.1185 - val_accuracy: 0.7014\n",
            "Epoch 285/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7576 - accuracy: 0.8906 - val_loss: 1.1203 - val_accuracy: 0.7083\n",
            "Epoch 286/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7198 - accuracy: 0.9184 - val_loss: 1.0963 - val_accuracy: 0.7153\n",
            "Epoch 287/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7461 - accuracy: 0.9028 - val_loss: 1.0918 - val_accuracy: 0.7292\n",
            "Epoch 288/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7476 - accuracy: 0.9167 - val_loss: 1.0893 - val_accuracy: 0.7222\n",
            "Epoch 289/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7174 - accuracy: 0.9149 - val_loss: 1.1010 - val_accuracy: 0.7222\n",
            "Epoch 290/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7180 - accuracy: 0.9271 - val_loss: 1.1083 - val_accuracy: 0.7014\n",
            "Epoch 291/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7375 - accuracy: 0.8993 - val_loss: 1.1049 - val_accuracy: 0.7153\n",
            "Epoch 292/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7079 - accuracy: 0.9288 - val_loss: 1.1002 - val_accuracy: 0.7431\n",
            "Epoch 293/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7270 - accuracy: 0.9115 - val_loss: 1.0979 - val_accuracy: 0.7222\n",
            "Epoch 294/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7192 - accuracy: 0.9340 - val_loss: 1.1043 - val_accuracy: 0.7153\n",
            "Epoch 295/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7321 - accuracy: 0.9132 - val_loss: 1.0988 - val_accuracy: 0.7153\n",
            "Epoch 296/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7414 - accuracy: 0.9149 - val_loss: 1.0952 - val_accuracy: 0.7222\n",
            "Epoch 297/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7170 - accuracy: 0.9149 - val_loss: 1.1041 - val_accuracy: 0.7153\n",
            "Epoch 298/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7008 - accuracy: 0.9184 - val_loss: 1.1017 - val_accuracy: 0.7153\n",
            "Epoch 299/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7053 - accuracy: 0.9306 - val_loss: 1.0983 - val_accuracy: 0.7153\n",
            "Epoch 300/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7091 - accuracy: 0.9271 - val_loss: 1.1013 - val_accuracy: 0.7014\n",
            "Epoch 301/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7114 - accuracy: 0.9323 - val_loss: 1.0999 - val_accuracy: 0.7014\n",
            "Epoch 302/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7066 - accuracy: 0.9323 - val_loss: 1.0985 - val_accuracy: 0.7222\n",
            "Epoch 303/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7083 - accuracy: 0.9219 - val_loss: 1.0958 - val_accuracy: 0.7292\n",
            "Epoch 304/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7124 - accuracy: 0.9201 - val_loss: 1.1054 - val_accuracy: 0.7222\n",
            "Epoch 305/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7063 - accuracy: 0.9340 - val_loss: 1.0886 - val_accuracy: 0.7292\n",
            "Epoch 306/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7072 - accuracy: 0.9358 - val_loss: 1.0968 - val_accuracy: 0.7431\n",
            "Epoch 307/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6963 - accuracy: 0.9323 - val_loss: 1.1023 - val_accuracy: 0.7222\n",
            "Epoch 308/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7062 - accuracy: 0.9323 - val_loss: 1.0987 - val_accuracy: 0.7292\n",
            "Epoch 309/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7082 - accuracy: 0.9201 - val_loss: 1.0859 - val_accuracy: 0.7222\n",
            "Epoch 310/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7269 - accuracy: 0.9045 - val_loss: 1.0952 - val_accuracy: 0.7500\n",
            "Epoch 311/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6932 - accuracy: 0.9410 - val_loss: 1.0860 - val_accuracy: 0.7500\n",
            "Epoch 312/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7142 - accuracy: 0.9184 - val_loss: 1.0825 - val_accuracy: 0.7222\n",
            "Epoch 313/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6943 - accuracy: 0.9375 - val_loss: 1.1017 - val_accuracy: 0.7153\n",
            "Epoch 314/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6890 - accuracy: 0.9375 - val_loss: 1.0817 - val_accuracy: 0.7361\n",
            "Epoch 315/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7078 - accuracy: 0.9184 - val_loss: 1.0830 - val_accuracy: 0.7222\n",
            "Epoch 316/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7066 - accuracy: 0.9201 - val_loss: 1.0774 - val_accuracy: 0.7500\n",
            "Epoch 317/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7113 - accuracy: 0.9097 - val_loss: 1.0833 - val_accuracy: 0.7361\n",
            "Epoch 318/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7088 - accuracy: 0.9410 - val_loss: 1.0826 - val_accuracy: 0.7431\n",
            "Epoch 319/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6937 - accuracy: 0.9271 - val_loss: 1.0885 - val_accuracy: 0.7222\n",
            "Epoch 320/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7061 - accuracy: 0.9219 - val_loss: 1.0903 - val_accuracy: 0.7361\n",
            "Epoch 321/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7024 - accuracy: 0.9201 - val_loss: 1.0717 - val_accuracy: 0.7708\n",
            "Epoch 322/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6732 - accuracy: 0.9462 - val_loss: 1.0823 - val_accuracy: 0.7431\n",
            "Epoch 323/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6897 - accuracy: 0.9340 - val_loss: 1.0928 - val_accuracy: 0.7569\n",
            "Epoch 324/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6905 - accuracy: 0.9375 - val_loss: 1.0758 - val_accuracy: 0.7500\n",
            "Epoch 325/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6832 - accuracy: 0.9358 - val_loss: 1.0750 - val_accuracy: 0.7361\n",
            "Epoch 326/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6746 - accuracy: 0.9497 - val_loss: 1.0950 - val_accuracy: 0.7431\n",
            "Epoch 327/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6756 - accuracy: 0.9410 - val_loss: 1.0831 - val_accuracy: 0.7500\n",
            "Epoch 328/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6860 - accuracy: 0.9271 - val_loss: 1.0874 - val_accuracy: 0.7361\n",
            "Epoch 329/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6600 - accuracy: 0.9479 - val_loss: 1.0822 - val_accuracy: 0.7431\n",
            "Epoch 330/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6758 - accuracy: 0.9253 - val_loss: 1.0864 - val_accuracy: 0.7292\n",
            "Epoch 331/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6820 - accuracy: 0.9410 - val_loss: 1.0937 - val_accuracy: 0.7222\n",
            "Epoch 332/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6740 - accuracy: 0.9323 - val_loss: 1.0851 - val_accuracy: 0.7292\n",
            "Epoch 333/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6723 - accuracy: 0.9323 - val_loss: 1.1012 - val_accuracy: 0.7083\n",
            "Epoch 334/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6846 - accuracy: 0.9392 - val_loss: 1.0920 - val_accuracy: 0.7431\n",
            "Epoch 335/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6739 - accuracy: 0.9479 - val_loss: 1.0911 - val_accuracy: 0.7431\n",
            "Epoch 336/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6633 - accuracy: 0.9427 - val_loss: 1.0831 - val_accuracy: 0.7153\n",
            "Epoch 337/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6704 - accuracy: 0.9410 - val_loss: 1.0759 - val_accuracy: 0.7292\n",
            "Epoch 338/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6959 - accuracy: 0.9219 - val_loss: 1.0803 - val_accuracy: 0.7431\n",
            "Epoch 339/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6774 - accuracy: 0.9375 - val_loss: 1.0766 - val_accuracy: 0.7361\n",
            "Epoch 340/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6700 - accuracy: 0.9497 - val_loss: 1.0819 - val_accuracy: 0.7431\n",
            "Epoch 341/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6727 - accuracy: 0.9427 - val_loss: 1.0807 - val_accuracy: 0.7431\n",
            "Epoch 342/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6603 - accuracy: 0.9410 - val_loss: 1.0945 - val_accuracy: 0.7500\n",
            "Epoch 343/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6449 - accuracy: 0.9462 - val_loss: 1.0892 - val_accuracy: 0.7431\n",
            "Epoch 344/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6714 - accuracy: 0.9323 - val_loss: 1.0865 - val_accuracy: 0.7222\n",
            "Epoch 345/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6856 - accuracy: 0.9340 - val_loss: 1.0746 - val_accuracy: 0.7083\n",
            "Epoch 346/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6687 - accuracy: 0.9323 - val_loss: 1.0755 - val_accuracy: 0.7431\n",
            "Epoch 347/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6585 - accuracy: 0.9514 - val_loss: 1.0784 - val_accuracy: 0.7153\n",
            "Epoch 348/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6556 - accuracy: 0.9497 - val_loss: 1.0760 - val_accuracy: 0.7292\n",
            "Epoch 349/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6665 - accuracy: 0.9479 - val_loss: 1.0992 - val_accuracy: 0.7292\n",
            "Epoch 350/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.6531 - accuracy: 0.9583 - val_loss: 1.0800 - val_accuracy: 0.7292\n",
            "Epoch 351/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6573 - accuracy: 0.9410 - val_loss: 1.0968 - val_accuracy: 0.6944\n",
            "Epoch 352/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6663 - accuracy: 0.9653 - val_loss: 1.0920 - val_accuracy: 0.7222\n",
            "Epoch 353/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6668 - accuracy: 0.9444 - val_loss: 1.0760 - val_accuracy: 0.7292\n",
            "Epoch 354/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6431 - accuracy: 0.9514 - val_loss: 1.0691 - val_accuracy: 0.7222\n",
            "Epoch 355/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6724 - accuracy: 0.9306 - val_loss: 1.0704 - val_accuracy: 0.7500\n",
            "Epoch 356/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6383 - accuracy: 0.9618 - val_loss: 1.0710 - val_accuracy: 0.7361\n",
            "Epoch 357/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6537 - accuracy: 0.9427 - val_loss: 1.0660 - val_accuracy: 0.7569\n",
            "Epoch 358/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6600 - accuracy: 0.9410 - val_loss: 1.0628 - val_accuracy: 0.7361\n",
            "Epoch 359/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6518 - accuracy: 0.9601 - val_loss: 1.0634 - val_accuracy: 0.7569\n",
            "Epoch 360/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6608 - accuracy: 0.9549 - val_loss: 1.0654 - val_accuracy: 0.7639\n",
            "Epoch 361/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6546 - accuracy: 0.9497 - val_loss: 1.0758 - val_accuracy: 0.7500\n",
            "Epoch 362/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6634 - accuracy: 0.9549 - val_loss: 1.0541 - val_accuracy: 0.7569\n",
            "Epoch 363/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6550 - accuracy: 0.9392 - val_loss: 1.0647 - val_accuracy: 0.7569\n",
            "Epoch 364/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6428 - accuracy: 0.9462 - val_loss: 1.0526 - val_accuracy: 0.7569\n",
            "Epoch 365/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6604 - accuracy: 0.9340 - val_loss: 1.0747 - val_accuracy: 0.7083\n",
            "Epoch 366/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6396 - accuracy: 0.9566 - val_loss: 1.0570 - val_accuracy: 0.7361\n",
            "Epoch 367/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6531 - accuracy: 0.9566 - val_loss: 1.0554 - val_accuracy: 0.7361\n",
            "Epoch 368/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6624 - accuracy: 0.9340 - val_loss: 1.0587 - val_accuracy: 0.7500\n",
            "Epoch 369/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6860 - accuracy: 0.9392 - val_loss: 1.0606 - val_accuracy: 0.7569\n",
            "Epoch 370/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6479 - accuracy: 0.9497 - val_loss: 1.0793 - val_accuracy: 0.7292\n",
            "Epoch 371/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6319 - accuracy: 0.9740 - val_loss: 1.0740 - val_accuracy: 0.7292\n",
            "Epoch 372/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6441 - accuracy: 0.9479 - val_loss: 1.0671 - val_accuracy: 0.7361\n",
            "Epoch 373/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6412 - accuracy: 0.9549 - val_loss: 1.0654 - val_accuracy: 0.7361\n",
            "Epoch 374/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6268 - accuracy: 0.9705 - val_loss: 1.0575 - val_accuracy: 0.7361\n",
            "Epoch 375/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6345 - accuracy: 0.9583 - val_loss: 1.0755 - val_accuracy: 0.7639\n",
            "Epoch 376/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6293 - accuracy: 0.9583 - val_loss: 1.0738 - val_accuracy: 0.7292\n",
            "Epoch 377/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6406 - accuracy: 0.9583 - val_loss: 1.0690 - val_accuracy: 0.7361\n",
            "Epoch 378/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6336 - accuracy: 0.9427 - val_loss: 1.0697 - val_accuracy: 0.7431\n",
            "Epoch 379/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6391 - accuracy: 0.9497 - val_loss: 1.0739 - val_accuracy: 0.7361\n",
            "Epoch 380/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6210 - accuracy: 0.9653 - val_loss: 1.0652 - val_accuracy: 0.7639\n",
            "Epoch 381/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6433 - accuracy: 0.9410 - val_loss: 1.0668 - val_accuracy: 0.7361\n",
            "Epoch 382/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6380 - accuracy: 0.9497 - val_loss: 1.0558 - val_accuracy: 0.7361\n",
            "Epoch 383/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6255 - accuracy: 0.9688 - val_loss: 1.0706 - val_accuracy: 0.7500\n",
            "Epoch 384/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6241 - accuracy: 0.9635 - val_loss: 1.0698 - val_accuracy: 0.7153\n",
            "Epoch 385/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6333 - accuracy: 0.9653 - val_loss: 1.0636 - val_accuracy: 0.7361\n",
            "Epoch 386/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6471 - accuracy: 0.9514 - val_loss: 1.0712 - val_accuracy: 0.7222\n",
            "Epoch 387/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6360 - accuracy: 0.9514 - val_loss: 1.0670 - val_accuracy: 0.7292\n",
            "Epoch 388/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6283 - accuracy: 0.9583 - val_loss: 1.0477 - val_accuracy: 0.7639\n",
            "Epoch 389/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6239 - accuracy: 0.9531 - val_loss: 1.0566 - val_accuracy: 0.7500\n",
            "Epoch 390/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6219 - accuracy: 0.9688 - val_loss: 1.0730 - val_accuracy: 0.7569\n",
            "Epoch 391/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6427 - accuracy: 0.9531 - val_loss: 1.0521 - val_accuracy: 0.7569\n",
            "Epoch 392/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6292 - accuracy: 0.9549 - val_loss: 1.0729 - val_accuracy: 0.7361\n",
            "Epoch 393/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6175 - accuracy: 0.9670 - val_loss: 1.0724 - val_accuracy: 0.7708\n",
            "Epoch 394/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6285 - accuracy: 0.9531 - val_loss: 1.0701 - val_accuracy: 0.7222\n",
            "Epoch 395/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6083 - accuracy: 0.9653 - val_loss: 1.0780 - val_accuracy: 0.7222\n",
            "Epoch 396/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6168 - accuracy: 0.9601 - val_loss: 1.0877 - val_accuracy: 0.7153\n",
            "Epoch 397/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6069 - accuracy: 0.9688 - val_loss: 1.0716 - val_accuracy: 0.7361\n",
            "Epoch 398/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6293 - accuracy: 0.9583 - val_loss: 1.0628 - val_accuracy: 0.7639\n",
            "Epoch 399/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6159 - accuracy: 0.9549 - val_loss: 1.0608 - val_accuracy: 0.7431\n",
            "Epoch 400/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6198 - accuracy: 0.9635 - val_loss: 1.0646 - val_accuracy: 0.7153\n",
            "Epoch 401/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6300 - accuracy: 0.9583 - val_loss: 1.0683 - val_accuracy: 0.7153\n",
            "Epoch 402/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6262 - accuracy: 0.9462 - val_loss: 1.0703 - val_accuracy: 0.7222\n",
            "Epoch 403/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6111 - accuracy: 0.9670 - val_loss: 1.0491 - val_accuracy: 0.7431\n",
            "Epoch 404/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5959 - accuracy: 0.9705 - val_loss: 1.0656 - val_accuracy: 0.7292\n",
            "Epoch 405/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6248 - accuracy: 0.9566 - val_loss: 1.0568 - val_accuracy: 0.7431\n",
            "Epoch 406/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6083 - accuracy: 0.9583 - val_loss: 1.0516 - val_accuracy: 0.7500\n",
            "Epoch 407/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6230 - accuracy: 0.9583 - val_loss: 1.0462 - val_accuracy: 0.7292\n",
            "Epoch 408/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6036 - accuracy: 0.9705 - val_loss: 1.0518 - val_accuracy: 0.7431\n",
            "Epoch 409/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6122 - accuracy: 0.9618 - val_loss: 1.0545 - val_accuracy: 0.7153\n",
            "Epoch 410/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6002 - accuracy: 0.9618 - val_loss: 1.0621 - val_accuracy: 0.7361\n",
            "Epoch 411/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6104 - accuracy: 0.9740 - val_loss: 1.0545 - val_accuracy: 0.7431\n",
            "Epoch 412/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6170 - accuracy: 0.9549 - val_loss: 1.0582 - val_accuracy: 0.7222\n",
            "Epoch 413/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5979 - accuracy: 0.9653 - val_loss: 1.0563 - val_accuracy: 0.7361\n",
            "Epoch 414/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5979 - accuracy: 0.9740 - val_loss: 1.0568 - val_accuracy: 0.7569\n",
            "Epoch 415/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6046 - accuracy: 0.9653 - val_loss: 1.0514 - val_accuracy: 0.7361\n",
            "Epoch 416/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5985 - accuracy: 0.9670 - val_loss: 1.0624 - val_accuracy: 0.7292\n",
            "Epoch 417/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6065 - accuracy: 0.9757 - val_loss: 1.0636 - val_accuracy: 0.7500\n",
            "Epoch 418/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6159 - accuracy: 0.9583 - val_loss: 1.0509 - val_accuracy: 0.7569\n",
            "Epoch 419/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5954 - accuracy: 0.9688 - val_loss: 1.0611 - val_accuracy: 0.7500\n",
            "Epoch 420/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6197 - accuracy: 0.9635 - val_loss: 1.0471 - val_accuracy: 0.7500\n",
            "Epoch 421/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6283 - accuracy: 0.9514 - val_loss: 1.0517 - val_accuracy: 0.7500\n",
            "Epoch 422/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5944 - accuracy: 0.9688 - val_loss: 1.0553 - val_accuracy: 0.7431\n",
            "Epoch 423/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6143 - accuracy: 0.9688 - val_loss: 1.0416 - val_accuracy: 0.7569\n",
            "Epoch 424/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6123 - accuracy: 0.9601 - val_loss: 1.0509 - val_accuracy: 0.7569\n",
            "Epoch 425/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6046 - accuracy: 0.9653 - val_loss: 1.0337 - val_accuracy: 0.7569\n",
            "Epoch 426/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5909 - accuracy: 0.9670 - val_loss: 1.0441 - val_accuracy: 0.7431\n",
            "Epoch 427/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6000 - accuracy: 0.9601 - val_loss: 1.0522 - val_accuracy: 0.7569\n",
            "Epoch 428/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6152 - accuracy: 0.9653 - val_loss: 1.0423 - val_accuracy: 0.7361\n",
            "Epoch 429/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6006 - accuracy: 0.9583 - val_loss: 1.0412 - val_accuracy: 0.7500\n",
            "Epoch 430/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5831 - accuracy: 0.9688 - val_loss: 1.0575 - val_accuracy: 0.7361\n",
            "Epoch 431/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5890 - accuracy: 0.9635 - val_loss: 1.0542 - val_accuracy: 0.7639\n",
            "Epoch 432/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5924 - accuracy: 0.9774 - val_loss: 1.0580 - val_accuracy: 0.7361\n",
            "Epoch 433/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6025 - accuracy: 0.9635 - val_loss: 1.0472 - val_accuracy: 0.7361\n",
            "Epoch 434/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5764 - accuracy: 0.9670 - val_loss: 1.0499 - val_accuracy: 0.7222\n",
            "Epoch 435/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6036 - accuracy: 0.9792 - val_loss: 1.0521 - val_accuracy: 0.7222\n",
            "Epoch 436/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5908 - accuracy: 0.9670 - val_loss: 1.0597 - val_accuracy: 0.7431\n",
            "Epoch 437/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5834 - accuracy: 0.9740 - val_loss: 1.0671 - val_accuracy: 0.7222\n",
            "Epoch 438/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5993 - accuracy: 0.9688 - val_loss: 1.0628 - val_accuracy: 0.7361\n",
            "Epoch 439/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6027 - accuracy: 0.9618 - val_loss: 1.0612 - val_accuracy: 0.7153\n",
            "Epoch 440/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5867 - accuracy: 0.9722 - val_loss: 1.0552 - val_accuracy: 0.7569\n",
            "Epoch 441/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5953 - accuracy: 0.9705 - val_loss: 1.0577 - val_accuracy: 0.7569\n",
            "Epoch 442/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6213 - accuracy: 0.9462 - val_loss: 1.0653 - val_accuracy: 0.7292\n",
            "Epoch 443/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5845 - accuracy: 0.9670 - val_loss: 1.0666 - val_accuracy: 0.7569\n",
            "Epoch 444/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5954 - accuracy: 0.9792 - val_loss: 1.0623 - val_accuracy: 0.7431\n",
            "Epoch 445/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5821 - accuracy: 0.9705 - val_loss: 1.0528 - val_accuracy: 0.7569\n",
            "Epoch 446/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5788 - accuracy: 0.9774 - val_loss: 1.0443 - val_accuracy: 0.7500\n",
            "Epoch 447/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5913 - accuracy: 0.9618 - val_loss: 1.0426 - val_accuracy: 0.7431\n",
            "Epoch 448/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5923 - accuracy: 0.9705 - val_loss: 1.0418 - val_accuracy: 0.7500\n",
            "Epoch 449/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6042 - accuracy: 0.9688 - val_loss: 1.0557 - val_accuracy: 0.7431\n",
            "Epoch 450/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5980 - accuracy: 0.9688 - val_loss: 1.0563 - val_accuracy: 0.7431\n",
            "Epoch 451/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5694 - accuracy: 0.9757 - val_loss: 1.0384 - val_accuracy: 0.7361\n",
            "Epoch 452/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5764 - accuracy: 0.9688 - val_loss: 1.0472 - val_accuracy: 0.7431\n",
            "Epoch 453/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5902 - accuracy: 0.9740 - val_loss: 1.0581 - val_accuracy: 0.7083\n",
            "Epoch 454/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5717 - accuracy: 0.9809 - val_loss: 1.0477 - val_accuracy: 0.7361\n",
            "Epoch 455/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5906 - accuracy: 0.9792 - val_loss: 1.0396 - val_accuracy: 0.7292\n",
            "Epoch 456/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6011 - accuracy: 0.9583 - val_loss: 1.0422 - val_accuracy: 0.7431\n",
            "Epoch 457/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5676 - accuracy: 0.9809 - val_loss: 1.0400 - val_accuracy: 0.7500\n",
            "Epoch 458/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5776 - accuracy: 0.9792 - val_loss: 1.0467 - val_accuracy: 0.7569\n",
            "Epoch 459/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5806 - accuracy: 0.9774 - val_loss: 1.0317 - val_accuracy: 0.7500\n",
            "Epoch 460/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5799 - accuracy: 0.9635 - val_loss: 1.0544 - val_accuracy: 0.7292\n",
            "Epoch 461/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5950 - accuracy: 0.9740 - val_loss: 1.0337 - val_accuracy: 0.7569\n",
            "Epoch 462/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5761 - accuracy: 0.9705 - val_loss: 1.0292 - val_accuracy: 0.7708\n",
            "Epoch 463/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5670 - accuracy: 0.9722 - val_loss: 1.0359 - val_accuracy: 0.7569\n",
            "Epoch 464/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5639 - accuracy: 0.9792 - val_loss: 1.0440 - val_accuracy: 0.7639\n",
            "Epoch 465/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5704 - accuracy: 0.9844 - val_loss: 1.0428 - val_accuracy: 0.7639\n",
            "Epoch 466/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5847 - accuracy: 0.9722 - val_loss: 1.0359 - val_accuracy: 0.7500\n",
            "Epoch 467/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5805 - accuracy: 0.9670 - val_loss: 1.0349 - val_accuracy: 0.7500\n",
            "Epoch 468/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5849 - accuracy: 0.9722 - val_loss: 1.0422 - val_accuracy: 0.7500\n",
            "Epoch 469/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5798 - accuracy: 0.9740 - val_loss: 1.0337 - val_accuracy: 0.7431\n",
            "Epoch 470/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5839 - accuracy: 0.9792 - val_loss: 1.0385 - val_accuracy: 0.7431\n",
            "Epoch 471/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5922 - accuracy: 0.9670 - val_loss: 1.0308 - val_accuracy: 0.7361\n",
            "Epoch 472/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5710 - accuracy: 0.9809 - val_loss: 1.0386 - val_accuracy: 0.7500\n",
            "Epoch 473/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5569 - accuracy: 0.9774 - val_loss: 1.0350 - val_accuracy: 0.7639\n",
            "Epoch 474/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5603 - accuracy: 0.9792 - val_loss: 1.0319 - val_accuracy: 0.7500\n",
            "Epoch 475/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5662 - accuracy: 0.9826 - val_loss: 1.0333 - val_accuracy: 0.7431\n",
            "Epoch 476/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5604 - accuracy: 0.9740 - val_loss: 1.0374 - val_accuracy: 0.7500\n",
            "Epoch 477/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5699 - accuracy: 0.9826 - val_loss: 1.0439 - val_accuracy: 0.7500\n",
            "Epoch 478/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5744 - accuracy: 0.9792 - val_loss: 1.0449 - val_accuracy: 0.7500\n",
            "Epoch 479/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5640 - accuracy: 0.9774 - val_loss: 1.0409 - val_accuracy: 0.7500\n",
            "Epoch 480/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5752 - accuracy: 0.9740 - val_loss: 1.0459 - val_accuracy: 0.7500\n",
            "Epoch 481/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5763 - accuracy: 0.9792 - val_loss: 1.0366 - val_accuracy: 0.7569\n",
            "Epoch 482/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5572 - accuracy: 0.9878 - val_loss: 1.0329 - val_accuracy: 0.7431\n",
            "Epoch 483/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5565 - accuracy: 0.9757 - val_loss: 1.0433 - val_accuracy: 0.7292\n",
            "Epoch 484/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5638 - accuracy: 0.9826 - val_loss: 1.0540 - val_accuracy: 0.7153\n",
            "Epoch 485/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5772 - accuracy: 0.9618 - val_loss: 1.0355 - val_accuracy: 0.7569\n",
            "Epoch 486/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5498 - accuracy: 0.9722 - val_loss: 1.0498 - val_accuracy: 0.7500\n",
            "Epoch 487/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5765 - accuracy: 0.9757 - val_loss: 1.0361 - val_accuracy: 0.7431\n",
            "Epoch 488/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5550 - accuracy: 0.9809 - val_loss: 1.0408 - val_accuracy: 0.7500\n",
            "Epoch 489/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5557 - accuracy: 0.9653 - val_loss: 1.0462 - val_accuracy: 0.7431\n",
            "Epoch 490/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5447 - accuracy: 0.9861 - val_loss: 1.0362 - val_accuracy: 0.7500\n",
            "Epoch 491/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5545 - accuracy: 0.9740 - val_loss: 1.0376 - val_accuracy: 0.7222\n",
            "Epoch 492/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5543 - accuracy: 0.9844 - val_loss: 1.0490 - val_accuracy: 0.7292\n",
            "Epoch 493/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5566 - accuracy: 0.9757 - val_loss: 1.0335 - val_accuracy: 0.7500\n",
            "Epoch 494/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5575 - accuracy: 0.9861 - val_loss: 1.0502 - val_accuracy: 0.7431\n",
            "Epoch 495/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5550 - accuracy: 0.9826 - val_loss: 1.0444 - val_accuracy: 0.7708\n",
            "Epoch 496/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5464 - accuracy: 0.9722 - val_loss: 1.0352 - val_accuracy: 0.7500\n",
            "Epoch 497/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5402 - accuracy: 0.9861 - val_loss: 1.0344 - val_accuracy: 0.7569\n",
            "Epoch 498/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5639 - accuracy: 0.9792 - val_loss: 1.0532 - val_accuracy: 0.7569\n",
            "Epoch 499/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5588 - accuracy: 0.9774 - val_loss: 1.0341 - val_accuracy: 0.7500\n",
            "Epoch 500/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5379 - accuracy: 0.9861 - val_loss: 1.0335 - val_accuracy: 0.7500\n",
            "Epoch 501/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5492 - accuracy: 0.9792 - val_loss: 1.0326 - val_accuracy: 0.7708\n",
            "Epoch 502/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5463 - accuracy: 0.9878 - val_loss: 1.0202 - val_accuracy: 0.7639\n",
            "Epoch 503/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5541 - accuracy: 0.9774 - val_loss: 1.0288 - val_accuracy: 0.7569\n",
            "Epoch 504/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5482 - accuracy: 0.9826 - val_loss: 1.0213 - val_accuracy: 0.7431\n",
            "Epoch 505/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5587 - accuracy: 0.9740 - val_loss: 1.0371 - val_accuracy: 0.7639\n",
            "Epoch 506/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5553 - accuracy: 0.9774 - val_loss: 1.0215 - val_accuracy: 0.7569\n",
            "Epoch 507/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5415 - accuracy: 0.9792 - val_loss: 1.0437 - val_accuracy: 0.7639\n",
            "Epoch 508/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5449 - accuracy: 0.9913 - val_loss: 1.0340 - val_accuracy: 0.7431\n",
            "Epoch 509/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5679 - accuracy: 0.9774 - val_loss: 1.0381 - val_accuracy: 0.7639\n",
            "Epoch 510/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5603 - accuracy: 0.9792 - val_loss: 1.0272 - val_accuracy: 0.7708\n",
            "Epoch 511/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5429 - accuracy: 0.9740 - val_loss: 1.0240 - val_accuracy: 0.7431\n",
            "Epoch 512/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5329 - accuracy: 0.9878 - val_loss: 1.0348 - val_accuracy: 0.7500\n",
            "Epoch 513/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5505 - accuracy: 0.9792 - val_loss: 1.0437 - val_accuracy: 0.7500\n",
            "Epoch 514/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5576 - accuracy: 0.9757 - val_loss: 1.0530 - val_accuracy: 0.7431\n",
            "Epoch 515/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5392 - accuracy: 0.9861 - val_loss: 1.0220 - val_accuracy: 0.7569\n",
            "Epoch 516/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5406 - accuracy: 0.9878 - val_loss: 1.0371 - val_accuracy: 0.7569\n",
            "Epoch 517/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5349 - accuracy: 0.9896 - val_loss: 1.0283 - val_accuracy: 0.7361\n",
            "Epoch 518/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5507 - accuracy: 0.9774 - val_loss: 1.0326 - val_accuracy: 0.7500\n",
            "Epoch 519/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5336 - accuracy: 0.9844 - val_loss: 1.0251 - val_accuracy: 0.7639\n",
            "Epoch 520/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5415 - accuracy: 0.9844 - val_loss: 1.0429 - val_accuracy: 0.7361\n",
            "Epoch 521/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5395 - accuracy: 0.9948 - val_loss: 1.0360 - val_accuracy: 0.7431\n",
            "Epoch 522/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5367 - accuracy: 0.9809 - val_loss: 1.0460 - val_accuracy: 0.7153\n",
            "Epoch 523/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5308 - accuracy: 0.9774 - val_loss: 1.0362 - val_accuracy: 0.7361\n",
            "Epoch 524/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5293 - accuracy: 0.9913 - val_loss: 1.0340 - val_accuracy: 0.7639\n",
            "Epoch 525/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5449 - accuracy: 0.9861 - val_loss: 1.0285 - val_accuracy: 0.7639\n",
            "Epoch 526/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5312 - accuracy: 0.9861 - val_loss: 1.0263 - val_accuracy: 0.7222\n",
            "Epoch 527/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5320 - accuracy: 0.9826 - val_loss: 1.0289 - val_accuracy: 0.7500\n",
            "Epoch 528/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5452 - accuracy: 0.9861 - val_loss: 1.0165 - val_accuracy: 0.7569\n",
            "Epoch 529/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5220 - accuracy: 0.9896 - val_loss: 1.0152 - val_accuracy: 0.7569\n",
            "Epoch 530/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5479 - accuracy: 0.9792 - val_loss: 1.0354 - val_accuracy: 0.7569\n",
            "Epoch 531/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5415 - accuracy: 0.9844 - val_loss: 1.0368 - val_accuracy: 0.7569\n",
            "Epoch 532/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5252 - accuracy: 0.9965 - val_loss: 1.0352 - val_accuracy: 0.7569\n",
            "Epoch 533/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5280 - accuracy: 0.9896 - val_loss: 1.0315 - val_accuracy: 0.7569\n",
            "Epoch 534/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5234 - accuracy: 0.9878 - val_loss: 1.0352 - val_accuracy: 0.7431\n",
            "Epoch 535/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5345 - accuracy: 0.9826 - val_loss: 1.0233 - val_accuracy: 0.7569\n",
            "Epoch 536/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5319 - accuracy: 0.9861 - val_loss: 1.0288 - val_accuracy: 0.7569\n",
            "Epoch 537/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5435 - accuracy: 0.9844 - val_loss: 1.0310 - val_accuracy: 0.7708\n",
            "Epoch 538/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5126 - accuracy: 0.9931 - val_loss: 1.0308 - val_accuracy: 0.7500\n",
            "Epoch 539/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5283 - accuracy: 0.9931 - val_loss: 1.0278 - val_accuracy: 0.7708\n",
            "Epoch 540/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5187 - accuracy: 0.9896 - val_loss: 1.0160 - val_accuracy: 0.7639\n",
            "Epoch 541/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5322 - accuracy: 0.9844 - val_loss: 1.0352 - val_accuracy: 0.7569\n",
            "Epoch 542/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5249 - accuracy: 0.9861 - val_loss: 1.0398 - val_accuracy: 0.7431\n",
            "Epoch 543/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5196 - accuracy: 0.9792 - val_loss: 1.0556 - val_accuracy: 0.7500\n",
            "Epoch 544/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5089 - accuracy: 0.9931 - val_loss: 1.0229 - val_accuracy: 0.7569\n",
            "Epoch 545/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5396 - accuracy: 0.9792 - val_loss: 1.0121 - val_accuracy: 0.7569\n",
            "Epoch 546/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5344 - accuracy: 0.9826 - val_loss: 1.0211 - val_accuracy: 0.7708\n",
            "Epoch 547/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5249 - accuracy: 0.9774 - val_loss: 1.0129 - val_accuracy: 0.7569\n",
            "Epoch 548/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5233 - accuracy: 0.9913 - val_loss: 1.0059 - val_accuracy: 0.7639\n",
            "Epoch 549/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5276 - accuracy: 0.9861 - val_loss: 1.0168 - val_accuracy: 0.7431\n",
            "Epoch 550/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5266 - accuracy: 0.9896 - val_loss: 1.0245 - val_accuracy: 0.7569\n",
            "Epoch 551/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5223 - accuracy: 0.9931 - val_loss: 1.0257 - val_accuracy: 0.7569\n",
            "Epoch 552/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5225 - accuracy: 0.9896 - val_loss: 1.0239 - val_accuracy: 0.7639\n",
            "Epoch 553/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5263 - accuracy: 0.9861 - val_loss: 1.0259 - val_accuracy: 0.7569\n",
            "Epoch 554/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5343 - accuracy: 0.9861 - val_loss: 1.0382 - val_accuracy: 0.7431\n",
            "Epoch 555/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5374 - accuracy: 0.9809 - val_loss: 1.0152 - val_accuracy: 0.7292\n",
            "Epoch 556/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5399 - accuracy: 0.9844 - val_loss: 1.0231 - val_accuracy: 0.7500\n",
            "Epoch 557/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5137 - accuracy: 0.9931 - val_loss: 1.0282 - val_accuracy: 0.7569\n",
            "Epoch 558/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5164 - accuracy: 0.9861 - val_loss: 1.0346 - val_accuracy: 0.7431\n",
            "Epoch 559/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5192 - accuracy: 0.9896 - val_loss: 1.0278 - val_accuracy: 0.7500\n",
            "Epoch 560/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5165 - accuracy: 0.9913 - val_loss: 1.0201 - val_accuracy: 0.7639\n",
            "Epoch 561/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5211 - accuracy: 0.9878 - val_loss: 1.0224 - val_accuracy: 0.7569\n",
            "Epoch 562/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5228 - accuracy: 0.9809 - val_loss: 1.0281 - val_accuracy: 0.7569\n",
            "Epoch 563/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5009 - accuracy: 1.0000 - val_loss: 1.0213 - val_accuracy: 0.7847\n",
            "Epoch 564/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5161 - accuracy: 0.9965 - val_loss: 1.0170 - val_accuracy: 0.7500\n",
            "Epoch 565/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5243 - accuracy: 0.9896 - val_loss: 1.0297 - val_accuracy: 0.7569\n",
            "Epoch 566/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5237 - accuracy: 0.9861 - val_loss: 1.0214 - val_accuracy: 0.7361\n",
            "Epoch 567/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5141 - accuracy: 0.9931 - val_loss: 1.0122 - val_accuracy: 0.7569\n",
            "Epoch 568/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5122 - accuracy: 0.9878 - val_loss: 1.0121 - val_accuracy: 0.7708\n",
            "Epoch 569/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5040 - accuracy: 0.9913 - val_loss: 1.0259 - val_accuracy: 0.7500\n",
            "Epoch 570/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5118 - accuracy: 0.9896 - val_loss: 1.0223 - val_accuracy: 0.7569\n",
            "Epoch 571/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5126 - accuracy: 0.9896 - val_loss: 1.0139 - val_accuracy: 0.7639\n",
            "Epoch 572/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5327 - accuracy: 0.9740 - val_loss: 1.0159 - val_accuracy: 0.7708\n",
            "Epoch 573/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5239 - accuracy: 0.9844 - val_loss: 1.0122 - val_accuracy: 0.7778\n",
            "Epoch 574/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5159 - accuracy: 0.9861 - val_loss: 1.0203 - val_accuracy: 0.7569\n",
            "Epoch 575/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5092 - accuracy: 0.9896 - val_loss: 1.0218 - val_accuracy: 0.7569\n",
            "Epoch 576/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5165 - accuracy: 0.9896 - val_loss: 1.0145 - val_accuracy: 0.7569\n",
            "Epoch 577/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5120 - accuracy: 0.9844 - val_loss: 1.0134 - val_accuracy: 0.7639\n",
            "Epoch 578/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4969 - accuracy: 0.9896 - val_loss: 1.0205 - val_accuracy: 0.7569\n",
            "Epoch 579/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5046 - accuracy: 0.9896 - val_loss: 1.0235 - val_accuracy: 0.7639\n",
            "Epoch 580/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5149 - accuracy: 0.9861 - val_loss: 1.0351 - val_accuracy: 0.7639\n",
            "Epoch 581/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4951 - accuracy: 0.9896 - val_loss: 1.0131 - val_accuracy: 0.7708\n",
            "Epoch 582/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4991 - accuracy: 0.9913 - val_loss: 1.0214 - val_accuracy: 0.7778\n",
            "Epoch 583/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5138 - accuracy: 0.9861 - val_loss: 1.0191 - val_accuracy: 0.7569\n",
            "Epoch 584/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5065 - accuracy: 0.9948 - val_loss: 1.0292 - val_accuracy: 0.7639\n",
            "Epoch 585/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5114 - accuracy: 0.9913 - val_loss: 1.0112 - val_accuracy: 0.7500\n",
            "Epoch 586/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5014 - accuracy: 0.9826 - val_loss: 1.0304 - val_accuracy: 0.7778\n",
            "Epoch 587/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5113 - accuracy: 0.9913 - val_loss: 1.0266 - val_accuracy: 0.7569\n",
            "Epoch 588/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5024 - accuracy: 0.9931 - val_loss: 1.0319 - val_accuracy: 0.7361\n",
            "Epoch 589/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5220 - accuracy: 0.9809 - val_loss: 1.0219 - val_accuracy: 0.7708\n",
            "Epoch 590/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5050 - accuracy: 0.9913 - val_loss: 1.0167 - val_accuracy: 0.7500\n",
            "Epoch 591/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5086 - accuracy: 0.9878 - val_loss: 1.0218 - val_accuracy: 0.7500\n",
            "Epoch 592/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5059 - accuracy: 0.9913 - val_loss: 1.0280 - val_accuracy: 0.7431\n",
            "Epoch 593/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4839 - accuracy: 0.9948 - val_loss: 1.0408 - val_accuracy: 0.7500\n",
            "Epoch 594/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4888 - accuracy: 0.9948 - val_loss: 1.0236 - val_accuracy: 0.7500\n",
            "Epoch 595/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5082 - accuracy: 0.9826 - val_loss: 1.0300 - val_accuracy: 0.7431\n",
            "Epoch 596/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5110 - accuracy: 0.9878 - val_loss: 1.0346 - val_accuracy: 0.7431\n",
            "Epoch 597/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5116 - accuracy: 0.9861 - val_loss: 1.0080 - val_accuracy: 0.7569\n",
            "Epoch 598/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5138 - accuracy: 0.9878 - val_loss: 1.0209 - val_accuracy: 0.7708\n",
            "Epoch 599/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5028 - accuracy: 0.9913 - val_loss: 1.0171 - val_accuracy: 0.7569\n",
            "Epoch 600/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5097 - accuracy: 0.9878 - val_loss: 1.0266 - val_accuracy: 0.7708\n",
            "Epoch 601/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4954 - accuracy: 0.9931 - val_loss: 1.0351 - val_accuracy: 0.7500\n",
            "Epoch 602/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4999 - accuracy: 0.9913 - val_loss: 1.0191 - val_accuracy: 0.7708\n",
            "Epoch 603/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5032 - accuracy: 0.9809 - val_loss: 1.0236 - val_accuracy: 0.7431\n",
            "Epoch 604/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5022 - accuracy: 0.9948 - val_loss: 1.0266 - val_accuracy: 0.7431\n",
            "Epoch 605/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4960 - accuracy: 0.9913 - val_loss: 1.0226 - val_accuracy: 0.7431\n",
            "Epoch 606/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5080 - accuracy: 0.9896 - val_loss: 1.0182 - val_accuracy: 0.7569\n",
            "Epoch 607/700\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.4938 - accuracy: 0.9948 - val_loss: 1.0161 - val_accuracy: 0.7569\n",
            "Epoch 608/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4954 - accuracy: 0.9913 - val_loss: 1.0412 - val_accuracy: 0.7569\n",
            "Epoch 609/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5032 - accuracy: 0.9861 - val_loss: 1.0173 - val_accuracy: 0.7569\n",
            "Epoch 610/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4961 - accuracy: 0.9913 - val_loss: 1.0245 - val_accuracy: 0.7431\n",
            "Epoch 611/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4959 - accuracy: 0.9861 - val_loss: 1.0170 - val_accuracy: 0.7500\n",
            "Epoch 612/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5152 - accuracy: 0.9844 - val_loss: 1.0490 - val_accuracy: 0.7222\n",
            "Epoch 613/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4805 - accuracy: 0.9931 - val_loss: 1.0221 - val_accuracy: 0.7569\n",
            "Epoch 614/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5010 - accuracy: 0.9913 - val_loss: 1.0232 - val_accuracy: 0.7500\n",
            "Epoch 615/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4942 - accuracy: 0.9931 - val_loss: 1.0176 - val_accuracy: 0.7778\n",
            "Epoch 616/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4937 - accuracy: 0.9931 - val_loss: 1.0339 - val_accuracy: 0.7500\n",
            "Epoch 617/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5001 - accuracy: 0.9878 - val_loss: 1.0214 - val_accuracy: 0.7500\n",
            "Epoch 618/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4998 - accuracy: 0.9844 - val_loss: 1.0187 - val_accuracy: 0.7500\n",
            "Epoch 619/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5013 - accuracy: 0.9878 - val_loss: 1.0156 - val_accuracy: 0.7569\n",
            "Epoch 620/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4984 - accuracy: 0.9896 - val_loss: 1.0280 - val_accuracy: 0.7569\n",
            "Epoch 621/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5029 - accuracy: 0.9913 - val_loss: 1.0211 - val_accuracy: 0.7639\n",
            "Epoch 622/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4907 - accuracy: 0.9948 - val_loss: 1.0176 - val_accuracy: 0.7569\n",
            "Epoch 623/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4873 - accuracy: 0.9965 - val_loss: 1.0260 - val_accuracy: 0.7431\n",
            "Epoch 624/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.4765 - accuracy: 0.9896 - val_loss: 1.0183 - val_accuracy: 0.7431\n",
            "Epoch 625/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4932 - accuracy: 0.9965 - val_loss: 1.0223 - val_accuracy: 0.7569\n",
            "Epoch 626/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4950 - accuracy: 0.9913 - val_loss: 1.0274 - val_accuracy: 0.7500\n",
            "Epoch 627/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4795 - accuracy: 0.9896 - val_loss: 1.0190 - val_accuracy: 0.7569\n",
            "Epoch 628/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4986 - accuracy: 0.9913 - val_loss: 1.0217 - val_accuracy: 0.7569\n",
            "Epoch 629/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5009 - accuracy: 0.9878 - val_loss: 1.0112 - val_accuracy: 0.7500\n",
            "Epoch 630/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4804 - accuracy: 0.9983 - val_loss: 1.0061 - val_accuracy: 0.7431\n",
            "Epoch 631/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4962 - accuracy: 0.9931 - val_loss: 1.0245 - val_accuracy: 0.7500\n",
            "Epoch 632/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4900 - accuracy: 0.9896 - val_loss: 1.0112 - val_accuracy: 0.7639\n",
            "Epoch 633/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4855 - accuracy: 0.9983 - val_loss: 1.0083 - val_accuracy: 0.7569\n",
            "Epoch 634/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4870 - accuracy: 0.9965 - val_loss: 1.0160 - val_accuracy: 0.7500\n",
            "Epoch 635/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4919 - accuracy: 0.9965 - val_loss: 1.0270 - val_accuracy: 0.7431\n",
            "Epoch 636/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4644 - accuracy: 0.9983 - val_loss: 1.0165 - val_accuracy: 0.7500\n",
            "Epoch 637/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4757 - accuracy: 0.9948 - val_loss: 1.0164 - val_accuracy: 0.7639\n",
            "Epoch 638/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4929 - accuracy: 0.9878 - val_loss: 1.0293 - val_accuracy: 0.7500\n",
            "Epoch 639/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.4913 - accuracy: 0.9965 - val_loss: 1.0184 - val_accuracy: 0.7708\n",
            "Epoch 640/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4969 - accuracy: 0.9931 - val_loss: 1.0258 - val_accuracy: 0.7708\n",
            "Epoch 641/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4932 - accuracy: 0.9913 - val_loss: 1.0302 - val_accuracy: 0.7569\n",
            "Epoch 642/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4811 - accuracy: 0.9913 - val_loss: 1.0278 - val_accuracy: 0.7431\n",
            "Epoch 643/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4786 - accuracy: 0.9965 - val_loss: 1.0154 - val_accuracy: 0.7639\n",
            "Epoch 644/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4833 - accuracy: 0.9965 - val_loss: 1.0227 - val_accuracy: 0.7708\n",
            "Epoch 645/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4868 - accuracy: 0.9948 - val_loss: 1.0161 - val_accuracy: 0.7500\n",
            "Epoch 646/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4816 - accuracy: 0.9931 - val_loss: 1.0034 - val_accuracy: 0.7639\n",
            "Epoch 647/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4968 - accuracy: 0.9878 - val_loss: 1.0143 - val_accuracy: 0.7500\n",
            "Epoch 648/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4741 - accuracy: 0.9931 - val_loss: 1.0247 - val_accuracy: 0.7569\n",
            "Epoch 649/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4794 - accuracy: 0.9948 - val_loss: 1.0327 - val_accuracy: 0.7708\n",
            "Epoch 650/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4948 - accuracy: 0.9792 - val_loss: 1.0264 - val_accuracy: 0.7500\n",
            "Epoch 651/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4768 - accuracy: 0.9931 - val_loss: 1.0163 - val_accuracy: 0.7569\n",
            "Epoch 652/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4788 - accuracy: 0.9931 - val_loss: 1.0120 - val_accuracy: 0.7708\n",
            "Epoch 653/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4794 - accuracy: 0.9931 - val_loss: 1.0066 - val_accuracy: 0.7708\n",
            "Epoch 654/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4701 - accuracy: 0.9948 - val_loss: 1.0082 - val_accuracy: 0.7569\n",
            "Epoch 655/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4825 - accuracy: 0.9948 - val_loss: 1.0112 - val_accuracy: 0.7569\n",
            "Epoch 656/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4679 - accuracy: 1.0000 - val_loss: 1.0073 - val_accuracy: 0.7569\n",
            "Epoch 657/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4593 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.7708\n",
            "Epoch 658/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4634 - accuracy: 0.9965 - val_loss: 1.0148 - val_accuracy: 0.7639\n",
            "Epoch 659/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4717 - accuracy: 0.9965 - val_loss: 1.0036 - val_accuracy: 0.7500\n",
            "Epoch 660/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4767 - accuracy: 1.0000 - val_loss: 1.0141 - val_accuracy: 0.7569\n",
            "Epoch 661/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4828 - accuracy: 0.9913 - val_loss: 0.9921 - val_accuracy: 0.7569\n",
            "Epoch 662/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4722 - accuracy: 0.9983 - val_loss: 0.9888 - val_accuracy: 0.7569\n",
            "Epoch 663/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4810 - accuracy: 0.9913 - val_loss: 1.0058 - val_accuracy: 0.7639\n",
            "Epoch 664/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4957 - accuracy: 0.9913 - val_loss: 1.0083 - val_accuracy: 0.7569\n",
            "Epoch 665/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4809 - accuracy: 0.9948 - val_loss: 1.0046 - val_accuracy: 0.7569\n",
            "Epoch 666/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4842 - accuracy: 0.9931 - val_loss: 1.0133 - val_accuracy: 0.7639\n",
            "Epoch 667/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4751 - accuracy: 0.9983 - val_loss: 0.9911 - val_accuracy: 0.7708\n",
            "Epoch 668/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4861 - accuracy: 0.9948 - val_loss: 1.0035 - val_accuracy: 0.7639\n",
            "Epoch 669/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4591 - accuracy: 0.9965 - val_loss: 1.0069 - val_accuracy: 0.7569\n",
            "Epoch 670/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4813 - accuracy: 0.9913 - val_loss: 0.9958 - val_accuracy: 0.7917\n",
            "Epoch 671/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4696 - accuracy: 0.9913 - val_loss: 1.0106 - val_accuracy: 0.7708\n",
            "Epoch 672/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4712 - accuracy: 1.0000 - val_loss: 1.0039 - val_accuracy: 0.7778\n",
            "Epoch 673/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4648 - accuracy: 0.9965 - val_loss: 1.0165 - val_accuracy: 0.7569\n",
            "Epoch 674/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4669 - accuracy: 0.9983 - val_loss: 1.0089 - val_accuracy: 0.7778\n",
            "Epoch 675/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4755 - accuracy: 0.9948 - val_loss: 1.0158 - val_accuracy: 0.7708\n",
            "Epoch 676/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4805 - accuracy: 0.9913 - val_loss: 1.0162 - val_accuracy: 0.7361\n",
            "Epoch 677/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4617 - accuracy: 0.9983 - val_loss: 1.0065 - val_accuracy: 0.7569\n",
            "Epoch 678/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4647 - accuracy: 0.9948 - val_loss: 1.0209 - val_accuracy: 0.7361\n",
            "Epoch 679/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4662 - accuracy: 0.9948 - val_loss: 1.0138 - val_accuracy: 0.7569\n",
            "Epoch 680/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4679 - accuracy: 0.9896 - val_loss: 1.0081 - val_accuracy: 0.7500\n",
            "Epoch 681/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4716 - accuracy: 0.9913 - val_loss: 1.0143 - val_accuracy: 0.7500\n",
            "Epoch 682/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4595 - accuracy: 0.9983 - val_loss: 1.0239 - val_accuracy: 0.7569\n",
            "Epoch 683/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4709 - accuracy: 0.9965 - val_loss: 1.0119 - val_accuracy: 0.7431\n",
            "Epoch 684/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4645 - accuracy: 0.9913 - val_loss: 1.0181 - val_accuracy: 0.7431\n",
            "Epoch 685/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4686 - accuracy: 0.9948 - val_loss: 1.0190 - val_accuracy: 0.7708\n",
            "Epoch 686/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4841 - accuracy: 0.9913 - val_loss: 1.0247 - val_accuracy: 0.7431\n",
            "Epoch 687/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4712 - accuracy: 0.9948 - val_loss: 1.0079 - val_accuracy: 0.7569\n",
            "Epoch 688/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4557 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 0.7431\n",
            "Epoch 689/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.4677 - accuracy: 0.9896 - val_loss: 1.0309 - val_accuracy: 0.7708\n",
            "Epoch 690/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4572 - accuracy: 0.9931 - val_loss: 1.0140 - val_accuracy: 0.7639\n",
            "Epoch 691/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.4708 - accuracy: 0.9948 - val_loss: 0.9965 - val_accuracy: 0.7708\n",
            "Epoch 692/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4464 - accuracy: 0.9948 - val_loss: 1.0288 - val_accuracy: 0.7639\n",
            "Epoch 693/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4794 - accuracy: 0.9878 - val_loss: 1.0098 - val_accuracy: 0.7708\n",
            "Epoch 694/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4678 - accuracy: 0.9948 - val_loss: 1.0043 - val_accuracy: 0.7500\n",
            "Epoch 695/700\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.4602 - accuracy: 0.9983 - val_loss: 1.0149 - val_accuracy: 0.7847\n",
            "Epoch 696/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4674 - accuracy: 0.9965 - val_loss: 1.0130 - val_accuracy: 0.7639\n",
            "Epoch 697/700\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.4564 - accuracy: 0.9965 - val_loss: 1.0126 - val_accuracy: 0.7708\n",
            "Epoch 698/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4637 - accuracy: 0.9948 - val_loss: 1.0026 - val_accuracy: 0.7500\n",
            "Epoch 699/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4663 - accuracy: 0.9983 - val_loss: 1.0034 - val_accuracy: 0.7569\n",
            "Epoch 700/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4833 - accuracy: 0.9931 - val_loss: 1.0141 - val_accuracy: 0.7708\n",
            "3\n",
            "Epoch 1/700\n",
            "9/9 [==============================] - 2s 110ms/step - loss: 2.3302 - accuracy: 0.1597 - val_loss: 2.4984 - val_accuracy: 0.1111\n",
            "Epoch 2/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 2.3373 - accuracy: 0.1649 - val_loss: 2.3563 - val_accuracy: 0.1111\n",
            "Epoch 3/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 2.1687 - accuracy: 0.1858 - val_loss: 2.2459 - val_accuracy: 0.1181\n",
            "Epoch 4/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 2.2101 - accuracy: 0.1719 - val_loss: 2.1560 - val_accuracy: 0.1181\n",
            "Epoch 5/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 2.1083 - accuracy: 0.2205 - val_loss: 2.1086 - val_accuracy: 0.1389\n",
            "Epoch 6/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 2.0514 - accuracy: 0.2309 - val_loss: 2.0797 - val_accuracy: 0.1528\n",
            "Epoch 7/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 2.0420 - accuracy: 0.2431 - val_loss: 2.0420 - val_accuracy: 0.1806\n",
            "Epoch 8/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 2.0614 - accuracy: 0.2274 - val_loss: 2.0140 - val_accuracy: 0.2222\n",
            "Epoch 9/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.9941 - accuracy: 0.2500 - val_loss: 1.9945 - val_accuracy: 0.2222\n",
            "Epoch 10/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 2.0041 - accuracy: 0.2448 - val_loss: 1.9749 - val_accuracy: 0.2361\n",
            "Epoch 11/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.9361 - accuracy: 0.2465 - val_loss: 1.9628 - val_accuracy: 0.2569\n",
            "Epoch 12/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.9296 - accuracy: 0.2639 - val_loss: 1.9567 - val_accuracy: 0.3125\n",
            "Epoch 13/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.9354 - accuracy: 0.2830 - val_loss: 1.9497 - val_accuracy: 0.3472\n",
            "Epoch 14/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.8676 - accuracy: 0.2743 - val_loss: 1.9514 - val_accuracy: 0.3611\n",
            "Epoch 15/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.9266 - accuracy: 0.2691 - val_loss: 1.9464 - val_accuracy: 0.3264\n",
            "Epoch 16/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.8410 - accuracy: 0.3021 - val_loss: 1.9403 - val_accuracy: 0.3333\n",
            "Epoch 17/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.8040 - accuracy: 0.3212 - val_loss: 1.9518 - val_accuracy: 0.2847\n",
            "Epoch 18/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.8595 - accuracy: 0.2778 - val_loss: 1.9457 - val_accuracy: 0.2639\n",
            "Epoch 19/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.8145 - accuracy: 0.3333 - val_loss: 1.9503 - val_accuracy: 0.2431\n",
            "Epoch 20/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.7601 - accuracy: 0.3403 - val_loss: 1.9483 - val_accuracy: 0.2431\n",
            "Epoch 21/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 1.7615 - accuracy: 0.3385 - val_loss: 1.9522 - val_accuracy: 0.2222\n",
            "Epoch 22/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.7479 - accuracy: 0.3333 - val_loss: 1.9641 - val_accuracy: 0.2083\n",
            "Epoch 23/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.7528 - accuracy: 0.3403 - val_loss: 1.9675 - val_accuracy: 0.2083\n",
            "Epoch 24/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.7308 - accuracy: 0.3663 - val_loss: 1.9731 - val_accuracy: 0.2083\n",
            "Epoch 25/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.7149 - accuracy: 0.3368 - val_loss: 1.9742 - val_accuracy: 0.2083\n",
            "Epoch 26/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.6561 - accuracy: 0.3802 - val_loss: 1.9772 - val_accuracy: 0.2639\n",
            "Epoch 27/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6838 - accuracy: 0.3594 - val_loss: 1.9874 - val_accuracy: 0.2222\n",
            "Epoch 28/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.6573 - accuracy: 0.4115 - val_loss: 1.9888 - val_accuracy: 0.2222\n",
            "Epoch 29/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.6676 - accuracy: 0.3472 - val_loss: 1.9708 - val_accuracy: 0.2569\n",
            "Epoch 30/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.6276 - accuracy: 0.4271 - val_loss: 1.9685 - val_accuracy: 0.2847\n",
            "Epoch 31/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.6482 - accuracy: 0.3750 - val_loss: 1.9676 - val_accuracy: 0.2153\n",
            "Epoch 32/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.6184 - accuracy: 0.3889 - val_loss: 1.9643 - val_accuracy: 0.2778\n",
            "Epoch 33/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6501 - accuracy: 0.3715 - val_loss: 1.9360 - val_accuracy: 0.2917\n",
            "Epoch 34/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.5859 - accuracy: 0.4288 - val_loss: 1.9217 - val_accuracy: 0.2847\n",
            "Epoch 35/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.5920 - accuracy: 0.4306 - val_loss: 1.9067 - val_accuracy: 0.2986\n",
            "Epoch 36/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.5362 - accuracy: 0.4497 - val_loss: 1.9049 - val_accuracy: 0.2986\n",
            "Epoch 37/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.5512 - accuracy: 0.4236 - val_loss: 1.8861 - val_accuracy: 0.3056\n",
            "Epoch 38/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.5359 - accuracy: 0.4757 - val_loss: 1.8810 - val_accuracy: 0.2639\n",
            "Epoch 39/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.5297 - accuracy: 0.4913 - val_loss: 1.8693 - val_accuracy: 0.2986\n",
            "Epoch 40/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.5051 - accuracy: 0.4826 - val_loss: 1.8543 - val_accuracy: 0.3056\n",
            "Epoch 41/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.5104 - accuracy: 0.4653 - val_loss: 1.8426 - val_accuracy: 0.2917\n",
            "Epoch 42/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4969 - accuracy: 0.4514 - val_loss: 1.8381 - val_accuracy: 0.2847\n",
            "Epoch 43/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.4670 - accuracy: 0.4705 - val_loss: 1.8202 - val_accuracy: 0.2708\n",
            "Epoch 44/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.5121 - accuracy: 0.4670 - val_loss: 1.8175 - val_accuracy: 0.2778\n",
            "Epoch 45/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4508 - accuracy: 0.4983 - val_loss: 1.8068 - val_accuracy: 0.2847\n",
            "Epoch 46/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.4738 - accuracy: 0.4740 - val_loss: 1.8148 - val_accuracy: 0.2778\n",
            "Epoch 47/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4978 - accuracy: 0.4740 - val_loss: 1.8096 - val_accuracy: 0.2986\n",
            "Epoch 48/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.4424 - accuracy: 0.4965 - val_loss: 1.8016 - val_accuracy: 0.3125\n",
            "Epoch 49/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4294 - accuracy: 0.5069 - val_loss: 1.7718 - val_accuracy: 0.3403\n",
            "Epoch 50/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.4109 - accuracy: 0.5226 - val_loss: 1.7693 - val_accuracy: 0.3333\n",
            "Epoch 51/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.4530 - accuracy: 0.5069 - val_loss: 1.7585 - val_accuracy: 0.3333\n",
            "Epoch 52/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3596 - accuracy: 0.5469 - val_loss: 1.7351 - val_accuracy: 0.3472\n",
            "Epoch 53/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4517 - accuracy: 0.4896 - val_loss: 1.7324 - val_accuracy: 0.3403\n",
            "Epoch 54/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3745 - accuracy: 0.5399 - val_loss: 1.7258 - val_accuracy: 0.3472\n",
            "Epoch 55/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3633 - accuracy: 0.5486 - val_loss: 1.7093 - val_accuracy: 0.3472\n",
            "Epoch 56/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 1.3555 - accuracy: 0.5677 - val_loss: 1.7150 - val_accuracy: 0.3333\n",
            "Epoch 57/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3886 - accuracy: 0.5122 - val_loss: 1.6892 - val_accuracy: 0.3681\n",
            "Epoch 58/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3386 - accuracy: 0.5694 - val_loss: 1.6888 - val_accuracy: 0.3681\n",
            "Epoch 59/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.3863 - accuracy: 0.5347 - val_loss: 1.6661 - val_accuracy: 0.4167\n",
            "Epoch 60/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3470 - accuracy: 0.5503 - val_loss: 1.6633 - val_accuracy: 0.3819\n",
            "Epoch 61/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3540 - accuracy: 0.5625 - val_loss: 1.6464 - val_accuracy: 0.3819\n",
            "Epoch 62/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3383 - accuracy: 0.5503 - val_loss: 1.6295 - val_accuracy: 0.3819\n",
            "Epoch 63/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3281 - accuracy: 0.5556 - val_loss: 1.6217 - val_accuracy: 0.4028\n",
            "Epoch 64/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3538 - accuracy: 0.5347 - val_loss: 1.6366 - val_accuracy: 0.3681\n",
            "Epoch 65/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2769 - accuracy: 0.5972 - val_loss: 1.6240 - val_accuracy: 0.3819\n",
            "Epoch 66/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3127 - accuracy: 0.5694 - val_loss: 1.6239 - val_accuracy: 0.4097\n",
            "Epoch 67/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3113 - accuracy: 0.5573 - val_loss: 1.5751 - val_accuracy: 0.4306\n",
            "Epoch 68/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3241 - accuracy: 0.5625 - val_loss: 1.5529 - val_accuracy: 0.4722\n",
            "Epoch 69/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2913 - accuracy: 0.5799 - val_loss: 1.5610 - val_accuracy: 0.4653\n",
            "Epoch 70/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2763 - accuracy: 0.5764 - val_loss: 1.5572 - val_accuracy: 0.4583\n",
            "Epoch 71/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2922 - accuracy: 0.5903 - val_loss: 1.5377 - val_accuracy: 0.4792\n",
            "Epoch 72/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2825 - accuracy: 0.5851 - val_loss: 1.5312 - val_accuracy: 0.4792\n",
            "Epoch 73/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2663 - accuracy: 0.6094 - val_loss: 1.5212 - val_accuracy: 0.4861\n",
            "Epoch 74/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2837 - accuracy: 0.5816 - val_loss: 1.5186 - val_accuracy: 0.4931\n",
            "Epoch 75/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2389 - accuracy: 0.6024 - val_loss: 1.5118 - val_accuracy: 0.5000\n",
            "Epoch 76/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2709 - accuracy: 0.5747 - val_loss: 1.4762 - val_accuracy: 0.5208\n",
            "Epoch 77/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2625 - accuracy: 0.5833 - val_loss: 1.4709 - val_accuracy: 0.5486\n",
            "Epoch 78/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2412 - accuracy: 0.6163 - val_loss: 1.4771 - val_accuracy: 0.5069\n",
            "Epoch 79/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2159 - accuracy: 0.6389 - val_loss: 1.4548 - val_accuracy: 0.5278\n",
            "Epoch 80/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2280 - accuracy: 0.6337 - val_loss: 1.4654 - val_accuracy: 0.5208\n",
            "Epoch 81/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2416 - accuracy: 0.6059 - val_loss: 1.4943 - val_accuracy: 0.4931\n",
            "Epoch 82/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2119 - accuracy: 0.6146 - val_loss: 1.4620 - val_accuracy: 0.5139\n",
            "Epoch 83/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2051 - accuracy: 0.6406 - val_loss: 1.4405 - val_accuracy: 0.5208\n",
            "Epoch 84/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1962 - accuracy: 0.6285 - val_loss: 1.4253 - val_accuracy: 0.5347\n",
            "Epoch 85/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2047 - accuracy: 0.6319 - val_loss: 1.4140 - val_accuracy: 0.5417\n",
            "Epoch 86/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2267 - accuracy: 0.6198 - val_loss: 1.3880 - val_accuracy: 0.5556\n",
            "Epoch 87/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2312 - accuracy: 0.6111 - val_loss: 1.3934 - val_accuracy: 0.5556\n",
            "Epoch 88/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.1796 - accuracy: 0.6597 - val_loss: 1.3971 - val_accuracy: 0.5417\n",
            "Epoch 89/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1939 - accuracy: 0.6528 - val_loss: 1.3854 - val_accuracy: 0.5556\n",
            "Epoch 90/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1867 - accuracy: 0.6458 - val_loss: 1.3999 - val_accuracy: 0.5347\n",
            "Epoch 91/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1793 - accuracy: 0.6684 - val_loss: 1.3909 - val_accuracy: 0.5417\n",
            "Epoch 92/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1687 - accuracy: 0.6441 - val_loss: 1.3595 - val_accuracy: 0.5833\n",
            "Epoch 93/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1565 - accuracy: 0.6771 - val_loss: 1.3977 - val_accuracy: 0.5556\n",
            "Epoch 94/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1853 - accuracy: 0.6562 - val_loss: 1.3664 - val_accuracy: 0.5972\n",
            "Epoch 95/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1595 - accuracy: 0.6788 - val_loss: 1.3651 - val_accuracy: 0.5833\n",
            "Epoch 96/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1440 - accuracy: 0.6875 - val_loss: 1.3737 - val_accuracy: 0.5625\n",
            "Epoch 97/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1931 - accuracy: 0.6528 - val_loss: 1.3923 - val_accuracy: 0.5417\n",
            "Epoch 98/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1181 - accuracy: 0.6892 - val_loss: 1.3693 - val_accuracy: 0.5625\n",
            "Epoch 99/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1495 - accuracy: 0.6597 - val_loss: 1.3520 - val_accuracy: 0.5833\n",
            "Epoch 100/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 1.1527 - accuracy: 0.6545 - val_loss: 1.3592 - val_accuracy: 0.5556\n",
            "Epoch 101/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1316 - accuracy: 0.6806 - val_loss: 1.3391 - val_accuracy: 0.5764\n",
            "Epoch 102/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1232 - accuracy: 0.6979 - val_loss: 1.3371 - val_accuracy: 0.6181\n",
            "Epoch 103/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1457 - accuracy: 0.6684 - val_loss: 1.3479 - val_accuracy: 0.5694\n",
            "Epoch 104/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1238 - accuracy: 0.6892 - val_loss: 1.3212 - val_accuracy: 0.5903\n",
            "Epoch 105/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1175 - accuracy: 0.6875 - val_loss: 1.3290 - val_accuracy: 0.6111\n",
            "Epoch 106/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.1111 - accuracy: 0.6997 - val_loss: 1.3273 - val_accuracy: 0.5903\n",
            "Epoch 107/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1106 - accuracy: 0.6840 - val_loss: 1.3128 - val_accuracy: 0.6111\n",
            "Epoch 108/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1202 - accuracy: 0.6771 - val_loss: 1.3265 - val_accuracy: 0.5972\n",
            "Epoch 109/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1010 - accuracy: 0.7014 - val_loss: 1.3216 - val_accuracy: 0.6250\n",
            "Epoch 110/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1068 - accuracy: 0.6736 - val_loss: 1.3168 - val_accuracy: 0.6042\n",
            "Epoch 111/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1096 - accuracy: 0.6840 - val_loss: 1.3139 - val_accuracy: 0.6042\n",
            "Epoch 112/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0873 - accuracy: 0.7031 - val_loss: 1.3172 - val_accuracy: 0.6042\n",
            "Epoch 113/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0956 - accuracy: 0.6944 - val_loss: 1.3159 - val_accuracy: 0.6250\n",
            "Epoch 114/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0823 - accuracy: 0.7049 - val_loss: 1.3006 - val_accuracy: 0.6042\n",
            "Epoch 115/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0843 - accuracy: 0.7135 - val_loss: 1.2900 - val_accuracy: 0.6389\n",
            "Epoch 116/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1035 - accuracy: 0.7066 - val_loss: 1.3045 - val_accuracy: 0.5972\n",
            "Epoch 117/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0968 - accuracy: 0.6979 - val_loss: 1.3178 - val_accuracy: 0.6181\n",
            "Epoch 118/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0629 - accuracy: 0.7257 - val_loss: 1.3194 - val_accuracy: 0.5903\n",
            "Epoch 119/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0762 - accuracy: 0.7274 - val_loss: 1.3002 - val_accuracy: 0.6111\n",
            "Epoch 120/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0801 - accuracy: 0.7118 - val_loss: 1.3094 - val_accuracy: 0.5903\n",
            "Epoch 121/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0744 - accuracy: 0.7049 - val_loss: 1.3085 - val_accuracy: 0.5972\n",
            "Epoch 122/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0472 - accuracy: 0.7031 - val_loss: 1.3023 - val_accuracy: 0.6111\n",
            "Epoch 123/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0691 - accuracy: 0.6997 - val_loss: 1.3075 - val_accuracy: 0.6181\n",
            "Epoch 124/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0703 - accuracy: 0.7118 - val_loss: 1.3027 - val_accuracy: 0.6250\n",
            "Epoch 125/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0543 - accuracy: 0.7188 - val_loss: 1.2960 - val_accuracy: 0.6319\n",
            "Epoch 126/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0870 - accuracy: 0.6979 - val_loss: 1.3000 - val_accuracy: 0.6319\n",
            "Epoch 127/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0213 - accuracy: 0.7396 - val_loss: 1.2953 - val_accuracy: 0.6111\n",
            "Epoch 128/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0560 - accuracy: 0.7083 - val_loss: 1.3153 - val_accuracy: 0.6250\n",
            "Epoch 129/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0628 - accuracy: 0.6979 - val_loss: 1.2894 - val_accuracy: 0.6111\n",
            "Epoch 130/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0511 - accuracy: 0.7292 - val_loss: 1.2758 - val_accuracy: 0.6111\n",
            "Epoch 131/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0481 - accuracy: 0.7344 - val_loss: 1.2746 - val_accuracy: 0.6389\n",
            "Epoch 132/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0350 - accuracy: 0.7309 - val_loss: 1.2916 - val_accuracy: 0.6181\n",
            "Epoch 133/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 1.0602 - accuracy: 0.6927 - val_loss: 1.3039 - val_accuracy: 0.5972\n",
            "Epoch 134/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0435 - accuracy: 0.7240 - val_loss: 1.2836 - val_accuracy: 0.6181\n",
            "Epoch 135/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0253 - accuracy: 0.7344 - val_loss: 1.2964 - val_accuracy: 0.6181\n",
            "Epoch 136/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0209 - accuracy: 0.7483 - val_loss: 1.2747 - val_accuracy: 0.6319\n",
            "Epoch 137/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0252 - accuracy: 0.7240 - val_loss: 1.2790 - val_accuracy: 0.6389\n",
            "Epoch 138/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0469 - accuracy: 0.7188 - val_loss: 1.2524 - val_accuracy: 0.6181\n",
            "Epoch 139/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0210 - accuracy: 0.7396 - val_loss: 1.2728 - val_accuracy: 0.6319\n",
            "Epoch 140/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0506 - accuracy: 0.7031 - val_loss: 1.2733 - val_accuracy: 0.6597\n",
            "Epoch 141/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9960 - accuracy: 0.7465 - val_loss: 1.2672 - val_accuracy: 0.6389\n",
            "Epoch 142/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0331 - accuracy: 0.7413 - val_loss: 1.2525 - val_accuracy: 0.6389\n",
            "Epoch 143/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0163 - accuracy: 0.7222 - val_loss: 1.2507 - val_accuracy: 0.6319\n",
            "Epoch 144/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0131 - accuracy: 0.7552 - val_loss: 1.2673 - val_accuracy: 0.6667\n",
            "Epoch 145/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0188 - accuracy: 0.7135 - val_loss: 1.2565 - val_accuracy: 0.6528\n",
            "Epoch 146/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9960 - accuracy: 0.7517 - val_loss: 1.2569 - val_accuracy: 0.6319\n",
            "Epoch 147/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9838 - accuracy: 0.7656 - val_loss: 1.2561 - val_accuracy: 0.6389\n",
            "Epoch 148/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0055 - accuracy: 0.7639 - val_loss: 1.2621 - val_accuracy: 0.6458\n",
            "Epoch 149/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9815 - accuracy: 0.7743 - val_loss: 1.2490 - val_accuracy: 0.6667\n",
            "Epoch 150/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9972 - accuracy: 0.7552 - val_loss: 1.2699 - val_accuracy: 0.6528\n",
            "Epoch 151/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9931 - accuracy: 0.7535 - val_loss: 1.2424 - val_accuracy: 0.6806\n",
            "Epoch 152/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9752 - accuracy: 0.7726 - val_loss: 1.2449 - val_accuracy: 0.6597\n",
            "Epoch 153/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9728 - accuracy: 0.7847 - val_loss: 1.2536 - val_accuracy: 0.6389\n",
            "Epoch 154/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9836 - accuracy: 0.7587 - val_loss: 1.2395 - val_accuracy: 0.6597\n",
            "Epoch 155/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9710 - accuracy: 0.7708 - val_loss: 1.2426 - val_accuracy: 0.6736\n",
            "Epoch 156/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9910 - accuracy: 0.7743 - val_loss: 1.2501 - val_accuracy: 0.6528\n",
            "Epoch 157/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9786 - accuracy: 0.7569 - val_loss: 1.2471 - val_accuracy: 0.6389\n",
            "Epoch 158/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9606 - accuracy: 0.7882 - val_loss: 1.2462 - val_accuracy: 0.6458\n",
            "Epoch 159/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9792 - accuracy: 0.7674 - val_loss: 1.2449 - val_accuracy: 0.6389\n",
            "Epoch 160/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9832 - accuracy: 0.7882 - val_loss: 1.2486 - val_accuracy: 0.6250\n",
            "Epoch 161/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9767 - accuracy: 0.7795 - val_loss: 1.2493 - val_accuracy: 0.6528\n",
            "Epoch 162/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.9647 - accuracy: 0.7674 - val_loss: 1.2537 - val_accuracy: 0.6597\n",
            "Epoch 163/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9670 - accuracy: 0.7656 - val_loss: 1.2369 - val_accuracy: 0.6597\n",
            "Epoch 164/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9587 - accuracy: 0.7726 - val_loss: 1.2438 - val_accuracy: 0.6319\n",
            "Epoch 165/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9491 - accuracy: 0.7969 - val_loss: 1.2415 - val_accuracy: 0.6528\n",
            "Epoch 166/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9472 - accuracy: 0.7882 - val_loss: 1.2312 - val_accuracy: 0.6597\n",
            "Epoch 167/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9597 - accuracy: 0.7795 - val_loss: 1.2332 - val_accuracy: 0.6806\n",
            "Epoch 168/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9487 - accuracy: 0.7969 - val_loss: 1.2347 - val_accuracy: 0.6458\n",
            "Epoch 169/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9511 - accuracy: 0.7951 - val_loss: 1.2266 - val_accuracy: 0.6875\n",
            "Epoch 170/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9483 - accuracy: 0.7812 - val_loss: 1.2198 - val_accuracy: 0.6736\n",
            "Epoch 171/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9504 - accuracy: 0.7656 - val_loss: 1.2161 - val_accuracy: 0.6597\n",
            "Epoch 172/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9472 - accuracy: 0.7969 - val_loss: 1.2212 - val_accuracy: 0.6944\n",
            "Epoch 173/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9369 - accuracy: 0.7899 - val_loss: 1.2239 - val_accuracy: 0.6667\n",
            "Epoch 174/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9300 - accuracy: 0.8108 - val_loss: 1.2487 - val_accuracy: 0.6528\n",
            "Epoch 175/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9568 - accuracy: 0.7812 - val_loss: 1.2439 - val_accuracy: 0.6806\n",
            "Epoch 176/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9531 - accuracy: 0.7726 - val_loss: 1.2624 - val_accuracy: 0.6389\n",
            "Epoch 177/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9311 - accuracy: 0.8021 - val_loss: 1.2431 - val_accuracy: 0.6597\n",
            "Epoch 178/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9254 - accuracy: 0.7969 - val_loss: 1.2334 - val_accuracy: 0.6806\n",
            "Epoch 179/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9138 - accuracy: 0.8108 - val_loss: 1.2316 - val_accuracy: 0.6528\n",
            "Epoch 180/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9346 - accuracy: 0.7917 - val_loss: 1.2236 - val_accuracy: 0.6389\n",
            "Epoch 181/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9252 - accuracy: 0.8090 - val_loss: 1.2235 - val_accuracy: 0.7014\n",
            "Epoch 182/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9441 - accuracy: 0.8021 - val_loss: 1.2296 - val_accuracy: 0.6875\n",
            "Epoch 183/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9239 - accuracy: 0.7986 - val_loss: 1.2244 - val_accuracy: 0.7014\n",
            "Epoch 184/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9024 - accuracy: 0.8247 - val_loss: 1.2303 - val_accuracy: 0.6528\n",
            "Epoch 185/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9154 - accuracy: 0.7934 - val_loss: 1.2322 - val_accuracy: 0.6458\n",
            "Epoch 186/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8899 - accuracy: 0.8177 - val_loss: 1.2026 - val_accuracy: 0.7083\n",
            "Epoch 187/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9098 - accuracy: 0.8142 - val_loss: 1.2086 - val_accuracy: 0.6806\n",
            "Epoch 188/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8820 - accuracy: 0.8056 - val_loss: 1.2143 - val_accuracy: 0.6875\n",
            "Epoch 189/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9003 - accuracy: 0.8142 - val_loss: 1.2171 - val_accuracy: 0.6875\n",
            "Epoch 190/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8997 - accuracy: 0.8212 - val_loss: 1.2018 - val_accuracy: 0.6944\n",
            "Epoch 191/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9057 - accuracy: 0.8003 - val_loss: 1.2220 - val_accuracy: 0.6736\n",
            "Epoch 192/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8925 - accuracy: 0.8281 - val_loss: 1.2221 - val_accuracy: 0.6736\n",
            "Epoch 193/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8893 - accuracy: 0.8264 - val_loss: 1.1981 - val_accuracy: 0.7083\n",
            "Epoch 194/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9038 - accuracy: 0.8212 - val_loss: 1.2025 - val_accuracy: 0.6944\n",
            "Epoch 195/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8981 - accuracy: 0.8177 - val_loss: 1.1993 - val_accuracy: 0.6944\n",
            "Epoch 196/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9175 - accuracy: 0.7934 - val_loss: 1.2277 - val_accuracy: 0.6597\n",
            "Epoch 197/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9016 - accuracy: 0.8212 - val_loss: 1.2123 - val_accuracy: 0.6458\n",
            "Epoch 198/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8903 - accuracy: 0.8142 - val_loss: 1.2170 - val_accuracy: 0.6944\n",
            "Epoch 199/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8759 - accuracy: 0.8229 - val_loss: 1.1938 - val_accuracy: 0.7014\n",
            "Epoch 200/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8921 - accuracy: 0.8281 - val_loss: 1.2026 - val_accuracy: 0.7431\n",
            "Epoch 201/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8653 - accuracy: 0.8316 - val_loss: 1.1993 - val_accuracy: 0.7014\n",
            "Epoch 202/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8694 - accuracy: 0.8264 - val_loss: 1.1944 - val_accuracy: 0.7222\n",
            "Epoch 203/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8739 - accuracy: 0.8368 - val_loss: 1.1844 - val_accuracy: 0.7292\n",
            "Epoch 204/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8718 - accuracy: 0.8403 - val_loss: 1.1884 - val_accuracy: 0.7292\n",
            "Epoch 205/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8791 - accuracy: 0.8368 - val_loss: 1.2109 - val_accuracy: 0.6806\n",
            "Epoch 206/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8696 - accuracy: 0.8299 - val_loss: 1.1933 - val_accuracy: 0.7083\n",
            "Epoch 207/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8851 - accuracy: 0.8229 - val_loss: 1.2005 - val_accuracy: 0.6806\n",
            "Epoch 208/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8695 - accuracy: 0.8438 - val_loss: 1.1902 - val_accuracy: 0.7153\n",
            "Epoch 209/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8612 - accuracy: 0.8472 - val_loss: 1.1998 - val_accuracy: 0.7083\n",
            "Epoch 210/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8716 - accuracy: 0.8507 - val_loss: 1.1965 - val_accuracy: 0.6875\n",
            "Epoch 211/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8634 - accuracy: 0.8438 - val_loss: 1.1836 - val_accuracy: 0.7292\n",
            "Epoch 212/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8831 - accuracy: 0.8229 - val_loss: 1.1881 - val_accuracy: 0.7361\n",
            "Epoch 213/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8705 - accuracy: 0.8420 - val_loss: 1.1904 - val_accuracy: 0.7014\n",
            "Epoch 214/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8532 - accuracy: 0.8333 - val_loss: 1.1995 - val_accuracy: 0.7222\n",
            "Epoch 215/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8501 - accuracy: 0.8368 - val_loss: 1.1927 - val_accuracy: 0.7292\n",
            "Epoch 216/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8632 - accuracy: 0.8420 - val_loss: 1.1852 - val_accuracy: 0.7431\n",
            "Epoch 217/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8521 - accuracy: 0.8368 - val_loss: 1.1726 - val_accuracy: 0.7431\n",
            "Epoch 218/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8628 - accuracy: 0.8542 - val_loss: 1.1881 - val_accuracy: 0.7153\n",
            "Epoch 219/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8224 - accuracy: 0.8819 - val_loss: 1.1841 - val_accuracy: 0.7431\n",
            "Epoch 220/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8372 - accuracy: 0.8490 - val_loss: 1.1906 - val_accuracy: 0.7222\n",
            "Epoch 221/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8404 - accuracy: 0.8611 - val_loss: 1.1681 - val_accuracy: 0.7361\n",
            "Epoch 222/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8452 - accuracy: 0.8507 - val_loss: 1.1751 - val_accuracy: 0.7222\n",
            "Epoch 223/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8715 - accuracy: 0.8333 - val_loss: 1.1781 - val_accuracy: 0.7292\n",
            "Epoch 224/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8428 - accuracy: 0.8490 - val_loss: 1.1669 - val_accuracy: 0.7222\n",
            "Epoch 225/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8332 - accuracy: 0.8420 - val_loss: 1.1964 - val_accuracy: 0.7153\n",
            "Epoch 226/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8502 - accuracy: 0.8524 - val_loss: 1.1881 - val_accuracy: 0.7083\n",
            "Epoch 227/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8487 - accuracy: 0.8420 - val_loss: 1.1794 - val_accuracy: 0.7361\n",
            "Epoch 228/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8241 - accuracy: 0.8559 - val_loss: 1.1839 - val_accuracy: 0.7639\n",
            "Epoch 229/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8214 - accuracy: 0.8646 - val_loss: 1.1858 - val_accuracy: 0.7292\n",
            "Epoch 230/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8419 - accuracy: 0.8524 - val_loss: 1.1863 - val_accuracy: 0.7222\n",
            "Epoch 231/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8295 - accuracy: 0.8542 - val_loss: 1.1970 - val_accuracy: 0.7014\n",
            "Epoch 232/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8498 - accuracy: 0.8351 - val_loss: 1.1884 - val_accuracy: 0.7292\n",
            "Epoch 233/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8261 - accuracy: 0.8542 - val_loss: 1.1980 - val_accuracy: 0.7014\n",
            "Epoch 234/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8149 - accuracy: 0.8646 - val_loss: 1.1818 - val_accuracy: 0.6944\n",
            "Epoch 235/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8278 - accuracy: 0.8420 - val_loss: 1.1711 - val_accuracy: 0.7361\n",
            "Epoch 236/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8431 - accuracy: 0.8559 - val_loss: 1.1729 - val_accuracy: 0.7361\n",
            "Epoch 237/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8248 - accuracy: 0.8455 - val_loss: 1.1832 - val_accuracy: 0.7292\n",
            "Epoch 238/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8299 - accuracy: 0.8524 - val_loss: 1.1610 - val_accuracy: 0.7361\n",
            "Epoch 239/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8216 - accuracy: 0.8698 - val_loss: 1.1821 - val_accuracy: 0.7083\n",
            "Epoch 240/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8228 - accuracy: 0.8472 - val_loss: 1.1725 - val_accuracy: 0.7292\n",
            "Epoch 241/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8205 - accuracy: 0.8663 - val_loss: 1.1700 - val_accuracy: 0.7361\n",
            "Epoch 242/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8105 - accuracy: 0.8715 - val_loss: 1.1680 - val_accuracy: 0.7361\n",
            "Epoch 243/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8148 - accuracy: 0.8472 - val_loss: 1.1558 - val_accuracy: 0.7431\n",
            "Epoch 244/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8349 - accuracy: 0.8681 - val_loss: 1.1728 - val_accuracy: 0.7361\n",
            "Epoch 245/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8343 - accuracy: 0.8559 - val_loss: 1.1728 - val_accuracy: 0.7361\n",
            "Epoch 246/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8161 - accuracy: 0.8628 - val_loss: 1.1666 - val_accuracy: 0.7083\n",
            "Epoch 247/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8026 - accuracy: 0.8681 - val_loss: 1.1606 - val_accuracy: 0.7222\n",
            "Epoch 248/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8162 - accuracy: 0.8733 - val_loss: 1.1525 - val_accuracy: 0.7361\n",
            "Epoch 249/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7973 - accuracy: 0.8837 - val_loss: 1.1474 - val_accuracy: 0.7222\n",
            "Epoch 250/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8209 - accuracy: 0.8559 - val_loss: 1.1725 - val_accuracy: 0.7431\n",
            "Epoch 251/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7984 - accuracy: 0.8681 - val_loss: 1.1681 - val_accuracy: 0.7222\n",
            "Epoch 252/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8035 - accuracy: 0.8681 - val_loss: 1.1576 - val_accuracy: 0.7083\n",
            "Epoch 253/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8142 - accuracy: 0.8785 - val_loss: 1.1462 - val_accuracy: 0.7569\n",
            "Epoch 254/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8055 - accuracy: 0.8750 - val_loss: 1.1507 - val_accuracy: 0.7292\n",
            "Epoch 255/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8085 - accuracy: 0.8646 - val_loss: 1.1643 - val_accuracy: 0.7153\n",
            "Epoch 256/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8150 - accuracy: 0.8785 - val_loss: 1.1485 - val_accuracy: 0.7431\n",
            "Epoch 257/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8102 - accuracy: 0.8750 - val_loss: 1.1632 - val_accuracy: 0.7431\n",
            "Epoch 258/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7959 - accuracy: 0.8785 - val_loss: 1.1614 - val_accuracy: 0.7569\n",
            "Epoch 259/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8065 - accuracy: 0.8750 - val_loss: 1.1455 - val_accuracy: 0.7500\n",
            "Epoch 260/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7895 - accuracy: 0.8750 - val_loss: 1.1508 - val_accuracy: 0.7500\n",
            "Epoch 261/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7888 - accuracy: 0.8785 - val_loss: 1.1704 - val_accuracy: 0.7292\n",
            "Epoch 262/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7964 - accuracy: 0.8715 - val_loss: 1.1672 - val_accuracy: 0.7222\n",
            "Epoch 263/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8038 - accuracy: 0.8785 - val_loss: 1.1663 - val_accuracy: 0.7292\n",
            "Epoch 264/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7805 - accuracy: 0.8785 - val_loss: 1.1562 - val_accuracy: 0.7361\n",
            "Epoch 265/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7756 - accuracy: 0.8924 - val_loss: 1.1521 - val_accuracy: 0.7222\n",
            "Epoch 266/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7887 - accuracy: 0.8767 - val_loss: 1.1513 - val_accuracy: 0.7569\n",
            "Epoch 267/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7733 - accuracy: 0.8889 - val_loss: 1.1432 - val_accuracy: 0.7569\n",
            "Epoch 268/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7776 - accuracy: 0.9028 - val_loss: 1.1395 - val_accuracy: 0.7847\n",
            "Epoch 269/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8031 - accuracy: 0.8472 - val_loss: 1.1434 - val_accuracy: 0.7708\n",
            "Epoch 270/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7957 - accuracy: 0.8767 - val_loss: 1.1388 - val_accuracy: 0.7500\n",
            "Epoch 271/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7772 - accuracy: 0.8698 - val_loss: 1.1495 - val_accuracy: 0.7361\n",
            "Epoch 272/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7805 - accuracy: 0.8837 - val_loss: 1.1473 - val_accuracy: 0.7431\n",
            "Epoch 273/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7843 - accuracy: 0.8646 - val_loss: 1.1530 - val_accuracy: 0.7431\n",
            "Epoch 274/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7715 - accuracy: 0.8941 - val_loss: 1.1465 - val_accuracy: 0.7500\n",
            "Epoch 275/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7667 - accuracy: 0.8767 - val_loss: 1.1439 - val_accuracy: 0.7431\n",
            "Epoch 276/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7659 - accuracy: 0.8889 - val_loss: 1.1287 - val_accuracy: 0.7569\n",
            "Epoch 277/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7657 - accuracy: 0.8906 - val_loss: 1.1448 - val_accuracy: 0.7014\n",
            "Epoch 278/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7615 - accuracy: 0.8941 - val_loss: 1.1403 - val_accuracy: 0.7500\n",
            "Epoch 279/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7510 - accuracy: 0.9184 - val_loss: 1.1627 - val_accuracy: 0.7361\n",
            "Epoch 280/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7787 - accuracy: 0.8976 - val_loss: 1.1537 - val_accuracy: 0.7292\n",
            "Epoch 281/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7567 - accuracy: 0.8958 - val_loss: 1.1525 - val_accuracy: 0.7431\n",
            "Epoch 282/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7887 - accuracy: 0.8611 - val_loss: 1.1611 - val_accuracy: 0.7153\n",
            "Epoch 283/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7579 - accuracy: 0.9010 - val_loss: 1.1462 - val_accuracy: 0.7222\n",
            "Epoch 284/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7657 - accuracy: 0.8976 - val_loss: 1.1604 - val_accuracy: 0.7222\n",
            "Epoch 285/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7585 - accuracy: 0.8993 - val_loss: 1.1632 - val_accuracy: 0.7292\n",
            "Epoch 286/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7606 - accuracy: 0.9045 - val_loss: 1.1545 - val_accuracy: 0.7222\n",
            "Epoch 287/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7646 - accuracy: 0.8993 - val_loss: 1.1441 - val_accuracy: 0.7153\n",
            "Epoch 288/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7557 - accuracy: 0.9115 - val_loss: 1.1383 - val_accuracy: 0.7083\n",
            "Epoch 289/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7450 - accuracy: 0.9097 - val_loss: 1.1405 - val_accuracy: 0.7361\n",
            "Epoch 290/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7581 - accuracy: 0.9097 - val_loss: 1.1471 - val_accuracy: 0.7292\n",
            "Epoch 291/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7535 - accuracy: 0.8958 - val_loss: 1.1470 - val_accuracy: 0.7222\n",
            "Epoch 292/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.7348 - accuracy: 0.9097 - val_loss: 1.1279 - val_accuracy: 0.7431\n",
            "Epoch 293/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7531 - accuracy: 0.9149 - val_loss: 1.1249 - val_accuracy: 0.7569\n",
            "Epoch 294/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7654 - accuracy: 0.8958 - val_loss: 1.1200 - val_accuracy: 0.7431\n",
            "Epoch 295/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7524 - accuracy: 0.9097 - val_loss: 1.1345 - val_accuracy: 0.7569\n",
            "Epoch 296/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7467 - accuracy: 0.9080 - val_loss: 1.1281 - val_accuracy: 0.7153\n",
            "Epoch 297/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7501 - accuracy: 0.9028 - val_loss: 1.1352 - val_accuracy: 0.7431\n",
            "Epoch 298/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7544 - accuracy: 0.8924 - val_loss: 1.1251 - val_accuracy: 0.7500\n",
            "Epoch 299/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7262 - accuracy: 0.9184 - val_loss: 1.1399 - val_accuracy: 0.7639\n",
            "Epoch 300/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7355 - accuracy: 0.9080 - val_loss: 1.1255 - val_accuracy: 0.7639\n",
            "Epoch 301/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7408 - accuracy: 0.9167 - val_loss: 1.1364 - val_accuracy: 0.7083\n",
            "Epoch 302/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7267 - accuracy: 0.9132 - val_loss: 1.1298 - val_accuracy: 0.7222\n",
            "Epoch 303/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7447 - accuracy: 0.8906 - val_loss: 1.1390 - val_accuracy: 0.7361\n",
            "Epoch 304/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7273 - accuracy: 0.9149 - val_loss: 1.1372 - val_accuracy: 0.7847\n",
            "Epoch 305/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7435 - accuracy: 0.9132 - val_loss: 1.1226 - val_accuracy: 0.7917\n",
            "Epoch 306/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7277 - accuracy: 0.9236 - val_loss: 1.1330 - val_accuracy: 0.7639\n",
            "Epoch 307/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7660 - accuracy: 0.8958 - val_loss: 1.1351 - val_accuracy: 0.7431\n",
            "Epoch 308/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7490 - accuracy: 0.9010 - val_loss: 1.1348 - val_accuracy: 0.7569\n",
            "Epoch 309/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7263 - accuracy: 0.9132 - val_loss: 1.1374 - val_accuracy: 0.7639\n",
            "Epoch 310/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7235 - accuracy: 0.9115 - val_loss: 1.1284 - val_accuracy: 0.7569\n",
            "Epoch 311/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7257 - accuracy: 0.9097 - val_loss: 1.1264 - val_accuracy: 0.7500\n",
            "Epoch 312/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7374 - accuracy: 0.8958 - val_loss: 1.1344 - val_accuracy: 0.7014\n",
            "Epoch 313/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7294 - accuracy: 0.9045 - val_loss: 1.1295 - val_accuracy: 0.7431\n",
            "Epoch 314/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7160 - accuracy: 0.9132 - val_loss: 1.1330 - val_accuracy: 0.7083\n",
            "Epoch 315/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7531 - accuracy: 0.8889 - val_loss: 1.1338 - val_accuracy: 0.7431\n",
            "Epoch 316/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7269 - accuracy: 0.9132 - val_loss: 1.1519 - val_accuracy: 0.7153\n",
            "Epoch 317/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7224 - accuracy: 0.9201 - val_loss: 1.1446 - val_accuracy: 0.7431\n",
            "Epoch 318/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7137 - accuracy: 0.9201 - val_loss: 1.1226 - val_accuracy: 0.7222\n",
            "Epoch 319/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7218 - accuracy: 0.9080 - val_loss: 1.1345 - val_accuracy: 0.7639\n",
            "Epoch 320/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7303 - accuracy: 0.9149 - val_loss: 1.1214 - val_accuracy: 0.7361\n",
            "Epoch 321/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7223 - accuracy: 0.9028 - val_loss: 1.1273 - val_accuracy: 0.7153\n",
            "Epoch 322/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7199 - accuracy: 0.9062 - val_loss: 1.1305 - val_accuracy: 0.7500\n",
            "Epoch 323/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7117 - accuracy: 0.9062 - val_loss: 1.1290 - val_accuracy: 0.7431\n",
            "Epoch 324/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7101 - accuracy: 0.9097 - val_loss: 1.1297 - val_accuracy: 0.7361\n",
            "Epoch 325/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7111 - accuracy: 0.9253 - val_loss: 1.1319 - val_accuracy: 0.7153\n",
            "Epoch 326/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7062 - accuracy: 0.9115 - val_loss: 1.1383 - val_accuracy: 0.7361\n",
            "Epoch 327/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7159 - accuracy: 0.9271 - val_loss: 1.1222 - val_accuracy: 0.7639\n",
            "Epoch 328/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6889 - accuracy: 0.9375 - val_loss: 1.1504 - val_accuracy: 0.7222\n",
            "Epoch 329/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7043 - accuracy: 0.9132 - val_loss: 1.1170 - val_accuracy: 0.7639\n",
            "Epoch 330/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7206 - accuracy: 0.9201 - val_loss: 1.1294 - val_accuracy: 0.7639\n",
            "Epoch 331/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7262 - accuracy: 0.9219 - val_loss: 1.1259 - val_accuracy: 0.7500\n",
            "Epoch 332/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7065 - accuracy: 0.9323 - val_loss: 1.1169 - val_accuracy: 0.7431\n",
            "Epoch 333/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7178 - accuracy: 0.9132 - val_loss: 1.1101 - val_accuracy: 0.7569\n",
            "Epoch 334/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7122 - accuracy: 0.9097 - val_loss: 1.1067 - val_accuracy: 0.7639\n",
            "Epoch 335/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7372 - accuracy: 0.9062 - val_loss: 1.1244 - val_accuracy: 0.7500\n",
            "Epoch 336/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7201 - accuracy: 0.9201 - val_loss: 1.1113 - val_accuracy: 0.7500\n",
            "Epoch 337/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7232 - accuracy: 0.9167 - val_loss: 1.1324 - val_accuracy: 0.7361\n",
            "Epoch 338/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6891 - accuracy: 0.9271 - val_loss: 1.1221 - val_accuracy: 0.7222\n",
            "Epoch 339/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7120 - accuracy: 0.9167 - val_loss: 1.1212 - val_accuracy: 0.7292\n",
            "Epoch 340/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7001 - accuracy: 0.9462 - val_loss: 1.1100 - val_accuracy: 0.7639\n",
            "Epoch 341/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6984 - accuracy: 0.9253 - val_loss: 1.1066 - val_accuracy: 0.7569\n",
            "Epoch 342/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7144 - accuracy: 0.8993 - val_loss: 1.1103 - val_accuracy: 0.7639\n",
            "Epoch 343/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6991 - accuracy: 0.9149 - val_loss: 1.1295 - val_accuracy: 0.7569\n",
            "Epoch 344/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7166 - accuracy: 0.9201 - val_loss: 1.1366 - val_accuracy: 0.7500\n",
            "Epoch 345/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6795 - accuracy: 0.9358 - val_loss: 1.1256 - val_accuracy: 0.7708\n",
            "Epoch 346/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6831 - accuracy: 0.9288 - val_loss: 1.1244 - val_accuracy: 0.7500\n",
            "Epoch 347/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6856 - accuracy: 0.9306 - val_loss: 1.1230 - val_accuracy: 0.7222\n",
            "Epoch 348/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6783 - accuracy: 0.9410 - val_loss: 1.1219 - val_accuracy: 0.7569\n",
            "Epoch 349/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7152 - accuracy: 0.9288 - val_loss: 1.1166 - val_accuracy: 0.7431\n",
            "Epoch 350/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6885 - accuracy: 0.9358 - val_loss: 1.1228 - val_accuracy: 0.7431\n",
            "Epoch 351/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6872 - accuracy: 0.9340 - val_loss: 1.1353 - val_accuracy: 0.7361\n",
            "Epoch 352/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6689 - accuracy: 0.9323 - val_loss: 1.1239 - val_accuracy: 0.7361\n",
            "Epoch 353/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6686 - accuracy: 0.9375 - val_loss: 1.1262 - val_accuracy: 0.7292\n",
            "Epoch 354/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6824 - accuracy: 0.9323 - val_loss: 1.1127 - val_accuracy: 0.7292\n",
            "Epoch 355/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6823 - accuracy: 0.9358 - val_loss: 1.1310 - val_accuracy: 0.7431\n",
            "Epoch 356/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6861 - accuracy: 0.9514 - val_loss: 1.1440 - val_accuracy: 0.7222\n",
            "Epoch 357/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6898 - accuracy: 0.9236 - val_loss: 1.1327 - val_accuracy: 0.7431\n",
            "Epoch 358/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6764 - accuracy: 0.9340 - val_loss: 1.1172 - val_accuracy: 0.7500\n",
            "Epoch 359/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6787 - accuracy: 0.9253 - val_loss: 1.1175 - val_accuracy: 0.7500\n",
            "Epoch 360/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6794 - accuracy: 0.9323 - val_loss: 1.0970 - val_accuracy: 0.7569\n",
            "Epoch 361/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6734 - accuracy: 0.9427 - val_loss: 1.1032 - val_accuracy: 0.7431\n",
            "Epoch 362/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6719 - accuracy: 0.9323 - val_loss: 1.1130 - val_accuracy: 0.7292\n",
            "Epoch 363/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6823 - accuracy: 0.9271 - val_loss: 1.1106 - val_accuracy: 0.7431\n",
            "Epoch 364/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6785 - accuracy: 0.9340 - val_loss: 1.1117 - val_accuracy: 0.7431\n",
            "Epoch 365/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6799 - accuracy: 0.9340 - val_loss: 1.1232 - val_accuracy: 0.7431\n",
            "Epoch 366/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6739 - accuracy: 0.9444 - val_loss: 1.1300 - val_accuracy: 0.7292\n",
            "Epoch 367/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6860 - accuracy: 0.9358 - val_loss: 1.1257 - val_accuracy: 0.7361\n",
            "Epoch 368/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6891 - accuracy: 0.9132 - val_loss: 1.1334 - val_accuracy: 0.7361\n",
            "Epoch 369/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6732 - accuracy: 0.9392 - val_loss: 1.1274 - val_accuracy: 0.7431\n",
            "Epoch 370/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6557 - accuracy: 0.9549 - val_loss: 1.1076 - val_accuracy: 0.7222\n",
            "Epoch 371/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6756 - accuracy: 0.9340 - val_loss: 1.1088 - val_accuracy: 0.7639\n",
            "Epoch 372/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6634 - accuracy: 0.9253 - val_loss: 1.1015 - val_accuracy: 0.7500\n",
            "Epoch 373/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6603 - accuracy: 0.9444 - val_loss: 1.1235 - val_accuracy: 0.7569\n",
            "Epoch 374/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6902 - accuracy: 0.9184 - val_loss: 1.1140 - val_accuracy: 0.7222\n",
            "Epoch 375/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6660 - accuracy: 0.9462 - val_loss: 1.1226 - val_accuracy: 0.7292\n",
            "Epoch 376/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6481 - accuracy: 0.9410 - val_loss: 1.1099 - val_accuracy: 0.7292\n",
            "Epoch 377/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6717 - accuracy: 0.9427 - val_loss: 1.1193 - val_accuracy: 0.7361\n",
            "Epoch 378/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6544 - accuracy: 0.9462 - val_loss: 1.1125 - val_accuracy: 0.7708\n",
            "Epoch 379/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6526 - accuracy: 0.9514 - val_loss: 1.1153 - val_accuracy: 0.7361\n",
            "Epoch 380/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6819 - accuracy: 0.9306 - val_loss: 1.1203 - val_accuracy: 0.7500\n",
            "Epoch 381/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6738 - accuracy: 0.9253 - val_loss: 1.1131 - val_accuracy: 0.7153\n",
            "Epoch 382/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6882 - accuracy: 0.9410 - val_loss: 1.1217 - val_accuracy: 0.7431\n",
            "Epoch 383/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6535 - accuracy: 0.9497 - val_loss: 1.1142 - val_accuracy: 0.7500\n",
            "Epoch 384/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6578 - accuracy: 0.9444 - val_loss: 1.1217 - val_accuracy: 0.7361\n",
            "Epoch 385/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6514 - accuracy: 0.9497 - val_loss: 1.1242 - val_accuracy: 0.7361\n",
            "Epoch 386/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6666 - accuracy: 0.9392 - val_loss: 1.1167 - val_accuracy: 0.7431\n",
            "Epoch 387/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6584 - accuracy: 0.9340 - val_loss: 1.1086 - val_accuracy: 0.7361\n",
            "Epoch 388/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6402 - accuracy: 0.9601 - val_loss: 1.0997 - val_accuracy: 0.7569\n",
            "Epoch 389/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6667 - accuracy: 0.9375 - val_loss: 1.1069 - val_accuracy: 0.7222\n",
            "Epoch 390/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6602 - accuracy: 0.9358 - val_loss: 1.0933 - val_accuracy: 0.7292\n",
            "Epoch 391/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6490 - accuracy: 0.9583 - val_loss: 1.1028 - val_accuracy: 0.7431\n",
            "Epoch 392/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6493 - accuracy: 0.9358 - val_loss: 1.1132 - val_accuracy: 0.7431\n",
            "Epoch 393/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.6404 - accuracy: 0.9479 - val_loss: 1.1032 - val_accuracy: 0.7292\n",
            "Epoch 394/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6573 - accuracy: 0.9444 - val_loss: 1.1004 - val_accuracy: 0.7292\n",
            "Epoch 395/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6596 - accuracy: 0.9323 - val_loss: 1.0975 - val_accuracy: 0.7292\n",
            "Epoch 396/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6520 - accuracy: 0.9462 - val_loss: 1.1028 - val_accuracy: 0.7222\n",
            "Epoch 397/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6384 - accuracy: 0.9514 - val_loss: 1.1098 - val_accuracy: 0.7431\n",
            "Epoch 398/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6577 - accuracy: 0.9427 - val_loss: 1.0984 - val_accuracy: 0.7431\n",
            "Epoch 399/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6449 - accuracy: 0.9531 - val_loss: 1.1033 - val_accuracy: 0.7569\n",
            "Epoch 400/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6445 - accuracy: 0.9497 - val_loss: 1.1120 - val_accuracy: 0.7639\n",
            "Epoch 401/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6324 - accuracy: 0.9601 - val_loss: 1.0929 - val_accuracy: 0.7431\n",
            "Epoch 402/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6332 - accuracy: 0.9549 - val_loss: 1.1056 - val_accuracy: 0.7153\n",
            "Epoch 403/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6278 - accuracy: 0.9601 - val_loss: 1.1041 - val_accuracy: 0.7639\n",
            "Epoch 404/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6296 - accuracy: 0.9618 - val_loss: 1.1028 - val_accuracy: 0.7708\n",
            "Epoch 405/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6363 - accuracy: 0.9514 - val_loss: 1.0956 - val_accuracy: 0.7708\n",
            "Epoch 406/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6574 - accuracy: 0.9497 - val_loss: 1.0926 - val_accuracy: 0.7569\n",
            "Epoch 407/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6412 - accuracy: 0.9601 - val_loss: 1.0814 - val_accuracy: 0.7500\n",
            "Epoch 408/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6282 - accuracy: 0.9618 - val_loss: 1.0933 - val_accuracy: 0.7361\n",
            "Epoch 409/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6451 - accuracy: 0.9479 - val_loss: 1.0981 - val_accuracy: 0.7569\n",
            "Epoch 410/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6482 - accuracy: 0.9392 - val_loss: 1.0902 - val_accuracy: 0.7500\n",
            "Epoch 411/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6227 - accuracy: 0.9653 - val_loss: 1.0890 - val_accuracy: 0.7569\n",
            "Epoch 412/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6413 - accuracy: 0.9479 - val_loss: 1.0893 - val_accuracy: 0.7292\n",
            "Epoch 413/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6156 - accuracy: 0.9566 - val_loss: 1.1010 - val_accuracy: 0.7569\n",
            "Epoch 414/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6240 - accuracy: 0.9514 - val_loss: 1.0845 - val_accuracy: 0.7569\n",
            "Epoch 415/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6335 - accuracy: 0.9462 - val_loss: 1.0922 - val_accuracy: 0.7847\n",
            "Epoch 416/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6321 - accuracy: 0.9618 - val_loss: 1.1143 - val_accuracy: 0.7569\n",
            "Epoch 417/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6334 - accuracy: 0.9688 - val_loss: 1.1000 - val_accuracy: 0.7778\n",
            "Epoch 418/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6121 - accuracy: 0.9601 - val_loss: 1.0969 - val_accuracy: 0.7500\n",
            "Epoch 419/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6361 - accuracy: 0.9531 - val_loss: 1.0948 - val_accuracy: 0.7569\n",
            "Epoch 420/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6156 - accuracy: 0.9705 - val_loss: 1.1071 - val_accuracy: 0.7500\n",
            "Epoch 421/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6273 - accuracy: 0.9549 - val_loss: 1.1112 - val_accuracy: 0.7500\n",
            "Epoch 422/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6369 - accuracy: 0.9462 - val_loss: 1.0993 - val_accuracy: 0.7708\n",
            "Epoch 423/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6317 - accuracy: 0.9566 - val_loss: 1.0861 - val_accuracy: 0.7847\n",
            "Epoch 424/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6311 - accuracy: 0.9670 - val_loss: 1.0951 - val_accuracy: 0.7431\n",
            "Epoch 425/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6352 - accuracy: 0.9479 - val_loss: 1.1023 - val_accuracy: 0.7431\n",
            "Epoch 426/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6180 - accuracy: 0.9601 - val_loss: 1.0953 - val_accuracy: 0.7500\n",
            "Epoch 427/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6239 - accuracy: 0.9601 - val_loss: 1.0908 - val_accuracy: 0.7222\n",
            "Epoch 428/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6144 - accuracy: 0.9670 - val_loss: 1.1063 - val_accuracy: 0.7639\n",
            "Epoch 429/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6300 - accuracy: 0.9549 - val_loss: 1.0943 - val_accuracy: 0.7778\n",
            "Epoch 430/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6368 - accuracy: 0.9531 - val_loss: 1.0887 - val_accuracy: 0.7639\n",
            "Epoch 431/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6245 - accuracy: 0.9601 - val_loss: 1.0890 - val_accuracy: 0.7569\n",
            "Epoch 432/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6199 - accuracy: 0.9462 - val_loss: 1.1036 - val_accuracy: 0.7500\n",
            "Epoch 433/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6306 - accuracy: 0.9549 - val_loss: 1.1089 - val_accuracy: 0.7500\n",
            "Epoch 434/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6194 - accuracy: 0.9566 - val_loss: 1.1024 - val_accuracy: 0.7361\n",
            "Epoch 435/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6207 - accuracy: 0.9670 - val_loss: 1.0966 - val_accuracy: 0.7639\n",
            "Epoch 436/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6324 - accuracy: 0.9653 - val_loss: 1.1016 - val_accuracy: 0.7569\n",
            "Epoch 437/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6204 - accuracy: 0.9583 - val_loss: 1.0973 - val_accuracy: 0.7431\n",
            "Epoch 438/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6299 - accuracy: 0.9497 - val_loss: 1.0905 - val_accuracy: 0.7639\n",
            "Epoch 439/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6033 - accuracy: 0.9618 - val_loss: 1.0983 - val_accuracy: 0.7639\n",
            "Epoch 440/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6154 - accuracy: 0.9514 - val_loss: 1.1081 - val_accuracy: 0.7569\n",
            "Epoch 441/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6075 - accuracy: 0.9705 - val_loss: 1.1000 - val_accuracy: 0.7431\n",
            "Epoch 442/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6110 - accuracy: 0.9635 - val_loss: 1.0967 - val_accuracy: 0.7639\n",
            "Epoch 443/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6082 - accuracy: 0.9514 - val_loss: 1.1020 - val_accuracy: 0.7569\n",
            "Epoch 444/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6253 - accuracy: 0.9497 - val_loss: 1.0873 - val_accuracy: 0.7847\n",
            "Epoch 445/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6048 - accuracy: 0.9618 - val_loss: 1.0866 - val_accuracy: 0.7708\n",
            "Epoch 446/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6062 - accuracy: 0.9740 - val_loss: 1.0949 - val_accuracy: 0.7708\n",
            "Epoch 447/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6056 - accuracy: 0.9653 - val_loss: 1.0724 - val_accuracy: 0.7708\n",
            "Epoch 448/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6097 - accuracy: 0.9722 - val_loss: 1.0959 - val_accuracy: 0.7431\n",
            "Epoch 449/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5979 - accuracy: 0.9688 - val_loss: 1.0963 - val_accuracy: 0.7431\n",
            "Epoch 450/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6054 - accuracy: 0.9601 - val_loss: 1.0930 - val_accuracy: 0.7639\n",
            "Epoch 451/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6276 - accuracy: 0.9514 - val_loss: 1.0967 - val_accuracy: 0.7500\n",
            "Epoch 452/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6054 - accuracy: 0.9740 - val_loss: 1.1076 - val_accuracy: 0.7569\n",
            "Epoch 453/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6077 - accuracy: 0.9705 - val_loss: 1.0817 - val_accuracy: 0.7708\n",
            "Epoch 454/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5910 - accuracy: 0.9670 - val_loss: 1.0925 - val_accuracy: 0.7847\n",
            "Epoch 455/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5987 - accuracy: 0.9618 - val_loss: 1.0912 - val_accuracy: 0.7569\n",
            "Epoch 456/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6016 - accuracy: 0.9618 - val_loss: 1.0912 - val_accuracy: 0.7639\n",
            "Epoch 457/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6206 - accuracy: 0.9583 - val_loss: 1.0916 - val_accuracy: 0.7431\n",
            "Epoch 458/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5934 - accuracy: 0.9635 - val_loss: 1.0895 - val_accuracy: 0.7639\n",
            "Epoch 459/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6062 - accuracy: 0.9618 - val_loss: 1.0686 - val_accuracy: 0.7569\n",
            "Epoch 460/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6025 - accuracy: 0.9653 - val_loss: 1.0816 - val_accuracy: 0.7361\n",
            "Epoch 461/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5980 - accuracy: 0.9653 - val_loss: 1.0745 - val_accuracy: 0.7708\n",
            "Epoch 462/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6125 - accuracy: 0.9653 - val_loss: 1.0819 - val_accuracy: 0.7500\n",
            "Epoch 463/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5997 - accuracy: 0.9670 - val_loss: 1.0864 - val_accuracy: 0.7778\n",
            "Epoch 464/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5906 - accuracy: 0.9757 - val_loss: 1.0926 - val_accuracy: 0.7708\n",
            "Epoch 465/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5934 - accuracy: 0.9757 - val_loss: 1.0858 - val_accuracy: 0.7361\n",
            "Epoch 466/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5982 - accuracy: 0.9618 - val_loss: 1.1040 - val_accuracy: 0.7569\n",
            "Epoch 467/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5932 - accuracy: 0.9601 - val_loss: 1.0990 - val_accuracy: 0.7569\n",
            "Epoch 468/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6032 - accuracy: 0.9635 - val_loss: 1.1034 - val_accuracy: 0.7500\n",
            "Epoch 469/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5889 - accuracy: 0.9635 - val_loss: 1.0869 - val_accuracy: 0.7639\n",
            "Epoch 470/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5908 - accuracy: 0.9688 - val_loss: 1.1011 - val_accuracy: 0.7569\n",
            "Epoch 471/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5707 - accuracy: 0.9722 - val_loss: 1.0913 - val_accuracy: 0.7500\n",
            "Epoch 472/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5775 - accuracy: 0.9809 - val_loss: 1.0770 - val_accuracy: 0.7431\n",
            "Epoch 473/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5960 - accuracy: 0.9670 - val_loss: 1.0963 - val_accuracy: 0.7569\n",
            "Epoch 474/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5946 - accuracy: 0.9722 - val_loss: 1.0771 - val_accuracy: 0.7569\n",
            "Epoch 475/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5810 - accuracy: 0.9740 - val_loss: 1.0905 - val_accuracy: 0.7500\n",
            "Epoch 476/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6022 - accuracy: 0.9722 - val_loss: 1.0849 - val_accuracy: 0.7708\n",
            "Epoch 477/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5818 - accuracy: 0.9774 - val_loss: 1.0791 - val_accuracy: 0.7431\n",
            "Epoch 478/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5754 - accuracy: 0.9774 - val_loss: 1.0850 - val_accuracy: 0.7569\n",
            "Epoch 479/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6008 - accuracy: 0.9618 - val_loss: 1.0816 - val_accuracy: 0.7847\n",
            "Epoch 480/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5936 - accuracy: 0.9670 - val_loss: 1.0767 - val_accuracy: 0.7569\n",
            "Epoch 481/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5879 - accuracy: 0.9635 - val_loss: 1.0826 - val_accuracy: 0.7361\n",
            "Epoch 482/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5872 - accuracy: 0.9688 - val_loss: 1.0785 - val_accuracy: 0.7569\n",
            "Epoch 483/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5915 - accuracy: 0.9705 - val_loss: 1.0959 - val_accuracy: 0.7500\n",
            "Epoch 484/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5956 - accuracy: 0.9722 - val_loss: 1.0959 - val_accuracy: 0.7431\n",
            "Epoch 485/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5779 - accuracy: 0.9740 - val_loss: 1.0995 - val_accuracy: 0.7639\n",
            "Epoch 486/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5914 - accuracy: 0.9688 - val_loss: 1.1015 - val_accuracy: 0.7569\n",
            "Epoch 487/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6097 - accuracy: 0.9497 - val_loss: 1.1025 - val_accuracy: 0.7778\n",
            "Epoch 488/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5837 - accuracy: 0.9774 - val_loss: 1.0812 - val_accuracy: 0.7569\n",
            "Epoch 489/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5783 - accuracy: 0.9740 - val_loss: 1.0896 - val_accuracy: 0.7500\n",
            "Epoch 490/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5786 - accuracy: 0.9809 - val_loss: 1.0695 - val_accuracy: 0.7917\n",
            "Epoch 491/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5772 - accuracy: 0.9653 - val_loss: 1.0667 - val_accuracy: 0.7917\n",
            "Epoch 492/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5696 - accuracy: 0.9861 - val_loss: 1.0929 - val_accuracy: 0.7708\n",
            "Epoch 493/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5887 - accuracy: 0.9531 - val_loss: 1.0823 - val_accuracy: 0.7708\n",
            "Epoch 494/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5968 - accuracy: 0.9688 - val_loss: 1.0937 - val_accuracy: 0.7569\n",
            "Epoch 495/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6046 - accuracy: 0.9740 - val_loss: 1.0898 - val_accuracy: 0.7778\n",
            "Epoch 496/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6045 - accuracy: 0.9531 - val_loss: 1.0823 - val_accuracy: 0.7708\n",
            "Epoch 497/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5930 - accuracy: 0.9618 - val_loss: 1.0861 - val_accuracy: 0.7778\n",
            "Epoch 498/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5700 - accuracy: 0.9740 - val_loss: 1.0807 - val_accuracy: 0.7639\n",
            "Epoch 499/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5750 - accuracy: 0.9722 - val_loss: 1.0811 - val_accuracy: 0.7778\n",
            "Epoch 500/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5608 - accuracy: 0.9774 - val_loss: 1.0910 - val_accuracy: 0.7708\n",
            "Epoch 501/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5692 - accuracy: 0.9722 - val_loss: 1.0828 - val_accuracy: 0.7639\n",
            "Epoch 502/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5744 - accuracy: 0.9740 - val_loss: 1.0829 - val_accuracy: 0.7639\n",
            "Epoch 503/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5765 - accuracy: 0.9670 - val_loss: 1.0777 - val_accuracy: 0.7847\n",
            "Epoch 504/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5849 - accuracy: 0.9635 - val_loss: 1.0796 - val_accuracy: 0.7569\n",
            "Epoch 505/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5775 - accuracy: 0.9757 - val_loss: 1.0941 - val_accuracy: 0.7569\n",
            "Epoch 506/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5549 - accuracy: 0.9809 - val_loss: 1.0680 - val_accuracy: 0.7847\n",
            "Epoch 507/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5668 - accuracy: 0.9757 - val_loss: 1.0717 - val_accuracy: 0.7778\n",
            "Epoch 508/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5651 - accuracy: 0.9792 - val_loss: 1.0790 - val_accuracy: 0.7639\n",
            "Epoch 509/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5583 - accuracy: 0.9774 - val_loss: 1.0662 - val_accuracy: 0.7708\n",
            "Epoch 510/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5745 - accuracy: 0.9757 - val_loss: 1.0791 - val_accuracy: 0.7569\n",
            "Epoch 511/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5557 - accuracy: 0.9809 - val_loss: 1.0819 - val_accuracy: 0.7500\n",
            "Epoch 512/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5652 - accuracy: 0.9688 - val_loss: 1.0771 - val_accuracy: 0.7431\n",
            "Epoch 513/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5820 - accuracy: 0.9792 - val_loss: 1.0691 - val_accuracy: 0.7847\n",
            "Epoch 514/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5686 - accuracy: 0.9688 - val_loss: 1.0731 - val_accuracy: 0.7569\n",
            "Epoch 515/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5623 - accuracy: 0.9826 - val_loss: 1.0911 - val_accuracy: 0.7639\n",
            "Epoch 516/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5733 - accuracy: 0.9705 - val_loss: 1.0731 - val_accuracy: 0.7708\n",
            "Epoch 517/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5524 - accuracy: 0.9809 - val_loss: 1.0755 - val_accuracy: 0.7639\n",
            "Epoch 518/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5586 - accuracy: 0.9826 - val_loss: 1.0721 - val_accuracy: 0.7500\n",
            "Epoch 519/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5616 - accuracy: 0.9774 - val_loss: 1.0787 - val_accuracy: 0.7708\n",
            "Epoch 520/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5579 - accuracy: 0.9774 - val_loss: 1.0725 - val_accuracy: 0.7639\n",
            "Epoch 521/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5886 - accuracy: 0.9653 - val_loss: 1.0795 - val_accuracy: 0.7847\n",
            "Epoch 522/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5666 - accuracy: 0.9757 - val_loss: 1.0779 - val_accuracy: 0.7778\n",
            "Epoch 523/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5620 - accuracy: 0.9740 - val_loss: 1.0896 - val_accuracy: 0.7500\n",
            "Epoch 524/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5609 - accuracy: 0.9635 - val_loss: 1.0868 - val_accuracy: 0.7639\n",
            "Epoch 525/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5639 - accuracy: 0.9688 - val_loss: 1.0852 - val_accuracy: 0.7708\n",
            "Epoch 526/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5544 - accuracy: 0.9740 - val_loss: 1.0794 - val_accuracy: 0.7708\n",
            "Epoch 527/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5806 - accuracy: 0.9774 - val_loss: 1.0793 - val_accuracy: 0.7569\n",
            "Epoch 528/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5500 - accuracy: 0.9792 - val_loss: 1.0935 - val_accuracy: 0.7708\n",
            "Epoch 529/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5478 - accuracy: 0.9826 - val_loss: 1.0869 - val_accuracy: 0.7778\n",
            "Epoch 530/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5748 - accuracy: 0.9740 - val_loss: 1.0732 - val_accuracy: 0.7639\n",
            "Epoch 531/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5480 - accuracy: 0.9826 - val_loss: 1.0796 - val_accuracy: 0.7639\n",
            "Epoch 532/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5544 - accuracy: 0.9757 - val_loss: 1.0825 - val_accuracy: 0.7500\n",
            "Epoch 533/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5737 - accuracy: 0.9774 - val_loss: 1.0673 - val_accuracy: 0.7986\n",
            "Epoch 534/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5620 - accuracy: 0.9757 - val_loss: 1.0798 - val_accuracy: 0.7708\n",
            "Epoch 535/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5600 - accuracy: 0.9809 - val_loss: 1.0616 - val_accuracy: 0.7708\n",
            "Epoch 536/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5553 - accuracy: 0.9722 - val_loss: 1.0638 - val_accuracy: 0.7639\n",
            "Epoch 537/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5440 - accuracy: 0.9774 - val_loss: 1.0775 - val_accuracy: 0.7500\n",
            "Epoch 538/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5471 - accuracy: 0.9896 - val_loss: 1.0691 - val_accuracy: 0.7778\n",
            "Epoch 539/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5600 - accuracy: 0.9792 - val_loss: 1.0743 - val_accuracy: 0.7917\n",
            "Epoch 540/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5567 - accuracy: 0.9774 - val_loss: 1.0581 - val_accuracy: 0.7569\n",
            "Epoch 541/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5541 - accuracy: 0.9774 - val_loss: 1.0755 - val_accuracy: 0.7639\n",
            "Epoch 542/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5465 - accuracy: 0.9740 - val_loss: 1.0779 - val_accuracy: 0.7778\n",
            "Epoch 543/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5533 - accuracy: 0.9826 - val_loss: 1.0700 - val_accuracy: 0.7778\n",
            "Epoch 544/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5602 - accuracy: 0.9844 - val_loss: 1.0750 - val_accuracy: 0.7569\n",
            "Epoch 545/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5506 - accuracy: 0.9774 - val_loss: 1.0682 - val_accuracy: 0.7639\n",
            "Epoch 546/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5468 - accuracy: 0.9740 - val_loss: 1.0733 - val_accuracy: 0.7639\n",
            "Epoch 547/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5442 - accuracy: 0.9826 - val_loss: 1.0755 - val_accuracy: 0.7708\n",
            "Epoch 548/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5430 - accuracy: 0.9878 - val_loss: 1.0686 - val_accuracy: 0.7847\n",
            "Epoch 549/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5554 - accuracy: 0.9826 - val_loss: 1.0735 - val_accuracy: 0.7778\n",
            "Epoch 550/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5473 - accuracy: 0.9826 - val_loss: 1.0670 - val_accuracy: 0.7500\n",
            "Epoch 551/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5419 - accuracy: 0.9792 - val_loss: 1.0774 - val_accuracy: 0.7778\n",
            "Epoch 552/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5516 - accuracy: 0.9826 - val_loss: 1.0780 - val_accuracy: 0.7569\n",
            "Epoch 553/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5729 - accuracy: 0.9670 - val_loss: 1.0557 - val_accuracy: 0.7847\n",
            "Epoch 554/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5500 - accuracy: 0.9722 - val_loss: 1.0705 - val_accuracy: 0.7639\n",
            "Epoch 555/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5273 - accuracy: 0.9913 - val_loss: 1.0829 - val_accuracy: 0.7569\n",
            "Epoch 556/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5345 - accuracy: 0.9896 - val_loss: 1.0895 - val_accuracy: 0.7569\n",
            "Epoch 557/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5371 - accuracy: 0.9878 - val_loss: 1.0782 - val_accuracy: 0.7639\n",
            "Epoch 558/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5483 - accuracy: 0.9774 - val_loss: 1.0819 - val_accuracy: 0.7569\n",
            "Epoch 559/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5666 - accuracy: 0.9774 - val_loss: 1.0816 - val_accuracy: 0.7708\n",
            "Epoch 560/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5370 - accuracy: 0.9774 - val_loss: 1.0797 - val_accuracy: 0.7639\n",
            "Epoch 561/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5341 - accuracy: 0.9948 - val_loss: 1.0683 - val_accuracy: 0.7708\n",
            "Epoch 562/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5450 - accuracy: 0.9670 - val_loss: 1.0581 - val_accuracy: 0.7778\n",
            "Epoch 563/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5364 - accuracy: 0.9809 - val_loss: 1.0545 - val_accuracy: 0.7708\n",
            "Epoch 564/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5435 - accuracy: 0.9844 - val_loss: 1.0752 - val_accuracy: 0.7778\n",
            "Epoch 565/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5300 - accuracy: 0.9774 - val_loss: 1.0619 - val_accuracy: 0.7708\n",
            "Epoch 566/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5249 - accuracy: 0.9931 - val_loss: 1.0585 - val_accuracy: 0.7778\n",
            "Epoch 567/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5352 - accuracy: 0.9757 - val_loss: 1.0773 - val_accuracy: 0.7500\n",
            "Epoch 568/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5435 - accuracy: 0.9861 - val_loss: 1.0644 - val_accuracy: 0.7708\n",
            "Epoch 569/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5313 - accuracy: 0.9826 - val_loss: 1.0626 - val_accuracy: 0.7569\n",
            "Epoch 570/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5240 - accuracy: 0.9931 - val_loss: 1.0542 - val_accuracy: 0.7778\n",
            "Epoch 571/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5330 - accuracy: 0.9861 - val_loss: 1.0588 - val_accuracy: 0.7569\n",
            "Epoch 572/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5457 - accuracy: 0.9809 - val_loss: 1.0520 - val_accuracy: 0.7778\n",
            "Epoch 573/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5358 - accuracy: 0.9826 - val_loss: 1.0612 - val_accuracy: 0.7639\n",
            "Epoch 574/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5280 - accuracy: 0.9878 - val_loss: 1.0564 - val_accuracy: 0.7708\n",
            "Epoch 575/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5267 - accuracy: 0.9792 - val_loss: 1.0554 - val_accuracy: 0.7500\n",
            "Epoch 576/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5403 - accuracy: 0.9740 - val_loss: 1.0500 - val_accuracy: 0.7500\n",
            "Epoch 577/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5398 - accuracy: 0.9809 - val_loss: 1.0544 - val_accuracy: 0.7569\n",
            "Epoch 578/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5517 - accuracy: 0.9792 - val_loss: 1.0510 - val_accuracy: 0.7500\n",
            "Epoch 579/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5272 - accuracy: 0.9809 - val_loss: 1.0798 - val_accuracy: 0.7569\n",
            "Epoch 580/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5429 - accuracy: 0.9705 - val_loss: 1.0600 - val_accuracy: 0.7569\n",
            "Epoch 581/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5317 - accuracy: 0.9896 - val_loss: 1.0660 - val_accuracy: 0.7639\n",
            "Epoch 582/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5217 - accuracy: 0.9826 - val_loss: 1.0488 - val_accuracy: 0.7639\n",
            "Epoch 583/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5239 - accuracy: 0.9844 - val_loss: 1.0593 - val_accuracy: 0.7639\n",
            "Epoch 584/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5074 - accuracy: 0.9913 - val_loss: 1.0682 - val_accuracy: 0.7778\n",
            "Epoch 585/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5343 - accuracy: 0.9861 - val_loss: 1.0728 - val_accuracy: 0.7431\n",
            "Epoch 586/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5459 - accuracy: 0.9792 - val_loss: 1.0642 - val_accuracy: 0.7500\n",
            "Epoch 587/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5423 - accuracy: 0.9757 - val_loss: 1.0629 - val_accuracy: 0.7500\n",
            "Epoch 588/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5188 - accuracy: 0.9896 - val_loss: 1.0735 - val_accuracy: 0.7500\n",
            "Epoch 589/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5295 - accuracy: 0.9896 - val_loss: 1.0712 - val_accuracy: 0.7639\n",
            "Epoch 590/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5407 - accuracy: 0.9722 - val_loss: 1.0707 - val_accuracy: 0.7639\n",
            "Epoch 591/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5200 - accuracy: 0.9878 - val_loss: 1.0580 - val_accuracy: 0.7778\n",
            "Epoch 592/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5268 - accuracy: 0.9844 - val_loss: 1.0622 - val_accuracy: 0.7708\n",
            "Epoch 593/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5203 - accuracy: 0.9878 - val_loss: 1.0809 - val_accuracy: 0.7292\n",
            "Epoch 594/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5197 - accuracy: 0.9844 - val_loss: 1.0706 - val_accuracy: 0.7708\n",
            "Epoch 595/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5080 - accuracy: 0.9931 - val_loss: 1.0605 - val_accuracy: 0.7569\n",
            "Epoch 596/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5341 - accuracy: 0.9809 - val_loss: 1.0694 - val_accuracy: 0.7639\n",
            "Epoch 597/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5249 - accuracy: 0.9826 - val_loss: 1.0673 - val_accuracy: 0.7361\n",
            "Epoch 598/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5075 - accuracy: 0.9931 - val_loss: 1.0617 - val_accuracy: 0.7569\n",
            "Epoch 599/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5290 - accuracy: 0.9844 - val_loss: 1.0678 - val_accuracy: 0.7569\n",
            "Epoch 600/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5468 - accuracy: 0.9844 - val_loss: 1.0657 - val_accuracy: 0.7639\n",
            "Epoch 601/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5200 - accuracy: 0.9913 - val_loss: 1.0731 - val_accuracy: 0.7500\n",
            "Epoch 602/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5363 - accuracy: 0.9792 - val_loss: 1.0720 - val_accuracy: 0.7500\n",
            "Epoch 603/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5055 - accuracy: 0.9896 - val_loss: 1.0685 - val_accuracy: 0.7431\n",
            "Epoch 604/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5313 - accuracy: 0.9826 - val_loss: 1.0581 - val_accuracy: 0.7708\n",
            "Epoch 605/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5293 - accuracy: 0.9861 - val_loss: 1.0538 - val_accuracy: 0.7639\n",
            "Epoch 606/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5096 - accuracy: 0.9878 - val_loss: 1.0720 - val_accuracy: 0.7708\n",
            "Epoch 607/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5240 - accuracy: 0.9844 - val_loss: 1.0585 - val_accuracy: 0.7639\n",
            "Epoch 608/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5137 - accuracy: 0.9913 - val_loss: 1.0663 - val_accuracy: 0.7569\n",
            "Epoch 609/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5205 - accuracy: 0.9896 - val_loss: 1.0724 - val_accuracy: 0.7639\n",
            "Epoch 610/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5065 - accuracy: 0.9948 - val_loss: 1.0438 - val_accuracy: 0.7639\n",
            "Epoch 611/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5177 - accuracy: 0.9844 - val_loss: 1.0707 - val_accuracy: 0.7708\n",
            "Epoch 612/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5091 - accuracy: 0.9931 - val_loss: 1.0712 - val_accuracy: 0.7500\n",
            "Epoch 613/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5149 - accuracy: 0.9878 - val_loss: 1.0682 - val_accuracy: 0.7708\n",
            "Epoch 614/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4997 - accuracy: 0.9896 - val_loss: 1.0638 - val_accuracy: 0.7431\n",
            "Epoch 615/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5174 - accuracy: 0.9861 - val_loss: 1.0742 - val_accuracy: 0.7292\n",
            "Epoch 616/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5015 - accuracy: 0.9913 - val_loss: 1.0640 - val_accuracy: 0.7569\n",
            "Epoch 617/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5064 - accuracy: 0.9931 - val_loss: 1.0637 - val_accuracy: 0.7500\n",
            "Epoch 618/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5304 - accuracy: 0.9740 - val_loss: 1.0646 - val_accuracy: 0.7569\n",
            "Epoch 619/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5214 - accuracy: 0.9896 - val_loss: 1.0629 - val_accuracy: 0.7639\n",
            "Epoch 620/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5172 - accuracy: 0.9861 - val_loss: 1.0639 - val_accuracy: 0.7500\n",
            "Epoch 621/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5194 - accuracy: 0.9896 - val_loss: 1.0664 - val_accuracy: 0.7500\n",
            "Epoch 622/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5136 - accuracy: 0.9965 - val_loss: 1.0734 - val_accuracy: 0.7500\n",
            "Epoch 623/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5078 - accuracy: 0.9913 - val_loss: 1.0615 - val_accuracy: 0.7500\n",
            "Epoch 624/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5131 - accuracy: 0.9878 - val_loss: 1.0642 - val_accuracy: 0.7639\n",
            "Epoch 625/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5051 - accuracy: 0.9878 - val_loss: 1.0699 - val_accuracy: 0.7569\n",
            "Epoch 626/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5093 - accuracy: 0.9913 - val_loss: 1.0647 - val_accuracy: 0.7500\n",
            "Epoch 627/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5173 - accuracy: 0.9861 - val_loss: 1.0658 - val_accuracy: 0.7639\n",
            "Epoch 628/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5034 - accuracy: 0.9844 - val_loss: 1.0648 - val_accuracy: 0.7639\n",
            "Epoch 629/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5258 - accuracy: 0.9809 - val_loss: 1.0519 - val_accuracy: 0.7569\n",
            "Epoch 630/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4955 - accuracy: 0.9896 - val_loss: 1.0649 - val_accuracy: 0.7500\n",
            "Epoch 631/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5063 - accuracy: 0.9896 - val_loss: 1.0594 - val_accuracy: 0.7569\n",
            "Epoch 632/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4962 - accuracy: 0.9948 - val_loss: 1.0733 - val_accuracy: 0.7639\n",
            "Epoch 633/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4981 - accuracy: 0.9913 - val_loss: 1.0496 - val_accuracy: 0.7708\n",
            "Epoch 634/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5021 - accuracy: 0.9861 - val_loss: 1.0477 - val_accuracy: 0.7569\n",
            "Epoch 635/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4904 - accuracy: 0.9913 - val_loss: 1.0548 - val_accuracy: 0.7500\n",
            "Epoch 636/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5040 - accuracy: 0.9878 - val_loss: 1.0595 - val_accuracy: 0.7569\n",
            "Epoch 637/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5021 - accuracy: 0.9913 - val_loss: 1.0597 - val_accuracy: 0.7639\n",
            "Epoch 638/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5034 - accuracy: 0.9896 - val_loss: 1.0459 - val_accuracy: 0.7639\n",
            "Epoch 639/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5130 - accuracy: 0.9896 - val_loss: 1.0461 - val_accuracy: 0.7708\n",
            "Epoch 640/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5199 - accuracy: 0.9774 - val_loss: 1.0509 - val_accuracy: 0.7500\n",
            "Epoch 641/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5163 - accuracy: 0.9861 - val_loss: 1.0406 - val_accuracy: 0.7778\n",
            "Epoch 642/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4946 - accuracy: 0.9931 - val_loss: 1.0532 - val_accuracy: 0.7917\n",
            "Epoch 643/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4972 - accuracy: 0.9913 - val_loss: 1.0557 - val_accuracy: 0.7708\n",
            "Epoch 644/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5087 - accuracy: 0.9896 - val_loss: 1.0670 - val_accuracy: 0.7431\n",
            "Epoch 645/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5162 - accuracy: 0.9948 - val_loss: 1.0557 - val_accuracy: 0.7917\n",
            "Epoch 646/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5028 - accuracy: 0.9896 - val_loss: 1.0548 - val_accuracy: 0.7500\n",
            "Epoch 647/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5017 - accuracy: 0.9983 - val_loss: 1.0598 - val_accuracy: 0.7569\n",
            "Epoch 648/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4985 - accuracy: 0.9948 - val_loss: 1.0603 - val_accuracy: 0.7708\n",
            "Epoch 649/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5025 - accuracy: 0.9861 - val_loss: 1.0539 - val_accuracy: 0.7639\n",
            "Epoch 650/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5017 - accuracy: 0.9878 - val_loss: 1.0619 - val_accuracy: 0.7708\n",
            "Epoch 651/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5002 - accuracy: 0.9931 - val_loss: 1.0668 - val_accuracy: 0.7708\n",
            "Epoch 652/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4932 - accuracy: 0.9931 - val_loss: 1.0684 - val_accuracy: 0.7431\n",
            "Epoch 653/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4957 - accuracy: 0.9896 - val_loss: 1.0624 - val_accuracy: 0.7500\n",
            "Epoch 654/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5034 - accuracy: 0.9948 - val_loss: 1.0500 - val_accuracy: 0.7708\n",
            "Epoch 655/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4952 - accuracy: 0.9948 - val_loss: 1.0590 - val_accuracy: 0.7778\n",
            "Epoch 656/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4864 - accuracy: 0.9913 - val_loss: 1.0592 - val_accuracy: 0.7500\n",
            "Epoch 657/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4937 - accuracy: 0.9931 - val_loss: 1.0638 - val_accuracy: 0.7847\n",
            "Epoch 658/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4895 - accuracy: 0.9965 - val_loss: 1.0558 - val_accuracy: 0.7708\n",
            "Epoch 659/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.4959 - accuracy: 0.9861 - val_loss: 1.0613 - val_accuracy: 0.7639\n",
            "Epoch 660/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5043 - accuracy: 0.9913 - val_loss: 1.0426 - val_accuracy: 0.7569\n",
            "Epoch 661/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5122 - accuracy: 0.9826 - val_loss: 1.0453 - val_accuracy: 0.7708\n",
            "Epoch 662/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5073 - accuracy: 0.9896 - val_loss: 1.0485 - val_accuracy: 0.7500\n",
            "Epoch 663/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4881 - accuracy: 0.9948 - val_loss: 1.0485 - val_accuracy: 0.7569\n",
            "Epoch 664/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4957 - accuracy: 0.9948 - val_loss: 1.0584 - val_accuracy: 0.7778\n",
            "Epoch 665/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4982 - accuracy: 0.9896 - val_loss: 1.0540 - val_accuracy: 0.7500\n",
            "Epoch 666/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4944 - accuracy: 0.9948 - val_loss: 1.0662 - val_accuracy: 0.7431\n",
            "Epoch 667/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4769 - accuracy: 0.9948 - val_loss: 1.0584 - val_accuracy: 0.7639\n",
            "Epoch 668/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4856 - accuracy: 0.9965 - val_loss: 1.0613 - val_accuracy: 0.7569\n",
            "Epoch 669/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4881 - accuracy: 0.9965 - val_loss: 1.0494 - val_accuracy: 0.7569\n",
            "Epoch 670/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4928 - accuracy: 0.9931 - val_loss: 1.0601 - val_accuracy: 0.7431\n",
            "Epoch 671/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5034 - accuracy: 0.9861 - val_loss: 1.0528 - val_accuracy: 0.7569\n",
            "Epoch 672/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4825 - accuracy: 0.9948 - val_loss: 1.0623 - val_accuracy: 0.7500\n",
            "Epoch 673/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4911 - accuracy: 0.9931 - val_loss: 1.0691 - val_accuracy: 0.7500\n",
            "Epoch 674/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4773 - accuracy: 0.9931 - val_loss: 1.0570 - val_accuracy: 0.7500\n",
            "Epoch 675/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4952 - accuracy: 0.9844 - val_loss: 1.0707 - val_accuracy: 0.7639\n",
            "Epoch 676/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5069 - accuracy: 0.9931 - val_loss: 1.0715 - val_accuracy: 0.7569\n",
            "Epoch 677/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4950 - accuracy: 0.9913 - val_loss: 1.0725 - val_accuracy: 0.7778\n",
            "Epoch 678/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4918 - accuracy: 0.9931 - val_loss: 1.0584 - val_accuracy: 0.7708\n",
            "Epoch 679/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4936 - accuracy: 0.9826 - val_loss: 1.0558 - val_accuracy: 0.7569\n",
            "Epoch 680/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4824 - accuracy: 0.9931 - val_loss: 1.0566 - val_accuracy: 0.7569\n",
            "Epoch 681/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4895 - accuracy: 0.9826 - val_loss: 1.0621 - val_accuracy: 0.7639\n",
            "Epoch 682/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4862 - accuracy: 0.9913 - val_loss: 1.0645 - val_accuracy: 0.7500\n",
            "Epoch 683/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4862 - accuracy: 0.9913 - val_loss: 1.0630 - val_accuracy: 0.7569\n",
            "Epoch 684/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4666 - accuracy: 0.9913 - val_loss: 1.0688 - val_accuracy: 0.7639\n",
            "Epoch 685/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4978 - accuracy: 0.9948 - val_loss: 1.0630 - val_accuracy: 0.7639\n",
            "Epoch 686/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4826 - accuracy: 0.9948 - val_loss: 1.0697 - val_accuracy: 0.7569\n",
            "Epoch 687/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4870 - accuracy: 0.9965 - val_loss: 1.0576 - val_accuracy: 0.7639\n",
            "Epoch 688/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4817 - accuracy: 0.9948 - val_loss: 1.0581 - val_accuracy: 0.7708\n",
            "Epoch 689/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4771 - accuracy: 0.9931 - val_loss: 1.0575 - val_accuracy: 0.7708\n",
            "Epoch 690/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4957 - accuracy: 0.9878 - val_loss: 1.0544 - val_accuracy: 0.7778\n",
            "Epoch 691/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4922 - accuracy: 0.9948 - val_loss: 1.0615 - val_accuracy: 0.7500\n",
            "Epoch 692/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4920 - accuracy: 0.9948 - val_loss: 1.0665 - val_accuracy: 0.7569\n",
            "Epoch 693/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4771 - accuracy: 0.9948 - val_loss: 1.0649 - val_accuracy: 0.7639\n",
            "Epoch 694/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4808 - accuracy: 0.9878 - val_loss: 1.0469 - val_accuracy: 0.7847\n",
            "Epoch 695/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4782 - accuracy: 0.9896 - val_loss: 1.0541 - val_accuracy: 0.7569\n",
            "Epoch 696/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4718 - accuracy: 0.9896 - val_loss: 1.0620 - val_accuracy: 0.7708\n",
            "Epoch 697/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4751 - accuracy: 1.0000 - val_loss: 1.0521 - val_accuracy: 0.7847\n",
            "Epoch 698/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4671 - accuracy: 0.9965 - val_loss: 1.0570 - val_accuracy: 0.7639\n",
            "Epoch 699/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4868 - accuracy: 0.9983 - val_loss: 1.0678 - val_accuracy: 0.7431\n",
            "Epoch 700/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4901 - accuracy: 0.9965 - val_loss: 1.0593 - val_accuracy: 0.7708\n",
            "4\n",
            "Epoch 1/700\n",
            "9/9 [==============================] - 2s 106ms/step - loss: 2.3427 - accuracy: 0.1632 - val_loss: 2.2405 - val_accuracy: 0.1458\n",
            "Epoch 2/700\n",
            "9/9 [==============================] - 1s 95ms/step - loss: 2.2286 - accuracy: 0.1684 - val_loss: 2.1811 - val_accuracy: 0.1458\n",
            "Epoch 3/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 2.1974 - accuracy: 0.1736 - val_loss: 2.1464 - val_accuracy: 0.1458\n",
            "Epoch 4/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 2.0752 - accuracy: 0.2101 - val_loss: 2.1134 - val_accuracy: 0.0972\n",
            "Epoch 5/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 2.0407 - accuracy: 0.2170 - val_loss: 2.0782 - val_accuracy: 0.0833\n",
            "Epoch 6/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 2.0683 - accuracy: 0.1927 - val_loss: 2.0520 - val_accuracy: 0.1111\n",
            "Epoch 7/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 2.0312 - accuracy: 0.2274 - val_loss: 2.0356 - val_accuracy: 0.1181\n",
            "Epoch 8/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.9832 - accuracy: 0.2535 - val_loss: 2.0173 - val_accuracy: 0.1250\n",
            "Epoch 9/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.9414 - accuracy: 0.2569 - val_loss: 2.0004 - val_accuracy: 0.1319\n",
            "Epoch 10/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.9548 - accuracy: 0.2691 - val_loss: 1.9820 - val_accuracy: 0.2292\n",
            "Epoch 11/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.8828 - accuracy: 0.2899 - val_loss: 1.9791 - val_accuracy: 0.2292\n",
            "Epoch 12/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.8736 - accuracy: 0.2569 - val_loss: 1.9780 - val_accuracy: 0.2361\n",
            "Epoch 13/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.8420 - accuracy: 0.3021 - val_loss: 1.9850 - val_accuracy: 0.2153\n",
            "Epoch 14/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.7908 - accuracy: 0.3194 - val_loss: 1.9885 - val_accuracy: 0.2014\n",
            "Epoch 15/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.7702 - accuracy: 0.3229 - val_loss: 1.9914 - val_accuracy: 0.2292\n",
            "Epoch 16/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.7758 - accuracy: 0.3490 - val_loss: 1.9953 - val_accuracy: 0.1597\n",
            "Epoch 17/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.8108 - accuracy: 0.2986 - val_loss: 1.9985 - val_accuracy: 0.1597\n",
            "Epoch 18/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.7429 - accuracy: 0.3490 - val_loss: 2.0055 - val_accuracy: 0.1528\n",
            "Epoch 19/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.7295 - accuracy: 0.3403 - val_loss: 2.0198 - val_accuracy: 0.1528\n",
            "Epoch 20/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.7105 - accuracy: 0.3507 - val_loss: 2.0302 - val_accuracy: 0.1806\n",
            "Epoch 21/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.7129 - accuracy: 0.3316 - val_loss: 2.0341 - val_accuracy: 0.1528\n",
            "Epoch 22/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.6728 - accuracy: 0.3750 - val_loss: 2.0401 - val_accuracy: 0.1736\n",
            "Epoch 23/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.6827 - accuracy: 0.3663 - val_loss: 2.0424 - val_accuracy: 0.1528\n",
            "Epoch 24/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6778 - accuracy: 0.3663 - val_loss: 2.0383 - val_accuracy: 0.1875\n",
            "Epoch 25/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.6418 - accuracy: 0.4149 - val_loss: 2.0527 - val_accuracy: 0.1806\n",
            "Epoch 26/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.6413 - accuracy: 0.3611 - val_loss: 2.0521 - val_accuracy: 0.1736\n",
            "Epoch 27/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.6185 - accuracy: 0.4010 - val_loss: 2.0582 - val_accuracy: 0.1597\n",
            "Epoch 28/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.5863 - accuracy: 0.4219 - val_loss: 2.0648 - val_accuracy: 0.1528\n",
            "Epoch 29/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.5536 - accuracy: 0.4184 - val_loss: 2.0533 - val_accuracy: 0.1458\n",
            "Epoch 30/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.5635 - accuracy: 0.4028 - val_loss: 2.0656 - val_accuracy: 0.1528\n",
            "Epoch 31/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.6026 - accuracy: 0.4097 - val_loss: 2.0392 - val_accuracy: 0.1528\n",
            "Epoch 32/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.5385 - accuracy: 0.4462 - val_loss: 2.0385 - val_accuracy: 0.1528\n",
            "Epoch 33/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.5500 - accuracy: 0.4219 - val_loss: 2.0414 - val_accuracy: 0.1528\n",
            "Epoch 34/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.5057 - accuracy: 0.4583 - val_loss: 2.0303 - val_accuracy: 0.1597\n",
            "Epoch 35/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.5105 - accuracy: 0.4531 - val_loss: 2.0170 - val_accuracy: 0.1667\n",
            "Epoch 36/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.4826 - accuracy: 0.4896 - val_loss: 2.0131 - val_accuracy: 0.2083\n",
            "Epoch 37/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4884 - accuracy: 0.4861 - val_loss: 1.9963 - val_accuracy: 0.1875\n",
            "Epoch 38/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.4694 - accuracy: 0.4653 - val_loss: 1.9998 - val_accuracy: 0.1736\n",
            "Epoch 39/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.4828 - accuracy: 0.4809 - val_loss: 1.9901 - val_accuracy: 0.1667\n",
            "Epoch 40/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.4721 - accuracy: 0.4844 - val_loss: 1.9550 - val_accuracy: 0.1875\n",
            "Epoch 41/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.4423 - accuracy: 0.4896 - val_loss: 1.9446 - val_accuracy: 0.1944\n",
            "Epoch 42/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.4645 - accuracy: 0.5035 - val_loss: 1.9386 - val_accuracy: 0.2361\n",
            "Epoch 43/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.4302 - accuracy: 0.5122 - val_loss: 1.9417 - val_accuracy: 0.2500\n",
            "Epoch 44/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.4103 - accuracy: 0.5069 - val_loss: 1.9285 - val_accuracy: 0.2569\n",
            "Epoch 45/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.4056 - accuracy: 0.5382 - val_loss: 1.9182 - val_accuracy: 0.2431\n",
            "Epoch 46/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.4063 - accuracy: 0.5260 - val_loss: 1.8841 - val_accuracy: 0.2569\n",
            "Epoch 47/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3867 - accuracy: 0.5295 - val_loss: 1.8566 - val_accuracy: 0.2639\n",
            "Epoch 48/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.3880 - accuracy: 0.5260 - val_loss: 1.8464 - val_accuracy: 0.2778\n",
            "Epoch 49/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.3512 - accuracy: 0.5399 - val_loss: 1.8188 - val_accuracy: 0.2639\n",
            "Epoch 50/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3607 - accuracy: 0.5608 - val_loss: 1.8036 - val_accuracy: 0.2639\n",
            "Epoch 51/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.3901 - accuracy: 0.5330 - val_loss: 1.7892 - val_accuracy: 0.2778\n",
            "Epoch 52/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.3572 - accuracy: 0.5469 - val_loss: 1.7893 - val_accuracy: 0.2778\n",
            "Epoch 53/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3446 - accuracy: 0.5590 - val_loss: 1.7638 - val_accuracy: 0.2917\n",
            "Epoch 54/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.3350 - accuracy: 0.5590 - val_loss: 1.7445 - val_accuracy: 0.2917\n",
            "Epoch 55/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.3396 - accuracy: 0.5833 - val_loss: 1.7406 - val_accuracy: 0.2917\n",
            "Epoch 56/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3093 - accuracy: 0.5660 - val_loss: 1.7301 - val_accuracy: 0.2917\n",
            "Epoch 57/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.3187 - accuracy: 0.5642 - val_loss: 1.7041 - val_accuracy: 0.3056\n",
            "Epoch 58/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.3364 - accuracy: 0.5677 - val_loss: 1.6645 - val_accuracy: 0.3264\n",
            "Epoch 59/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.3056 - accuracy: 0.6059 - val_loss: 1.6559 - val_accuracy: 0.3472\n",
            "Epoch 60/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.3025 - accuracy: 0.5694 - val_loss: 1.6513 - val_accuracy: 0.3472\n",
            "Epoch 61/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2973 - accuracy: 0.5642 - val_loss: 1.6210 - val_accuracy: 0.3611\n",
            "Epoch 62/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2816 - accuracy: 0.5955 - val_loss: 1.6116 - val_accuracy: 0.3681\n",
            "Epoch 63/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2839 - accuracy: 0.5903 - val_loss: 1.6104 - val_accuracy: 0.3542\n",
            "Epoch 64/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2602 - accuracy: 0.6111 - val_loss: 1.5992 - val_accuracy: 0.3542\n",
            "Epoch 65/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.2794 - accuracy: 0.5851 - val_loss: 1.5792 - val_accuracy: 0.3819\n",
            "Epoch 66/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2652 - accuracy: 0.5885 - val_loss: 1.5442 - val_accuracy: 0.4375\n",
            "Epoch 67/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2462 - accuracy: 0.6181 - val_loss: 1.5605 - val_accuracy: 0.4097\n",
            "Epoch 68/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2650 - accuracy: 0.5712 - val_loss: 1.5381 - val_accuracy: 0.4167\n",
            "Epoch 69/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.2648 - accuracy: 0.6163 - val_loss: 1.5089 - val_accuracy: 0.4583\n",
            "Epoch 70/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.2372 - accuracy: 0.6128 - val_loss: 1.5060 - val_accuracy: 0.4306\n",
            "Epoch 71/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.2426 - accuracy: 0.6250 - val_loss: 1.4824 - val_accuracy: 0.4444\n",
            "Epoch 72/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.2319 - accuracy: 0.6007 - val_loss: 1.4822 - val_accuracy: 0.4375\n",
            "Epoch 73/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2736 - accuracy: 0.5677 - val_loss: 1.4763 - val_accuracy: 0.4722\n",
            "Epoch 74/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2273 - accuracy: 0.6285 - val_loss: 1.4729 - val_accuracy: 0.4653\n",
            "Epoch 75/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.2322 - accuracy: 0.6076 - val_loss: 1.4430 - val_accuracy: 0.4861\n",
            "Epoch 76/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2339 - accuracy: 0.6076 - val_loss: 1.4597 - val_accuracy: 0.4722\n",
            "Epoch 77/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.2368 - accuracy: 0.6146 - val_loss: 1.4333 - val_accuracy: 0.4931\n",
            "Epoch 78/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1860 - accuracy: 0.6389 - val_loss: 1.4189 - val_accuracy: 0.5486\n",
            "Epoch 79/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.2118 - accuracy: 0.6215 - val_loss: 1.4187 - val_accuracy: 0.5139\n",
            "Epoch 80/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.2221 - accuracy: 0.6233 - val_loss: 1.4423 - val_accuracy: 0.5278\n",
            "Epoch 81/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1860 - accuracy: 0.6389 - val_loss: 1.4102 - val_accuracy: 0.5347\n",
            "Epoch 82/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1911 - accuracy: 0.6337 - val_loss: 1.3924 - val_accuracy: 0.5347\n",
            "Epoch 83/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.2107 - accuracy: 0.6198 - val_loss: 1.4038 - val_accuracy: 0.5417\n",
            "Epoch 84/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1950 - accuracy: 0.6493 - val_loss: 1.3946 - val_accuracy: 0.5694\n",
            "Epoch 85/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1521 - accuracy: 0.6562 - val_loss: 1.3983 - val_accuracy: 0.5486\n",
            "Epoch 86/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1515 - accuracy: 0.6649 - val_loss: 1.3805 - val_accuracy: 0.5833\n",
            "Epoch 87/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1470 - accuracy: 0.6649 - val_loss: 1.3690 - val_accuracy: 0.5972\n",
            "Epoch 88/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1720 - accuracy: 0.6441 - val_loss: 1.3765 - val_accuracy: 0.6042\n",
            "Epoch 89/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1458 - accuracy: 0.6649 - val_loss: 1.3776 - val_accuracy: 0.5903\n",
            "Epoch 90/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1621 - accuracy: 0.6493 - val_loss: 1.3676 - val_accuracy: 0.6042\n",
            "Epoch 91/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.1580 - accuracy: 0.6545 - val_loss: 1.3693 - val_accuracy: 0.5694\n",
            "Epoch 92/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.1742 - accuracy: 0.6354 - val_loss: 1.3603 - val_accuracy: 0.5903\n",
            "Epoch 93/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1469 - accuracy: 0.6528 - val_loss: 1.3573 - val_accuracy: 0.5833\n",
            "Epoch 94/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1342 - accuracy: 0.6632 - val_loss: 1.3557 - val_accuracy: 0.6042\n",
            "Epoch 95/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1468 - accuracy: 0.6597 - val_loss: 1.3535 - val_accuracy: 0.5903\n",
            "Epoch 96/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1381 - accuracy: 0.6632 - val_loss: 1.3539 - val_accuracy: 0.5903\n",
            "Epoch 97/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.1152 - accuracy: 0.6840 - val_loss: 1.3533 - val_accuracy: 0.5764\n",
            "Epoch 98/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1214 - accuracy: 0.6944 - val_loss: 1.3255 - val_accuracy: 0.5972\n",
            "Epoch 99/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1279 - accuracy: 0.6667 - val_loss: 1.3259 - val_accuracy: 0.5764\n",
            "Epoch 100/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1308 - accuracy: 0.6788 - val_loss: 1.3427 - val_accuracy: 0.5417\n",
            "Epoch 101/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.1009 - accuracy: 0.6858 - val_loss: 1.3306 - val_accuracy: 0.6042\n",
            "Epoch 102/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1285 - accuracy: 0.6719 - val_loss: 1.3194 - val_accuracy: 0.5972\n",
            "Epoch 103/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.1103 - accuracy: 0.7031 - val_loss: 1.3323 - val_accuracy: 0.5833\n",
            "Epoch 104/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1053 - accuracy: 0.6823 - val_loss: 1.3516 - val_accuracy: 0.5556\n",
            "Epoch 105/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.1273 - accuracy: 0.6823 - val_loss: 1.3194 - val_accuracy: 0.6042\n",
            "Epoch 106/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0954 - accuracy: 0.7135 - val_loss: 1.3391 - val_accuracy: 0.5903\n",
            "Epoch 107/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1190 - accuracy: 0.6788 - val_loss: 1.3399 - val_accuracy: 0.5764\n",
            "Epoch 108/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0868 - accuracy: 0.6962 - val_loss: 1.3271 - val_accuracy: 0.5903\n",
            "Epoch 109/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.1072 - accuracy: 0.6667 - val_loss: 1.3117 - val_accuracy: 0.6042\n",
            "Epoch 110/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0981 - accuracy: 0.6944 - val_loss: 1.3104 - val_accuracy: 0.6250\n",
            "Epoch 111/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.1241 - accuracy: 0.6771 - val_loss: 1.3172 - val_accuracy: 0.5972\n",
            "Epoch 112/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0768 - accuracy: 0.7205 - val_loss: 1.3059 - val_accuracy: 0.6181\n",
            "Epoch 113/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.1029 - accuracy: 0.6979 - val_loss: 1.3029 - val_accuracy: 0.6319\n",
            "Epoch 114/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0652 - accuracy: 0.7292 - val_loss: 1.2942 - val_accuracy: 0.6458\n",
            "Epoch 115/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0665 - accuracy: 0.7292 - val_loss: 1.3100 - val_accuracy: 0.6319\n",
            "Epoch 116/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0551 - accuracy: 0.7153 - val_loss: 1.3068 - val_accuracy: 0.6181\n",
            "Epoch 117/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0614 - accuracy: 0.7188 - val_loss: 1.3285 - val_accuracy: 0.5972\n",
            "Epoch 118/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0351 - accuracy: 0.7292 - val_loss: 1.3126 - val_accuracy: 0.6111\n",
            "Epoch 119/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0781 - accuracy: 0.7066 - val_loss: 1.3056 - val_accuracy: 0.6111\n",
            "Epoch 120/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0696 - accuracy: 0.7188 - val_loss: 1.3265 - val_accuracy: 0.5972\n",
            "Epoch 121/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 1.0532 - accuracy: 0.7309 - val_loss: 1.3206 - val_accuracy: 0.5833\n",
            "Epoch 122/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0524 - accuracy: 0.7240 - val_loss: 1.3148 - val_accuracy: 0.5903\n",
            "Epoch 123/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0300 - accuracy: 0.7413 - val_loss: 1.3246 - val_accuracy: 0.5625\n",
            "Epoch 124/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 1.0465 - accuracy: 0.7344 - val_loss: 1.3145 - val_accuracy: 0.5764\n",
            "Epoch 125/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0656 - accuracy: 0.7257 - val_loss: 1.3084 - val_accuracy: 0.5972\n",
            "Epoch 126/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0398 - accuracy: 0.7240 - val_loss: 1.3036 - val_accuracy: 0.5903\n",
            "Epoch 127/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0579 - accuracy: 0.7066 - val_loss: 1.2763 - val_accuracy: 0.6319\n",
            "Epoch 128/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0329 - accuracy: 0.7517 - val_loss: 1.2999 - val_accuracy: 0.6181\n",
            "Epoch 129/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 1.0486 - accuracy: 0.7066 - val_loss: 1.2836 - val_accuracy: 0.6181\n",
            "Epoch 130/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0228 - accuracy: 0.7274 - val_loss: 1.2971 - val_accuracy: 0.5833\n",
            "Epoch 131/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0286 - accuracy: 0.7622 - val_loss: 1.2882 - val_accuracy: 0.6389\n",
            "Epoch 132/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 1.0098 - accuracy: 0.7396 - val_loss: 1.2701 - val_accuracy: 0.6528\n",
            "Epoch 133/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0117 - accuracy: 0.7552 - val_loss: 1.2825 - val_accuracy: 0.6389\n",
            "Epoch 134/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0330 - accuracy: 0.7309 - val_loss: 1.2855 - val_accuracy: 0.6181\n",
            "Epoch 135/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9996 - accuracy: 0.7500 - val_loss: 1.2828 - val_accuracy: 0.6250\n",
            "Epoch 136/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 1.0167 - accuracy: 0.7361 - val_loss: 1.2841 - val_accuracy: 0.6181\n",
            "Epoch 137/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0293 - accuracy: 0.7535 - val_loss: 1.2933 - val_accuracy: 0.6319\n",
            "Epoch 138/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9952 - accuracy: 0.7535 - val_loss: 1.2758 - val_accuracy: 0.6458\n",
            "Epoch 139/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9798 - accuracy: 0.7778 - val_loss: 1.2645 - val_accuracy: 0.6250\n",
            "Epoch 140/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9976 - accuracy: 0.7517 - val_loss: 1.2762 - val_accuracy: 0.6458\n",
            "Epoch 141/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0019 - accuracy: 0.7604 - val_loss: 1.2762 - val_accuracy: 0.6111\n",
            "Epoch 142/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9947 - accuracy: 0.7604 - val_loss: 1.2737 - val_accuracy: 0.6319\n",
            "Epoch 143/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 1.0100 - accuracy: 0.7604 - val_loss: 1.2787 - val_accuracy: 0.6250\n",
            "Epoch 144/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9835 - accuracy: 0.7743 - val_loss: 1.2882 - val_accuracy: 0.6042\n",
            "Epoch 145/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 1.0120 - accuracy: 0.7361 - val_loss: 1.2690 - val_accuracy: 0.6458\n",
            "Epoch 146/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9994 - accuracy: 0.7622 - val_loss: 1.2580 - val_accuracy: 0.6458\n",
            "Epoch 147/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 1.0045 - accuracy: 0.7587 - val_loss: 1.2580 - val_accuracy: 0.6319\n",
            "Epoch 148/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 1.0014 - accuracy: 0.7639 - val_loss: 1.2544 - val_accuracy: 0.6319\n",
            "Epoch 149/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9898 - accuracy: 0.7587 - val_loss: 1.2623 - val_accuracy: 0.6389\n",
            "Epoch 150/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9802 - accuracy: 0.7552 - val_loss: 1.2700 - val_accuracy: 0.6181\n",
            "Epoch 151/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9667 - accuracy: 0.7535 - val_loss: 1.2622 - val_accuracy: 0.6181\n",
            "Epoch 152/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9896 - accuracy: 0.7361 - val_loss: 1.2624 - val_accuracy: 0.6181\n",
            "Epoch 153/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9655 - accuracy: 0.7708 - val_loss: 1.2526 - val_accuracy: 0.6458\n",
            "Epoch 154/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9717 - accuracy: 0.7743 - val_loss: 1.2521 - val_accuracy: 0.6597\n",
            "Epoch 155/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9466 - accuracy: 0.7951 - val_loss: 1.2615 - val_accuracy: 0.6389\n",
            "Epoch 156/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9673 - accuracy: 0.7691 - val_loss: 1.2772 - val_accuracy: 0.6111\n",
            "Epoch 157/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9482 - accuracy: 0.7847 - val_loss: 1.2722 - val_accuracy: 0.6389\n",
            "Epoch 158/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9657 - accuracy: 0.7691 - val_loss: 1.2718 - val_accuracy: 0.6250\n",
            "Epoch 159/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9621 - accuracy: 0.7986 - val_loss: 1.2658 - val_accuracy: 0.6597\n",
            "Epoch 160/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9479 - accuracy: 0.7969 - val_loss: 1.2667 - val_accuracy: 0.6389\n",
            "Epoch 161/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9754 - accuracy: 0.8003 - val_loss: 1.2556 - val_accuracy: 0.6389\n",
            "Epoch 162/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9416 - accuracy: 0.7847 - val_loss: 1.2581 - val_accuracy: 0.6458\n",
            "Epoch 163/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9401 - accuracy: 0.7882 - val_loss: 1.2532 - val_accuracy: 0.6458\n",
            "Epoch 164/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.9534 - accuracy: 0.7760 - val_loss: 1.2458 - val_accuracy: 0.6528\n",
            "Epoch 165/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9409 - accuracy: 0.7899 - val_loss: 1.2428 - val_accuracy: 0.6806\n",
            "Epoch 166/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9704 - accuracy: 0.7691 - val_loss: 1.2438 - val_accuracy: 0.6667\n",
            "Epoch 167/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9254 - accuracy: 0.8056 - val_loss: 1.2481 - val_accuracy: 0.6597\n",
            "Epoch 168/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9355 - accuracy: 0.7865 - val_loss: 1.2410 - val_accuracy: 0.6597\n",
            "Epoch 169/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9541 - accuracy: 0.7743 - val_loss: 1.2453 - val_accuracy: 0.6944\n",
            "Epoch 170/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9330 - accuracy: 0.7882 - val_loss: 1.2343 - val_accuracy: 0.6875\n",
            "Epoch 171/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9411 - accuracy: 0.7708 - val_loss: 1.2422 - val_accuracy: 0.6319\n",
            "Epoch 172/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9282 - accuracy: 0.8090 - val_loss: 1.2393 - val_accuracy: 0.6667\n",
            "Epoch 173/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9414 - accuracy: 0.7986 - val_loss: 1.2426 - val_accuracy: 0.6667\n",
            "Epoch 174/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9357 - accuracy: 0.8090 - val_loss: 1.2415 - val_accuracy: 0.6597\n",
            "Epoch 175/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9237 - accuracy: 0.8038 - val_loss: 1.2351 - val_accuracy: 0.6736\n",
            "Epoch 176/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9376 - accuracy: 0.7899 - val_loss: 1.2519 - val_accuracy: 0.6736\n",
            "Epoch 177/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.9272 - accuracy: 0.7917 - val_loss: 1.2454 - val_accuracy: 0.6528\n",
            "Epoch 178/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9318 - accuracy: 0.8229 - val_loss: 1.2352 - val_accuracy: 0.6597\n",
            "Epoch 179/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.9087 - accuracy: 0.8247 - val_loss: 1.2484 - val_accuracy: 0.6667\n",
            "Epoch 180/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9021 - accuracy: 0.8160 - val_loss: 1.2374 - val_accuracy: 0.6667\n",
            "Epoch 181/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9174 - accuracy: 0.8038 - val_loss: 1.2372 - val_accuracy: 0.6597\n",
            "Epoch 182/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.9094 - accuracy: 0.7951 - val_loss: 1.2444 - val_accuracy: 0.6597\n",
            "Epoch 183/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.9035 - accuracy: 0.8264 - val_loss: 1.2358 - val_accuracy: 0.6667\n",
            "Epoch 184/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8935 - accuracy: 0.8229 - val_loss: 1.2374 - val_accuracy: 0.6667\n",
            "Epoch 185/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8969 - accuracy: 0.8264 - val_loss: 1.2345 - val_accuracy: 0.6597\n",
            "Epoch 186/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9112 - accuracy: 0.8038 - val_loss: 1.2200 - val_accuracy: 0.6875\n",
            "Epoch 187/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8813 - accuracy: 0.8333 - val_loss: 1.2198 - val_accuracy: 0.6667\n",
            "Epoch 188/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9180 - accuracy: 0.8021 - val_loss: 1.2316 - val_accuracy: 0.6667\n",
            "Epoch 189/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8974 - accuracy: 0.8073 - val_loss: 1.2171 - val_accuracy: 0.6875\n",
            "Epoch 190/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8836 - accuracy: 0.8212 - val_loss: 1.2286 - val_accuracy: 0.6875\n",
            "Epoch 191/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.9004 - accuracy: 0.8229 - val_loss: 1.2175 - val_accuracy: 0.6667\n",
            "Epoch 192/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.9090 - accuracy: 0.8056 - val_loss: 1.2256 - val_accuracy: 0.6597\n",
            "Epoch 193/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8998 - accuracy: 0.8264 - val_loss: 1.2299 - val_accuracy: 0.6736\n",
            "Epoch 194/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.9137 - accuracy: 0.8021 - val_loss: 1.2249 - val_accuracy: 0.6597\n",
            "Epoch 195/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8952 - accuracy: 0.8090 - val_loss: 1.2265 - val_accuracy: 0.6806\n",
            "Epoch 196/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8859 - accuracy: 0.8038 - val_loss: 1.2118 - val_accuracy: 0.6667\n",
            "Epoch 197/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.9017 - accuracy: 0.8038 - val_loss: 1.2309 - val_accuracy: 0.6458\n",
            "Epoch 198/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8624 - accuracy: 0.8455 - val_loss: 1.2181 - val_accuracy: 0.6806\n",
            "Epoch 199/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8697 - accuracy: 0.8351 - val_loss: 1.2180 - val_accuracy: 0.6806\n",
            "Epoch 200/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.8767 - accuracy: 0.8160 - val_loss: 1.2095 - val_accuracy: 0.6875\n",
            "Epoch 201/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8880 - accuracy: 0.8177 - val_loss: 1.2244 - val_accuracy: 0.6597\n",
            "Epoch 202/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8629 - accuracy: 0.8385 - val_loss: 1.2206 - val_accuracy: 0.6389\n",
            "Epoch 203/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8813 - accuracy: 0.8229 - val_loss: 1.2084 - val_accuracy: 0.6736\n",
            "Epoch 204/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8548 - accuracy: 0.8368 - val_loss: 1.2063 - val_accuracy: 0.6597\n",
            "Epoch 205/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8513 - accuracy: 0.8333 - val_loss: 1.2113 - val_accuracy: 0.6597\n",
            "Epoch 206/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8723 - accuracy: 0.8281 - val_loss: 1.2086 - val_accuracy: 0.6806\n",
            "Epoch 207/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8696 - accuracy: 0.8264 - val_loss: 1.2086 - val_accuracy: 0.6736\n",
            "Epoch 208/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8475 - accuracy: 0.8611 - val_loss: 1.2087 - val_accuracy: 0.6944\n",
            "Epoch 209/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8599 - accuracy: 0.8420 - val_loss: 1.2116 - val_accuracy: 0.6667\n",
            "Epoch 210/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8557 - accuracy: 0.8194 - val_loss: 1.2199 - val_accuracy: 0.6736\n",
            "Epoch 211/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8548 - accuracy: 0.8542 - val_loss: 1.2174 - val_accuracy: 0.6597\n",
            "Epoch 212/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8509 - accuracy: 0.8385 - val_loss: 1.2027 - val_accuracy: 0.6806\n",
            "Epoch 213/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8255 - accuracy: 0.8750 - val_loss: 1.2084 - val_accuracy: 0.6597\n",
            "Epoch 214/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8416 - accuracy: 0.8542 - val_loss: 1.2028 - val_accuracy: 0.6667\n",
            "Epoch 215/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8172 - accuracy: 0.8715 - val_loss: 1.2108 - val_accuracy: 0.6736\n",
            "Epoch 216/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8550 - accuracy: 0.8472 - val_loss: 1.2151 - val_accuracy: 0.6736\n",
            "Epoch 217/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.8380 - accuracy: 0.8594 - val_loss: 1.2000 - val_accuracy: 0.6667\n",
            "Epoch 218/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8487 - accuracy: 0.8576 - val_loss: 1.2119 - val_accuracy: 0.6319\n",
            "Epoch 219/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8297 - accuracy: 0.8542 - val_loss: 1.2056 - val_accuracy: 0.6528\n",
            "Epoch 220/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8282 - accuracy: 0.8785 - val_loss: 1.1933 - val_accuracy: 0.6806\n",
            "Epoch 221/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8322 - accuracy: 0.8490 - val_loss: 1.2026 - val_accuracy: 0.6806\n",
            "Epoch 222/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8520 - accuracy: 0.8681 - val_loss: 1.1914 - val_accuracy: 0.6875\n",
            "Epoch 223/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8126 - accuracy: 0.8490 - val_loss: 1.1922 - val_accuracy: 0.6806\n",
            "Epoch 224/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8336 - accuracy: 0.8472 - val_loss: 1.1946 - val_accuracy: 0.6528\n",
            "Epoch 225/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8571 - accuracy: 0.8316 - val_loss: 1.1977 - val_accuracy: 0.6389\n",
            "Epoch 226/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8450 - accuracy: 0.8368 - val_loss: 1.1949 - val_accuracy: 0.6597\n",
            "Epoch 227/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8655 - accuracy: 0.8455 - val_loss: 1.2001 - val_accuracy: 0.6458\n",
            "Epoch 228/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8350 - accuracy: 0.8559 - val_loss: 1.1908 - val_accuracy: 0.6944\n",
            "Epoch 229/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8213 - accuracy: 0.8663 - val_loss: 1.1860 - val_accuracy: 0.6806\n",
            "Epoch 230/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8181 - accuracy: 0.8594 - val_loss: 1.1891 - val_accuracy: 0.6806\n",
            "Epoch 231/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8050 - accuracy: 0.8785 - val_loss: 1.1803 - val_accuracy: 0.7083\n",
            "Epoch 232/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8078 - accuracy: 0.8646 - val_loss: 1.1948 - val_accuracy: 0.6875\n",
            "Epoch 233/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8195 - accuracy: 0.8819 - val_loss: 1.1988 - val_accuracy: 0.6944\n",
            "Epoch 234/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8363 - accuracy: 0.8663 - val_loss: 1.1807 - val_accuracy: 0.7014\n",
            "Epoch 235/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.8022 - accuracy: 0.8681 - val_loss: 1.1769 - val_accuracy: 0.6944\n",
            "Epoch 236/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8227 - accuracy: 0.8663 - val_loss: 1.1873 - val_accuracy: 0.6875\n",
            "Epoch 237/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8319 - accuracy: 0.8611 - val_loss: 1.1793 - val_accuracy: 0.6736\n",
            "Epoch 238/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8022 - accuracy: 0.8785 - val_loss: 1.1965 - val_accuracy: 0.6458\n",
            "Epoch 239/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.8016 - accuracy: 0.8889 - val_loss: 1.1863 - val_accuracy: 0.6667\n",
            "Epoch 240/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.8192 - accuracy: 0.8646 - val_loss: 1.1806 - val_accuracy: 0.6944\n",
            "Epoch 241/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7921 - accuracy: 0.8750 - val_loss: 1.1716 - val_accuracy: 0.6875\n",
            "Epoch 242/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.8032 - accuracy: 0.8837 - val_loss: 1.1793 - val_accuracy: 0.6806\n",
            "Epoch 243/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8249 - accuracy: 0.8646 - val_loss: 1.1858 - val_accuracy: 0.6736\n",
            "Epoch 244/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.8144 - accuracy: 0.8542 - val_loss: 1.1634 - val_accuracy: 0.7014\n",
            "Epoch 245/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.8154 - accuracy: 0.8559 - val_loss: 1.1688 - val_accuracy: 0.6875\n",
            "Epoch 246/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8078 - accuracy: 0.8698 - val_loss: 1.1705 - val_accuracy: 0.6944\n",
            "Epoch 247/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8039 - accuracy: 0.8733 - val_loss: 1.1709 - val_accuracy: 0.6806\n",
            "Epoch 248/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.8052 - accuracy: 0.8750 - val_loss: 1.1731 - val_accuracy: 0.6667\n",
            "Epoch 249/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7887 - accuracy: 0.8611 - val_loss: 1.1561 - val_accuracy: 0.6875\n",
            "Epoch 250/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7872 - accuracy: 0.8750 - val_loss: 1.1627 - val_accuracy: 0.6875\n",
            "Epoch 251/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7968 - accuracy: 0.8837 - val_loss: 1.1579 - val_accuracy: 0.6875\n",
            "Epoch 252/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.8117 - accuracy: 0.8646 - val_loss: 1.1667 - val_accuracy: 0.7083\n",
            "Epoch 253/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.8024 - accuracy: 0.8646 - val_loss: 1.1755 - val_accuracy: 0.6944\n",
            "Epoch 254/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7698 - accuracy: 0.9080 - val_loss: 1.1713 - val_accuracy: 0.6875\n",
            "Epoch 255/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7859 - accuracy: 0.8819 - val_loss: 1.1827 - val_accuracy: 0.6597\n",
            "Epoch 256/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7823 - accuracy: 0.8663 - val_loss: 1.1805 - val_accuracy: 0.6667\n",
            "Epoch 257/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.8073 - accuracy: 0.8785 - val_loss: 1.1670 - val_accuracy: 0.6806\n",
            "Epoch 258/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.8028 - accuracy: 0.8663 - val_loss: 1.1713 - val_accuracy: 0.6875\n",
            "Epoch 259/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7691 - accuracy: 0.8872 - val_loss: 1.1547 - val_accuracy: 0.7014\n",
            "Epoch 260/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7846 - accuracy: 0.8958 - val_loss: 1.1624 - val_accuracy: 0.6875\n",
            "Epoch 261/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7908 - accuracy: 0.8872 - val_loss: 1.1772 - val_accuracy: 0.7014\n",
            "Epoch 262/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7874 - accuracy: 0.8837 - val_loss: 1.1608 - val_accuracy: 0.7014\n",
            "Epoch 263/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7812 - accuracy: 0.8924 - val_loss: 1.1793 - val_accuracy: 0.6875\n",
            "Epoch 264/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7946 - accuracy: 0.8594 - val_loss: 1.1651 - val_accuracy: 0.7014\n",
            "Epoch 265/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7928 - accuracy: 0.8785 - val_loss: 1.1635 - val_accuracy: 0.7014\n",
            "Epoch 266/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7763 - accuracy: 0.8958 - val_loss: 1.1629 - val_accuracy: 0.7014\n",
            "Epoch 267/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7558 - accuracy: 0.8993 - val_loss: 1.1675 - val_accuracy: 0.6944\n",
            "Epoch 268/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7691 - accuracy: 0.8872 - val_loss: 1.1687 - val_accuracy: 0.6667\n",
            "Epoch 269/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7930 - accuracy: 0.8819 - val_loss: 1.1623 - val_accuracy: 0.6875\n",
            "Epoch 270/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7741 - accuracy: 0.8785 - val_loss: 1.1765 - val_accuracy: 0.6736\n",
            "Epoch 271/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7572 - accuracy: 0.8889 - val_loss: 1.1764 - val_accuracy: 0.6806\n",
            "Epoch 272/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7713 - accuracy: 0.8941 - val_loss: 1.1634 - val_accuracy: 0.6736\n",
            "Epoch 273/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7732 - accuracy: 0.8906 - val_loss: 1.1495 - val_accuracy: 0.7153\n",
            "Epoch 274/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7631 - accuracy: 0.8976 - val_loss: 1.1534 - val_accuracy: 0.6944\n",
            "Epoch 275/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7582 - accuracy: 0.8767 - val_loss: 1.1513 - val_accuracy: 0.7014\n",
            "Epoch 276/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7701 - accuracy: 0.8941 - val_loss: 1.1555 - val_accuracy: 0.6875\n",
            "Epoch 277/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7533 - accuracy: 0.9028 - val_loss: 1.1534 - val_accuracy: 0.6875\n",
            "Epoch 278/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7443 - accuracy: 0.9236 - val_loss: 1.1522 - val_accuracy: 0.7083\n",
            "Epoch 279/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7523 - accuracy: 0.9062 - val_loss: 1.1662 - val_accuracy: 0.6875\n",
            "Epoch 280/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7608 - accuracy: 0.8924 - val_loss: 1.1410 - val_accuracy: 0.7083\n",
            "Epoch 281/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7482 - accuracy: 0.8958 - val_loss: 1.1506 - val_accuracy: 0.7014\n",
            "Epoch 282/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7578 - accuracy: 0.9080 - val_loss: 1.1575 - val_accuracy: 0.6875\n",
            "Epoch 283/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7649 - accuracy: 0.8872 - val_loss: 1.1491 - val_accuracy: 0.7153\n",
            "Epoch 284/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7470 - accuracy: 0.9080 - val_loss: 1.1588 - val_accuracy: 0.7014\n",
            "Epoch 285/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7495 - accuracy: 0.9097 - val_loss: 1.1523 - val_accuracy: 0.7153\n",
            "Epoch 286/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7643 - accuracy: 0.8872 - val_loss: 1.1578 - val_accuracy: 0.7014\n",
            "Epoch 287/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7417 - accuracy: 0.9115 - val_loss: 1.1553 - val_accuracy: 0.7014\n",
            "Epoch 288/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7339 - accuracy: 0.9132 - val_loss: 1.1504 - val_accuracy: 0.7014\n",
            "Epoch 289/700\n",
            "9/9 [==============================] - 1s 119ms/step - loss: 0.7393 - accuracy: 0.9010 - val_loss: 1.1544 - val_accuracy: 0.7014\n",
            "Epoch 290/700\n",
            "9/9 [==============================] - 1s 117ms/step - loss: 0.7506 - accuracy: 0.8993 - val_loss: 1.1695 - val_accuracy: 0.6806\n",
            "Epoch 291/700\n",
            "9/9 [==============================] - 1s 113ms/step - loss: 0.7418 - accuracy: 0.9115 - val_loss: 1.1516 - val_accuracy: 0.6944\n",
            "Epoch 292/700\n",
            "9/9 [==============================] - 1s 108ms/step - loss: 0.7526 - accuracy: 0.9028 - val_loss: 1.1584 - val_accuracy: 0.7153\n",
            "Epoch 293/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7133 - accuracy: 0.9271 - val_loss: 1.1569 - val_accuracy: 0.6875\n",
            "Epoch 294/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7632 - accuracy: 0.8889 - val_loss: 1.1507 - val_accuracy: 0.6875\n",
            "Epoch 295/700\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7233 - accuracy: 0.9201 - val_loss: 1.1650 - val_accuracy: 0.7014\n",
            "Epoch 296/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7236 - accuracy: 0.9253 - val_loss: 1.1597 - val_accuracy: 0.6806\n",
            "Epoch 297/700\n",
            "9/9 [==============================] - 1s 109ms/step - loss: 0.7296 - accuracy: 0.9219 - val_loss: 1.1516 - val_accuracy: 0.6944\n",
            "Epoch 298/700\n",
            "9/9 [==============================] - 1s 115ms/step - loss: 0.7316 - accuracy: 0.9288 - val_loss: 1.1494 - val_accuracy: 0.6875\n",
            "Epoch 299/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.7278 - accuracy: 0.9149 - val_loss: 1.1493 - val_accuracy: 0.7014\n",
            "Epoch 300/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7474 - accuracy: 0.9028 - val_loss: 1.1559 - val_accuracy: 0.6944\n",
            "Epoch 301/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7403 - accuracy: 0.9097 - val_loss: 1.1543 - val_accuracy: 0.6806\n",
            "Epoch 302/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7360 - accuracy: 0.9080 - val_loss: 1.1608 - val_accuracy: 0.6944\n",
            "Epoch 303/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7173 - accuracy: 0.9184 - val_loss: 1.1460 - val_accuracy: 0.7153\n",
            "Epoch 304/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7295 - accuracy: 0.9236 - val_loss: 1.1381 - val_accuracy: 0.7361\n",
            "Epoch 305/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7267 - accuracy: 0.9184 - val_loss: 1.1397 - val_accuracy: 0.7222\n",
            "Epoch 306/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.7224 - accuracy: 0.9236 - val_loss: 1.1330 - val_accuracy: 0.7083\n",
            "Epoch 307/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7224 - accuracy: 0.9132 - val_loss: 1.1382 - val_accuracy: 0.7014\n",
            "Epoch 308/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7434 - accuracy: 0.8958 - val_loss: 1.1570 - val_accuracy: 0.7153\n",
            "Epoch 309/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7044 - accuracy: 0.9306 - val_loss: 1.1541 - val_accuracy: 0.7153\n",
            "Epoch 310/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7136 - accuracy: 0.9149 - val_loss: 1.1332 - val_accuracy: 0.7361\n",
            "Epoch 311/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7170 - accuracy: 0.9306 - val_loss: 1.1505 - val_accuracy: 0.7083\n",
            "Epoch 312/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7062 - accuracy: 0.9340 - val_loss: 1.1468 - val_accuracy: 0.7153\n",
            "Epoch 313/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7049 - accuracy: 0.9358 - val_loss: 1.1445 - val_accuracy: 0.7083\n",
            "Epoch 314/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7299 - accuracy: 0.9132 - val_loss: 1.1338 - val_accuracy: 0.7292\n",
            "Epoch 315/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7180 - accuracy: 0.9097 - val_loss: 1.1474 - val_accuracy: 0.7292\n",
            "Epoch 316/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.7054 - accuracy: 0.9045 - val_loss: 1.1356 - val_accuracy: 0.7292\n",
            "Epoch 317/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7191 - accuracy: 0.9149 - val_loss: 1.1381 - val_accuracy: 0.7361\n",
            "Epoch 318/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7082 - accuracy: 0.9323 - val_loss: 1.1331 - val_accuracy: 0.7222\n",
            "Epoch 319/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7293 - accuracy: 0.9010 - val_loss: 1.1405 - val_accuracy: 0.7014\n",
            "Epoch 320/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7043 - accuracy: 0.9271 - val_loss: 1.1382 - val_accuracy: 0.7292\n",
            "Epoch 321/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.7055 - accuracy: 0.9253 - val_loss: 1.1260 - val_accuracy: 0.7083\n",
            "Epoch 322/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.7138 - accuracy: 0.9167 - val_loss: 1.1191 - val_accuracy: 0.7222\n",
            "Epoch 323/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6977 - accuracy: 0.9253 - val_loss: 1.1386 - val_accuracy: 0.7014\n",
            "Epoch 324/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7328 - accuracy: 0.9219 - val_loss: 1.1276 - val_accuracy: 0.7292\n",
            "Epoch 325/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.7081 - accuracy: 0.9097 - val_loss: 1.1249 - val_accuracy: 0.7153\n",
            "Epoch 326/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6928 - accuracy: 0.9427 - val_loss: 1.1349 - val_accuracy: 0.7083\n",
            "Epoch 327/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.7124 - accuracy: 0.9080 - val_loss: 1.1278 - val_accuracy: 0.7153\n",
            "Epoch 328/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6984 - accuracy: 0.9306 - val_loss: 1.1264 - val_accuracy: 0.7014\n",
            "Epoch 329/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7048 - accuracy: 0.9271 - val_loss: 1.1444 - val_accuracy: 0.7014\n",
            "Epoch 330/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.7060 - accuracy: 0.9184 - val_loss: 1.1324 - val_accuracy: 0.7083\n",
            "Epoch 331/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7028 - accuracy: 0.9219 - val_loss: 1.1181 - val_accuracy: 0.7222\n",
            "Epoch 332/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.7065 - accuracy: 0.9271 - val_loss: 1.1234 - val_accuracy: 0.7083\n",
            "Epoch 333/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6824 - accuracy: 0.9427 - val_loss: 1.1187 - val_accuracy: 0.7083\n",
            "Epoch 334/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.7007 - accuracy: 0.9167 - val_loss: 1.1343 - val_accuracy: 0.7083\n",
            "Epoch 335/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6912 - accuracy: 0.9219 - val_loss: 1.1290 - val_accuracy: 0.7153\n",
            "Epoch 336/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6969 - accuracy: 0.9306 - val_loss: 1.1388 - val_accuracy: 0.7083\n",
            "Epoch 337/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6830 - accuracy: 0.9288 - val_loss: 1.1385 - val_accuracy: 0.7222\n",
            "Epoch 338/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6816 - accuracy: 0.9340 - val_loss: 1.1309 - val_accuracy: 0.7014\n",
            "Epoch 339/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6926 - accuracy: 0.9271 - val_loss: 1.1327 - val_accuracy: 0.7153\n",
            "Epoch 340/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6969 - accuracy: 0.9306 - val_loss: 1.1174 - val_accuracy: 0.7292\n",
            "Epoch 341/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6968 - accuracy: 0.9340 - val_loss: 1.1162 - val_accuracy: 0.7500\n",
            "Epoch 342/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6871 - accuracy: 0.9375 - val_loss: 1.1179 - val_accuracy: 0.7361\n",
            "Epoch 343/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6925 - accuracy: 0.9392 - val_loss: 1.1129 - val_accuracy: 0.7083\n",
            "Epoch 344/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6784 - accuracy: 0.9410 - val_loss: 1.1183 - val_accuracy: 0.7014\n",
            "Epoch 345/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6898 - accuracy: 0.9201 - val_loss: 1.1194 - val_accuracy: 0.7431\n",
            "Epoch 346/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6864 - accuracy: 0.9323 - val_loss: 1.1311 - val_accuracy: 0.7083\n",
            "Epoch 347/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6920 - accuracy: 0.9219 - val_loss: 1.1159 - val_accuracy: 0.7361\n",
            "Epoch 348/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6883 - accuracy: 0.9271 - val_loss: 1.1233 - val_accuracy: 0.7361\n",
            "Epoch 349/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6799 - accuracy: 0.9392 - val_loss: 1.1295 - val_accuracy: 0.7083\n",
            "Epoch 350/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6836 - accuracy: 0.9167 - val_loss: 1.1202 - val_accuracy: 0.7500\n",
            "Epoch 351/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6812 - accuracy: 0.9427 - val_loss: 1.1276 - val_accuracy: 0.7222\n",
            "Epoch 352/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6819 - accuracy: 0.9253 - val_loss: 1.1202 - val_accuracy: 0.7222\n",
            "Epoch 353/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6759 - accuracy: 0.9479 - val_loss: 1.1191 - val_accuracy: 0.7153\n",
            "Epoch 354/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6637 - accuracy: 0.9566 - val_loss: 1.1376 - val_accuracy: 0.7222\n",
            "Epoch 355/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6556 - accuracy: 0.9479 - val_loss: 1.1334 - val_accuracy: 0.7153\n",
            "Epoch 356/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6696 - accuracy: 0.9497 - val_loss: 1.1374 - val_accuracy: 0.7222\n",
            "Epoch 357/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6846 - accuracy: 0.9340 - val_loss: 1.1424 - val_accuracy: 0.6806\n",
            "Epoch 358/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6830 - accuracy: 0.9253 - val_loss: 1.1199 - val_accuracy: 0.7222\n",
            "Epoch 359/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6603 - accuracy: 0.9323 - val_loss: 1.1335 - val_accuracy: 0.7292\n",
            "Epoch 360/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.6656 - accuracy: 0.9462 - val_loss: 1.1430 - val_accuracy: 0.7014\n",
            "Epoch 361/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6641 - accuracy: 0.9479 - val_loss: 1.1352 - val_accuracy: 0.7153\n",
            "Epoch 362/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6792 - accuracy: 0.9323 - val_loss: 1.1345 - val_accuracy: 0.7083\n",
            "Epoch 363/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6516 - accuracy: 0.9549 - val_loss: 1.1362 - val_accuracy: 0.7083\n",
            "Epoch 364/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6704 - accuracy: 0.9410 - val_loss: 1.1221 - val_accuracy: 0.7222\n",
            "Epoch 365/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6744 - accuracy: 0.9392 - val_loss: 1.1315 - val_accuracy: 0.7361\n",
            "Epoch 366/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6637 - accuracy: 0.9497 - val_loss: 1.1242 - val_accuracy: 0.7292\n",
            "Epoch 367/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6712 - accuracy: 0.9410 - val_loss: 1.1128 - val_accuracy: 0.7500\n",
            "Epoch 368/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6742 - accuracy: 0.9497 - val_loss: 1.1176 - val_accuracy: 0.7153\n",
            "Epoch 369/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6653 - accuracy: 0.9549 - val_loss: 1.1106 - val_accuracy: 0.7292\n",
            "Epoch 370/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6474 - accuracy: 0.9601 - val_loss: 1.1196 - val_accuracy: 0.7361\n",
            "Epoch 371/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6487 - accuracy: 0.9444 - val_loss: 1.1078 - val_accuracy: 0.7569\n",
            "Epoch 372/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6539 - accuracy: 0.9462 - val_loss: 1.1067 - val_accuracy: 0.7569\n",
            "Epoch 373/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6477 - accuracy: 0.9358 - val_loss: 1.1065 - val_accuracy: 0.7361\n",
            "Epoch 374/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6485 - accuracy: 0.9479 - val_loss: 1.1197 - val_accuracy: 0.7431\n",
            "Epoch 375/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6449 - accuracy: 0.9444 - val_loss: 1.1261 - val_accuracy: 0.7431\n",
            "Epoch 376/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6404 - accuracy: 0.9601 - val_loss: 1.1179 - val_accuracy: 0.7431\n",
            "Epoch 377/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6399 - accuracy: 0.9566 - val_loss: 1.1243 - val_accuracy: 0.7500\n",
            "Epoch 378/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6615 - accuracy: 0.9358 - val_loss: 1.1162 - val_accuracy: 0.7431\n",
            "Epoch 379/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6484 - accuracy: 0.9410 - val_loss: 1.1208 - val_accuracy: 0.7361\n",
            "Epoch 380/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6575 - accuracy: 0.9462 - val_loss: 1.1142 - val_accuracy: 0.7431\n",
            "Epoch 381/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6694 - accuracy: 0.9427 - val_loss: 1.1061 - val_accuracy: 0.7292\n",
            "Epoch 382/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6416 - accuracy: 0.9618 - val_loss: 1.1095 - val_accuracy: 0.7431\n",
            "Epoch 383/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6391 - accuracy: 0.9479 - val_loss: 1.1225 - val_accuracy: 0.7639\n",
            "Epoch 384/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6553 - accuracy: 0.9427 - val_loss: 1.1183 - val_accuracy: 0.7361\n",
            "Epoch 385/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6402 - accuracy: 0.9514 - val_loss: 1.1273 - val_accuracy: 0.7222\n",
            "Epoch 386/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6471 - accuracy: 0.9479 - val_loss: 1.1080 - val_accuracy: 0.7431\n",
            "Epoch 387/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6466 - accuracy: 0.9392 - val_loss: 1.1318 - val_accuracy: 0.7222\n",
            "Epoch 388/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6438 - accuracy: 0.9479 - val_loss: 1.1196 - val_accuracy: 0.7292\n",
            "Epoch 389/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6404 - accuracy: 0.9497 - val_loss: 1.1257 - val_accuracy: 0.7222\n",
            "Epoch 390/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6430 - accuracy: 0.9601 - val_loss: 1.1125 - val_accuracy: 0.7361\n",
            "Epoch 391/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6487 - accuracy: 0.9479 - val_loss: 1.1141 - val_accuracy: 0.7569\n",
            "Epoch 392/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6412 - accuracy: 0.9497 - val_loss: 1.1169 - val_accuracy: 0.7292\n",
            "Epoch 393/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6291 - accuracy: 0.9531 - val_loss: 1.1092 - val_accuracy: 0.7500\n",
            "Epoch 394/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6324 - accuracy: 0.9549 - val_loss: 1.1285 - val_accuracy: 0.7292\n",
            "Epoch 395/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6267 - accuracy: 0.9688 - val_loss: 1.1183 - val_accuracy: 0.7500\n",
            "Epoch 396/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6390 - accuracy: 0.9549 - val_loss: 1.1112 - val_accuracy: 0.7431\n",
            "Epoch 397/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6347 - accuracy: 0.9566 - val_loss: 1.1140 - val_accuracy: 0.7361\n",
            "Epoch 398/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6271 - accuracy: 0.9583 - val_loss: 1.1223 - val_accuracy: 0.7361\n",
            "Epoch 399/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6483 - accuracy: 0.9375 - val_loss: 1.1235 - val_accuracy: 0.7153\n",
            "Epoch 400/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6543 - accuracy: 0.9531 - val_loss: 1.1136 - val_accuracy: 0.7500\n",
            "Epoch 401/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6348 - accuracy: 0.9531 - val_loss: 1.1208 - val_accuracy: 0.7361\n",
            "Epoch 402/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.6320 - accuracy: 0.9618 - val_loss: 1.1191 - val_accuracy: 0.7361\n",
            "Epoch 403/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6150 - accuracy: 0.9514 - val_loss: 1.1102 - val_accuracy: 0.7431\n",
            "Epoch 404/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6371 - accuracy: 0.9618 - val_loss: 1.1258 - val_accuracy: 0.7222\n",
            "Epoch 405/700\n",
            "9/9 [==============================] - 1s 94ms/step - loss: 0.6346 - accuracy: 0.9583 - val_loss: 1.1260 - val_accuracy: 0.7222\n",
            "Epoch 406/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6242 - accuracy: 0.9531 - val_loss: 1.1181 - val_accuracy: 0.7083\n",
            "Epoch 407/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6329 - accuracy: 0.9583 - val_loss: 1.1006 - val_accuracy: 0.7569\n",
            "Epoch 408/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6335 - accuracy: 0.9392 - val_loss: 1.1122 - val_accuracy: 0.7153\n",
            "Epoch 409/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6293 - accuracy: 0.9705 - val_loss: 1.1005 - val_accuracy: 0.7292\n",
            "Epoch 410/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6386 - accuracy: 0.9583 - val_loss: 1.1143 - val_accuracy: 0.7292\n",
            "Epoch 411/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6143 - accuracy: 0.9670 - val_loss: 1.0960 - val_accuracy: 0.7292\n",
            "Epoch 412/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6230 - accuracy: 0.9601 - val_loss: 1.0906 - val_accuracy: 0.7569\n",
            "Epoch 413/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6179 - accuracy: 0.9583 - val_loss: 1.1086 - val_accuracy: 0.7361\n",
            "Epoch 414/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6442 - accuracy: 0.9392 - val_loss: 1.1096 - val_accuracy: 0.7292\n",
            "Epoch 415/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6386 - accuracy: 0.9444 - val_loss: 1.1117 - val_accuracy: 0.7292\n",
            "Epoch 416/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6106 - accuracy: 0.9635 - val_loss: 1.1019 - val_accuracy: 0.7361\n",
            "Epoch 417/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6175 - accuracy: 0.9531 - val_loss: 1.1075 - val_accuracy: 0.7222\n",
            "Epoch 418/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6420 - accuracy: 0.9531 - val_loss: 1.1130 - val_accuracy: 0.7153\n",
            "Epoch 419/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6331 - accuracy: 0.9514 - val_loss: 1.1095 - val_accuracy: 0.7292\n",
            "Epoch 420/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6106 - accuracy: 0.9653 - val_loss: 1.0962 - val_accuracy: 0.7361\n",
            "Epoch 421/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5985 - accuracy: 0.9722 - val_loss: 1.1089 - val_accuracy: 0.7292\n",
            "Epoch 422/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6102 - accuracy: 0.9705 - val_loss: 1.1041 - val_accuracy: 0.7153\n",
            "Epoch 423/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6288 - accuracy: 0.9531 - val_loss: 1.1046 - val_accuracy: 0.7431\n",
            "Epoch 424/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.6245 - accuracy: 0.9618 - val_loss: 1.1248 - val_accuracy: 0.7014\n",
            "Epoch 425/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6196 - accuracy: 0.9722 - val_loss: 1.1250 - val_accuracy: 0.7083\n",
            "Epoch 426/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6175 - accuracy: 0.9618 - val_loss: 1.1155 - val_accuracy: 0.7153\n",
            "Epoch 427/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6343 - accuracy: 0.9566 - val_loss: 1.1078 - val_accuracy: 0.7361\n",
            "Epoch 428/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.6032 - accuracy: 0.9549 - val_loss: 1.1273 - val_accuracy: 0.7222\n",
            "Epoch 429/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6222 - accuracy: 0.9618 - val_loss: 1.1182 - val_accuracy: 0.7222\n",
            "Epoch 430/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6218 - accuracy: 0.9670 - val_loss: 1.1181 - val_accuracy: 0.7361\n",
            "Epoch 431/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6220 - accuracy: 0.9462 - val_loss: 1.1128 - val_accuracy: 0.7222\n",
            "Epoch 432/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.6155 - accuracy: 0.9583 - val_loss: 1.1193 - val_accuracy: 0.7292\n",
            "Epoch 433/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.6231 - accuracy: 0.9601 - val_loss: 1.0973 - val_accuracy: 0.7569\n",
            "Epoch 434/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6104 - accuracy: 0.9670 - val_loss: 1.0977 - val_accuracy: 0.7639\n",
            "Epoch 435/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5828 - accuracy: 0.9705 - val_loss: 1.1134 - val_accuracy: 0.7431\n",
            "Epoch 436/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6025 - accuracy: 0.9722 - val_loss: 1.0925 - val_accuracy: 0.7361\n",
            "Epoch 437/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5982 - accuracy: 0.9774 - val_loss: 1.0975 - val_accuracy: 0.7292\n",
            "Epoch 438/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.6011 - accuracy: 0.9688 - val_loss: 1.1020 - val_accuracy: 0.7569\n",
            "Epoch 439/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6172 - accuracy: 0.9566 - val_loss: 1.0984 - val_accuracy: 0.7431\n",
            "Epoch 440/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.6108 - accuracy: 0.9653 - val_loss: 1.1027 - val_accuracy: 0.7153\n",
            "Epoch 441/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5972 - accuracy: 0.9635 - val_loss: 1.0924 - val_accuracy: 0.7083\n",
            "Epoch 442/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.6061 - accuracy: 0.9549 - val_loss: 1.0789 - val_accuracy: 0.7361\n",
            "Epoch 443/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6113 - accuracy: 0.9618 - val_loss: 1.0927 - val_accuracy: 0.7569\n",
            "Epoch 444/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5937 - accuracy: 0.9792 - val_loss: 1.0928 - val_accuracy: 0.7500\n",
            "Epoch 445/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5998 - accuracy: 0.9705 - val_loss: 1.0969 - val_accuracy: 0.7361\n",
            "Epoch 446/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.6139 - accuracy: 0.9601 - val_loss: 1.1084 - val_accuracy: 0.7222\n",
            "Epoch 447/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5955 - accuracy: 0.9705 - val_loss: 1.1020 - val_accuracy: 0.7431\n",
            "Epoch 448/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5924 - accuracy: 0.9670 - val_loss: 1.0942 - val_accuracy: 0.7500\n",
            "Epoch 449/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5931 - accuracy: 0.9618 - val_loss: 1.0879 - val_accuracy: 0.7500\n",
            "Epoch 450/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5984 - accuracy: 0.9688 - val_loss: 1.0844 - val_accuracy: 0.7500\n",
            "Epoch 451/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5979 - accuracy: 0.9653 - val_loss: 1.1039 - val_accuracy: 0.7292\n",
            "Epoch 452/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5973 - accuracy: 0.9774 - val_loss: 1.0942 - val_accuracy: 0.7500\n",
            "Epoch 453/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5940 - accuracy: 0.9740 - val_loss: 1.1037 - val_accuracy: 0.7361\n",
            "Epoch 454/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5803 - accuracy: 0.9740 - val_loss: 1.0972 - val_accuracy: 0.7292\n",
            "Epoch 455/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5946 - accuracy: 0.9774 - val_loss: 1.0999 - val_accuracy: 0.7083\n",
            "Epoch 456/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5924 - accuracy: 0.9635 - val_loss: 1.0979 - val_accuracy: 0.7431\n",
            "Epoch 457/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5990 - accuracy: 0.9653 - val_loss: 1.1200 - val_accuracy: 0.7153\n",
            "Epoch 458/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5986 - accuracy: 0.9653 - val_loss: 1.1033 - val_accuracy: 0.7292\n",
            "Epoch 459/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5865 - accuracy: 0.9583 - val_loss: 1.0949 - val_accuracy: 0.7361\n",
            "Epoch 460/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.6089 - accuracy: 0.9722 - val_loss: 1.0998 - val_accuracy: 0.7361\n",
            "Epoch 461/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5825 - accuracy: 0.9740 - val_loss: 1.0964 - val_accuracy: 0.7431\n",
            "Epoch 462/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5834 - accuracy: 0.9792 - val_loss: 1.1139 - val_accuracy: 0.7014\n",
            "Epoch 463/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5917 - accuracy: 0.9635 - val_loss: 1.0762 - val_accuracy: 0.7500\n",
            "Epoch 464/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5848 - accuracy: 0.9740 - val_loss: 1.1051 - val_accuracy: 0.7222\n",
            "Epoch 465/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5921 - accuracy: 0.9722 - val_loss: 1.0837 - val_accuracy: 0.7500\n",
            "Epoch 466/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5923 - accuracy: 0.9670 - val_loss: 1.0891 - val_accuracy: 0.7431\n",
            "Epoch 467/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.6021 - accuracy: 0.9635 - val_loss: 1.0913 - val_accuracy: 0.7361\n",
            "Epoch 468/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5734 - accuracy: 0.9809 - val_loss: 1.0835 - val_accuracy: 0.7639\n",
            "Epoch 469/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5827 - accuracy: 0.9809 - val_loss: 1.0862 - val_accuracy: 0.7361\n",
            "Epoch 470/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5709 - accuracy: 0.9844 - val_loss: 1.1009 - val_accuracy: 0.7292\n",
            "Epoch 471/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5861 - accuracy: 0.9792 - val_loss: 1.1069 - val_accuracy: 0.7361\n",
            "Epoch 472/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5743 - accuracy: 0.9809 - val_loss: 1.0961 - val_accuracy: 0.7500\n",
            "Epoch 473/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5826 - accuracy: 0.9740 - val_loss: 1.0808 - val_accuracy: 0.7708\n",
            "Epoch 474/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5816 - accuracy: 0.9705 - val_loss: 1.0926 - val_accuracy: 0.7361\n",
            "Epoch 475/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5734 - accuracy: 0.9740 - val_loss: 1.0900 - val_accuracy: 0.7361\n",
            "Epoch 476/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5713 - accuracy: 0.9705 - val_loss: 1.0976 - val_accuracy: 0.7500\n",
            "Epoch 477/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5885 - accuracy: 0.9688 - val_loss: 1.0881 - val_accuracy: 0.7639\n",
            "Epoch 478/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5854 - accuracy: 0.9722 - val_loss: 1.0887 - val_accuracy: 0.7292\n",
            "Epoch 479/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5919 - accuracy: 0.9635 - val_loss: 1.1008 - val_accuracy: 0.7153\n",
            "Epoch 480/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5731 - accuracy: 0.9722 - val_loss: 1.0876 - val_accuracy: 0.7500\n",
            "Epoch 481/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5743 - accuracy: 0.9792 - val_loss: 1.0946 - val_accuracy: 0.7361\n",
            "Epoch 482/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5840 - accuracy: 0.9601 - val_loss: 1.1156 - val_accuracy: 0.7153\n",
            "Epoch 483/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5748 - accuracy: 0.9705 - val_loss: 1.0856 - val_accuracy: 0.7569\n",
            "Epoch 484/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5770 - accuracy: 0.9740 - val_loss: 1.0896 - val_accuracy: 0.7500\n",
            "Epoch 485/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5700 - accuracy: 0.9844 - val_loss: 1.0844 - val_accuracy: 0.7361\n",
            "Epoch 486/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5719 - accuracy: 0.9757 - val_loss: 1.0945 - val_accuracy: 0.7431\n",
            "Epoch 487/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5544 - accuracy: 0.9826 - val_loss: 1.0884 - val_accuracy: 0.7500\n",
            "Epoch 488/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5796 - accuracy: 0.9653 - val_loss: 1.0809 - val_accuracy: 0.7569\n",
            "Epoch 489/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5756 - accuracy: 0.9653 - val_loss: 1.0846 - val_accuracy: 0.7639\n",
            "Epoch 490/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5841 - accuracy: 0.9774 - val_loss: 1.0780 - val_accuracy: 0.7639\n",
            "Epoch 491/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5671 - accuracy: 0.9844 - val_loss: 1.0947 - val_accuracy: 0.7431\n",
            "Epoch 492/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5619 - accuracy: 0.9774 - val_loss: 1.0852 - val_accuracy: 0.7361\n",
            "Epoch 493/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5740 - accuracy: 0.9757 - val_loss: 1.0920 - val_accuracy: 0.7500\n",
            "Epoch 494/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5757 - accuracy: 0.9757 - val_loss: 1.0957 - val_accuracy: 0.7361\n",
            "Epoch 495/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5742 - accuracy: 0.9740 - val_loss: 1.0975 - val_accuracy: 0.7361\n",
            "Epoch 496/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5711 - accuracy: 0.9774 - val_loss: 1.0961 - val_accuracy: 0.7500\n",
            "Epoch 497/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5629 - accuracy: 0.9740 - val_loss: 1.0951 - val_accuracy: 0.7500\n",
            "Epoch 498/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5590 - accuracy: 0.9792 - val_loss: 1.0822 - val_accuracy: 0.7431\n",
            "Epoch 499/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5492 - accuracy: 0.9861 - val_loss: 1.0857 - val_accuracy: 0.7569\n",
            "Epoch 500/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5723 - accuracy: 0.9757 - val_loss: 1.0890 - val_accuracy: 0.7431\n",
            "Epoch 501/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5571 - accuracy: 0.9774 - val_loss: 1.0863 - val_accuracy: 0.7292\n",
            "Epoch 502/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5702 - accuracy: 0.9757 - val_loss: 1.1035 - val_accuracy: 0.7222\n",
            "Epoch 503/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5490 - accuracy: 0.9792 - val_loss: 1.0894 - val_accuracy: 0.7431\n",
            "Epoch 504/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5826 - accuracy: 0.9583 - val_loss: 1.0833 - val_accuracy: 0.7569\n",
            "Epoch 505/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5511 - accuracy: 0.9774 - val_loss: 1.0908 - val_accuracy: 0.7431\n",
            "Epoch 506/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5593 - accuracy: 0.9670 - val_loss: 1.0834 - val_accuracy: 0.7500\n",
            "Epoch 507/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5473 - accuracy: 0.9792 - val_loss: 1.0858 - val_accuracy: 0.7431\n",
            "Epoch 508/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5615 - accuracy: 0.9722 - val_loss: 1.0933 - val_accuracy: 0.7361\n",
            "Epoch 509/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5638 - accuracy: 0.9792 - val_loss: 1.0929 - val_accuracy: 0.7361\n",
            "Epoch 510/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5360 - accuracy: 0.9844 - val_loss: 1.0949 - val_accuracy: 0.7500\n",
            "Epoch 511/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5633 - accuracy: 0.9809 - val_loss: 1.0987 - val_accuracy: 0.7500\n",
            "Epoch 512/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5461 - accuracy: 0.9913 - val_loss: 1.0912 - val_accuracy: 0.7639\n",
            "Epoch 513/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5713 - accuracy: 0.9722 - val_loss: 1.0913 - val_accuracy: 0.7431\n",
            "Epoch 514/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5595 - accuracy: 0.9740 - val_loss: 1.0904 - val_accuracy: 0.7292\n",
            "Epoch 515/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5737 - accuracy: 0.9774 - val_loss: 1.0930 - val_accuracy: 0.7153\n",
            "Epoch 516/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5697 - accuracy: 0.9740 - val_loss: 1.0773 - val_accuracy: 0.7500\n",
            "Epoch 517/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5672 - accuracy: 0.9792 - val_loss: 1.0855 - val_accuracy: 0.7431\n",
            "Epoch 518/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5436 - accuracy: 0.9844 - val_loss: 1.0841 - val_accuracy: 0.7639\n",
            "Epoch 519/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5778 - accuracy: 0.9740 - val_loss: 1.0793 - val_accuracy: 0.7569\n",
            "Epoch 520/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5768 - accuracy: 0.9722 - val_loss: 1.0859 - val_accuracy: 0.7569\n",
            "Epoch 521/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5537 - accuracy: 0.9861 - val_loss: 1.0953 - val_accuracy: 0.7361\n",
            "Epoch 522/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5603 - accuracy: 0.9757 - val_loss: 1.0965 - val_accuracy: 0.7153\n",
            "Epoch 523/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5515 - accuracy: 0.9792 - val_loss: 1.1031 - val_accuracy: 0.7222\n",
            "Epoch 524/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5501 - accuracy: 0.9809 - val_loss: 1.0834 - val_accuracy: 0.7500\n",
            "Epoch 525/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5404 - accuracy: 0.9809 - val_loss: 1.0881 - val_accuracy: 0.7569\n",
            "Epoch 526/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5353 - accuracy: 0.9913 - val_loss: 1.0877 - val_accuracy: 0.7500\n",
            "Epoch 527/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5490 - accuracy: 0.9878 - val_loss: 1.0803 - val_accuracy: 0.7569\n",
            "Epoch 528/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5490 - accuracy: 0.9774 - val_loss: 1.0860 - val_accuracy: 0.7431\n",
            "Epoch 529/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5496 - accuracy: 0.9809 - val_loss: 1.0821 - val_accuracy: 0.7431\n",
            "Epoch 530/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5384 - accuracy: 0.9878 - val_loss: 1.0918 - val_accuracy: 0.7222\n",
            "Epoch 531/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5467 - accuracy: 0.9826 - val_loss: 1.0828 - val_accuracy: 0.7500\n",
            "Epoch 532/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5434 - accuracy: 0.9757 - val_loss: 1.0702 - val_accuracy: 0.7708\n",
            "Epoch 533/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5399 - accuracy: 0.9774 - val_loss: 1.0790 - val_accuracy: 0.7569\n",
            "Epoch 534/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5587 - accuracy: 0.9826 - val_loss: 1.0696 - val_accuracy: 0.7569\n",
            "Epoch 535/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5324 - accuracy: 0.9792 - val_loss: 1.0742 - val_accuracy: 0.7500\n",
            "Epoch 536/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5371 - accuracy: 0.9844 - val_loss: 1.0743 - val_accuracy: 0.7500\n",
            "Epoch 537/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5453 - accuracy: 0.9826 - val_loss: 1.0895 - val_accuracy: 0.7222\n",
            "Epoch 538/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5342 - accuracy: 0.9878 - val_loss: 1.0825 - val_accuracy: 0.7222\n",
            "Epoch 539/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5567 - accuracy: 0.9861 - val_loss: 1.0940 - val_accuracy: 0.7222\n",
            "Epoch 540/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5354 - accuracy: 0.9861 - val_loss: 1.0834 - val_accuracy: 0.7431\n",
            "Epoch 541/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5256 - accuracy: 0.9861 - val_loss: 1.0720 - val_accuracy: 0.7431\n",
            "Epoch 542/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5434 - accuracy: 0.9896 - val_loss: 1.0717 - val_accuracy: 0.7500\n",
            "Epoch 543/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5346 - accuracy: 0.9826 - val_loss: 1.0647 - val_accuracy: 0.7639\n",
            "Epoch 544/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5465 - accuracy: 0.9792 - val_loss: 1.0912 - val_accuracy: 0.7292\n",
            "Epoch 545/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5332 - accuracy: 0.9774 - val_loss: 1.0873 - val_accuracy: 0.7431\n",
            "Epoch 546/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5431 - accuracy: 0.9809 - val_loss: 1.0743 - val_accuracy: 0.7569\n",
            "Epoch 547/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5373 - accuracy: 0.9844 - val_loss: 1.0870 - val_accuracy: 0.7431\n",
            "Epoch 548/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5309 - accuracy: 0.9774 - val_loss: 1.0967 - val_accuracy: 0.7431\n",
            "Epoch 549/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5513 - accuracy: 0.9844 - val_loss: 1.0778 - val_accuracy: 0.7361\n",
            "Epoch 550/700\n",
            "9/9 [==============================] - 1s 107ms/step - loss: 0.5449 - accuracy: 0.9844 - val_loss: 1.0677 - val_accuracy: 0.7500\n",
            "Epoch 551/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5288 - accuracy: 0.9792 - val_loss: 1.0721 - val_accuracy: 0.7569\n",
            "Epoch 552/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5455 - accuracy: 0.9792 - val_loss: 1.0826 - val_accuracy: 0.7431\n",
            "Epoch 553/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5380 - accuracy: 0.9861 - val_loss: 1.0700 - val_accuracy: 0.7569\n",
            "Epoch 554/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5278 - accuracy: 0.9844 - val_loss: 1.0687 - val_accuracy: 0.7569\n",
            "Epoch 555/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5251 - accuracy: 0.9913 - val_loss: 1.0717 - val_accuracy: 0.7500\n",
            "Epoch 556/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5261 - accuracy: 0.9931 - val_loss: 1.0578 - val_accuracy: 0.7500\n",
            "Epoch 557/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5246 - accuracy: 0.9861 - val_loss: 1.0862 - val_accuracy: 0.7431\n",
            "Epoch 558/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5320 - accuracy: 0.9809 - val_loss: 1.0707 - val_accuracy: 0.7569\n",
            "Epoch 559/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5507 - accuracy: 0.9809 - val_loss: 1.0831 - val_accuracy: 0.7361\n",
            "Epoch 560/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5198 - accuracy: 0.9861 - val_loss: 1.0714 - val_accuracy: 0.7708\n",
            "Epoch 561/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5271 - accuracy: 0.9913 - val_loss: 1.0742 - val_accuracy: 0.7569\n",
            "Epoch 562/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5376 - accuracy: 0.9809 - val_loss: 1.0657 - val_accuracy: 0.7708\n",
            "Epoch 563/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5222 - accuracy: 0.9844 - val_loss: 1.0857 - val_accuracy: 0.7222\n",
            "Epoch 564/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5363 - accuracy: 0.9826 - val_loss: 1.0721 - val_accuracy: 0.7569\n",
            "Epoch 565/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5147 - accuracy: 0.9809 - val_loss: 1.0803 - val_accuracy: 0.7292\n",
            "Epoch 566/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5405 - accuracy: 0.9809 - val_loss: 1.0849 - val_accuracy: 0.7361\n",
            "Epoch 567/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5131 - accuracy: 0.9913 - val_loss: 1.0957 - val_accuracy: 0.7222\n",
            "Epoch 568/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5371 - accuracy: 0.9774 - val_loss: 1.0685 - val_accuracy: 0.7431\n",
            "Epoch 569/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5133 - accuracy: 0.9878 - val_loss: 1.0825 - val_accuracy: 0.7361\n",
            "Epoch 570/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5343 - accuracy: 0.9774 - val_loss: 1.0772 - val_accuracy: 0.7222\n",
            "Epoch 571/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5414 - accuracy: 0.9826 - val_loss: 1.0608 - val_accuracy: 0.7708\n",
            "Epoch 572/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5202 - accuracy: 0.9878 - val_loss: 1.0650 - val_accuracy: 0.7292\n",
            "Epoch 573/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5285 - accuracy: 0.9844 - val_loss: 1.0678 - val_accuracy: 0.7431\n",
            "Epoch 574/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5222 - accuracy: 0.9809 - val_loss: 1.0557 - val_accuracy: 0.7569\n",
            "Epoch 575/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5199 - accuracy: 0.9913 - val_loss: 1.0604 - val_accuracy: 0.7361\n",
            "Epoch 576/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5356 - accuracy: 0.9809 - val_loss: 1.0693 - val_accuracy: 0.7500\n",
            "Epoch 577/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5278 - accuracy: 0.9861 - val_loss: 1.0795 - val_accuracy: 0.7292\n",
            "Epoch 578/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5154 - accuracy: 0.9878 - val_loss: 1.0713 - val_accuracy: 0.7639\n",
            "Epoch 579/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5423 - accuracy: 0.9688 - val_loss: 1.0683 - val_accuracy: 0.7500\n",
            "Epoch 580/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5338 - accuracy: 0.9792 - val_loss: 1.0718 - val_accuracy: 0.7431\n",
            "Epoch 581/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5177 - accuracy: 0.9913 - val_loss: 1.0796 - val_accuracy: 0.7361\n",
            "Epoch 582/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5031 - accuracy: 0.9948 - val_loss: 1.0639 - val_accuracy: 0.7639\n",
            "Epoch 583/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5257 - accuracy: 0.9878 - val_loss: 1.0608 - val_accuracy: 0.7569\n",
            "Epoch 584/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5138 - accuracy: 0.9878 - val_loss: 1.0700 - val_accuracy: 0.7639\n",
            "Epoch 585/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5177 - accuracy: 0.9913 - val_loss: 1.0627 - val_accuracy: 0.7569\n",
            "Epoch 586/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5222 - accuracy: 0.9826 - val_loss: 1.0731 - val_accuracy: 0.7431\n",
            "Epoch 587/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5342 - accuracy: 0.9896 - val_loss: 1.0733 - val_accuracy: 0.7500\n",
            "Epoch 588/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5214 - accuracy: 0.9896 - val_loss: 1.0690 - val_accuracy: 0.7500\n",
            "Epoch 589/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5180 - accuracy: 0.9861 - val_loss: 1.0701 - val_accuracy: 0.7500\n",
            "Epoch 590/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5143 - accuracy: 0.9913 - val_loss: 1.0650 - val_accuracy: 0.7431\n",
            "Epoch 591/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5061 - accuracy: 0.9913 - val_loss: 1.0660 - val_accuracy: 0.7431\n",
            "Epoch 592/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5137 - accuracy: 0.9774 - val_loss: 1.0614 - val_accuracy: 0.7639\n",
            "Epoch 593/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5175 - accuracy: 0.9896 - val_loss: 1.0615 - val_accuracy: 0.7569\n",
            "Epoch 594/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5155 - accuracy: 0.9878 - val_loss: 1.0643 - val_accuracy: 0.7639\n",
            "Epoch 595/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5366 - accuracy: 0.9844 - val_loss: 1.0650 - val_accuracy: 0.7431\n",
            "Epoch 596/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5247 - accuracy: 0.9931 - val_loss: 1.0582 - val_accuracy: 0.7708\n",
            "Epoch 597/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5123 - accuracy: 0.9809 - val_loss: 1.0520 - val_accuracy: 0.7569\n",
            "Epoch 598/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5073 - accuracy: 0.9896 - val_loss: 1.0626 - val_accuracy: 0.7431\n",
            "Epoch 599/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5168 - accuracy: 0.9844 - val_loss: 1.0770 - val_accuracy: 0.7431\n",
            "Epoch 600/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5169 - accuracy: 0.9913 - val_loss: 1.0663 - val_accuracy: 0.7361\n",
            "Epoch 601/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5105 - accuracy: 0.9913 - val_loss: 1.0760 - val_accuracy: 0.7639\n",
            "Epoch 602/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5267 - accuracy: 0.9861 - val_loss: 1.0566 - val_accuracy: 0.7708\n",
            "Epoch 603/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.5107 - accuracy: 0.9844 - val_loss: 1.0646 - val_accuracy: 0.7569\n",
            "Epoch 604/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4983 - accuracy: 0.9948 - val_loss: 1.0569 - val_accuracy: 0.7778\n",
            "Epoch 605/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5162 - accuracy: 0.9913 - val_loss: 1.0686 - val_accuracy: 0.7500\n",
            "Epoch 606/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5176 - accuracy: 0.9913 - val_loss: 1.0536 - val_accuracy: 0.7778\n",
            "Epoch 607/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5089 - accuracy: 0.9878 - val_loss: 1.0588 - val_accuracy: 0.7778\n",
            "Epoch 608/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5057 - accuracy: 0.9844 - val_loss: 1.0661 - val_accuracy: 0.7500\n",
            "Epoch 609/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5070 - accuracy: 0.9931 - val_loss: 1.0607 - val_accuracy: 0.7708\n",
            "Epoch 610/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5029 - accuracy: 0.9844 - val_loss: 1.0531 - val_accuracy: 0.7639\n",
            "Epoch 611/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5117 - accuracy: 0.9896 - val_loss: 1.0498 - val_accuracy: 0.7708\n",
            "Epoch 612/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5014 - accuracy: 0.9931 - val_loss: 1.0574 - val_accuracy: 0.7708\n",
            "Epoch 613/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5098 - accuracy: 0.9896 - val_loss: 1.0637 - val_accuracy: 0.7639\n",
            "Epoch 614/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.5007 - accuracy: 0.9931 - val_loss: 1.0568 - val_accuracy: 0.7847\n",
            "Epoch 615/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5090 - accuracy: 0.9931 - val_loss: 1.0684 - val_accuracy: 0.7708\n",
            "Epoch 616/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.5171 - accuracy: 0.9826 - val_loss: 1.0549 - val_accuracy: 0.7569\n",
            "Epoch 617/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4945 - accuracy: 0.9913 - val_loss: 1.0623 - val_accuracy: 0.7431\n",
            "Epoch 618/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5086 - accuracy: 0.9861 - val_loss: 1.0640 - val_accuracy: 0.7361\n",
            "Epoch 619/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5176 - accuracy: 0.9826 - val_loss: 1.0602 - val_accuracy: 0.7639\n",
            "Epoch 620/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5175 - accuracy: 0.9844 - val_loss: 1.0749 - val_accuracy: 0.7431\n",
            "Epoch 621/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4995 - accuracy: 0.9896 - val_loss: 1.0675 - val_accuracy: 0.7431\n",
            "Epoch 622/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4993 - accuracy: 0.9931 - val_loss: 1.0565 - val_accuracy: 0.7431\n",
            "Epoch 623/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4983 - accuracy: 0.9948 - val_loss: 1.0709 - val_accuracy: 0.7431\n",
            "Epoch 624/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4863 - accuracy: 0.9931 - val_loss: 1.0607 - val_accuracy: 0.7569\n",
            "Epoch 625/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4957 - accuracy: 0.9931 - val_loss: 1.0566 - val_accuracy: 0.7431\n",
            "Epoch 626/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4887 - accuracy: 0.9896 - val_loss: 1.0502 - val_accuracy: 0.7708\n",
            "Epoch 627/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.5014 - accuracy: 0.9896 - val_loss: 1.0772 - val_accuracy: 0.7431\n",
            "Epoch 628/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.5015 - accuracy: 0.9896 - val_loss: 1.0634 - val_accuracy: 0.7569\n",
            "Epoch 629/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4897 - accuracy: 0.9896 - val_loss: 1.0686 - val_accuracy: 0.7569\n",
            "Epoch 630/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.5080 - accuracy: 0.9878 - val_loss: 1.0575 - val_accuracy: 0.7639\n",
            "Epoch 631/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.5036 - accuracy: 0.9931 - val_loss: 1.0599 - val_accuracy: 0.7569\n",
            "Epoch 632/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4963 - accuracy: 0.9948 - val_loss: 1.0528 - val_accuracy: 0.7639\n",
            "Epoch 633/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4984 - accuracy: 0.9896 - val_loss: 1.0482 - val_accuracy: 0.7708\n",
            "Epoch 634/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4895 - accuracy: 0.9965 - val_loss: 1.0561 - val_accuracy: 0.7639\n",
            "Epoch 635/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4873 - accuracy: 0.9913 - val_loss: 1.0584 - val_accuracy: 0.7639\n",
            "Epoch 636/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4994 - accuracy: 0.9931 - val_loss: 1.0471 - val_accuracy: 0.7708\n",
            "Epoch 637/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4990 - accuracy: 0.9896 - val_loss: 1.0580 - val_accuracy: 0.7500\n",
            "Epoch 638/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.5042 - accuracy: 0.9931 - val_loss: 1.0527 - val_accuracy: 0.7569\n",
            "Epoch 639/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4813 - accuracy: 0.9965 - val_loss: 1.0559 - val_accuracy: 0.7500\n",
            "Epoch 640/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.5094 - accuracy: 0.9844 - val_loss: 1.0496 - val_accuracy: 0.7708\n",
            "Epoch 641/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.5075 - accuracy: 0.9809 - val_loss: 1.0538 - val_accuracy: 0.7639\n",
            "Epoch 642/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4939 - accuracy: 0.9896 - val_loss: 1.0583 - val_accuracy: 0.7569\n",
            "Epoch 643/700\n",
            "9/9 [==============================] - 1s 106ms/step - loss: 0.4809 - accuracy: 0.9913 - val_loss: 1.0446 - val_accuracy: 0.7778\n",
            "Epoch 644/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4895 - accuracy: 0.9931 - val_loss: 1.0493 - val_accuracy: 0.7500\n",
            "Epoch 645/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5050 - accuracy: 0.9896 - val_loss: 1.0547 - val_accuracy: 0.7569\n",
            "Epoch 646/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4850 - accuracy: 0.9913 - val_loss: 1.0467 - val_accuracy: 0.7708\n",
            "Epoch 647/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4766 - accuracy: 0.9965 - val_loss: 1.0521 - val_accuracy: 0.7708\n",
            "Epoch 648/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4864 - accuracy: 0.9878 - val_loss: 1.0490 - val_accuracy: 0.7847\n",
            "Epoch 649/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4965 - accuracy: 0.9965 - val_loss: 1.0500 - val_accuracy: 0.7569\n",
            "Epoch 650/700\n",
            "9/9 [==============================] - 1s 96ms/step - loss: 0.4876 - accuracy: 0.9913 - val_loss: 1.0407 - val_accuracy: 0.7569\n",
            "Epoch 651/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4968 - accuracy: 0.9948 - val_loss: 1.0529 - val_accuracy: 0.7847\n",
            "Epoch 652/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4875 - accuracy: 0.9913 - val_loss: 1.0556 - val_accuracy: 0.7778\n",
            "Epoch 653/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4904 - accuracy: 0.9948 - val_loss: 1.0533 - val_accuracy: 0.7431\n",
            "Epoch 654/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4969 - accuracy: 0.9878 - val_loss: 1.0594 - val_accuracy: 0.7569\n",
            "Epoch 655/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4930 - accuracy: 0.9913 - val_loss: 1.0455 - val_accuracy: 0.7778\n",
            "Epoch 656/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4956 - accuracy: 0.9931 - val_loss: 1.0615 - val_accuracy: 0.7708\n",
            "Epoch 657/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4751 - accuracy: 0.9948 - val_loss: 1.0503 - val_accuracy: 0.7708\n",
            "Epoch 658/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4856 - accuracy: 0.9896 - val_loss: 1.0504 - val_accuracy: 0.7778\n",
            "Epoch 659/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.5134 - accuracy: 0.9844 - val_loss: 1.0394 - val_accuracy: 0.7708\n",
            "Epoch 660/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4924 - accuracy: 0.9878 - val_loss: 1.0496 - val_accuracy: 0.7500\n",
            "Epoch 661/700\n",
            "9/9 [==============================] - 1s 99ms/step - loss: 0.4720 - accuracy: 0.9931 - val_loss: 1.0527 - val_accuracy: 0.7569\n",
            "Epoch 662/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4804 - accuracy: 0.9931 - val_loss: 1.0637 - val_accuracy: 0.7569\n",
            "Epoch 663/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4750 - accuracy: 0.9965 - val_loss: 1.0583 - val_accuracy: 0.7639\n",
            "Epoch 664/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4865 - accuracy: 0.9878 - val_loss: 1.0602 - val_accuracy: 0.7500\n",
            "Epoch 665/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4786 - accuracy: 0.9965 - val_loss: 1.0545 - val_accuracy: 0.7778\n",
            "Epoch 666/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4865 - accuracy: 0.9983 - val_loss: 1.0474 - val_accuracy: 0.7778\n",
            "Epoch 667/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4869 - accuracy: 0.9931 - val_loss: 1.0342 - val_accuracy: 0.7639\n",
            "Epoch 668/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4881 - accuracy: 0.9913 - val_loss: 1.0473 - val_accuracy: 0.7569\n",
            "Epoch 669/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4877 - accuracy: 0.9878 - val_loss: 1.0716 - val_accuracy: 0.7361\n",
            "Epoch 670/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4896 - accuracy: 0.9913 - val_loss: 1.0579 - val_accuracy: 0.7361\n",
            "Epoch 671/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4698 - accuracy: 0.9965 - val_loss: 1.0563 - val_accuracy: 0.7500\n",
            "Epoch 672/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4697 - accuracy: 0.9965 - val_loss: 1.0554 - val_accuracy: 0.7778\n",
            "Epoch 673/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4840 - accuracy: 0.9965 - val_loss: 1.0498 - val_accuracy: 0.7708\n",
            "Epoch 674/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4731 - accuracy: 0.9913 - val_loss: 1.0539 - val_accuracy: 0.7500\n",
            "Epoch 675/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4926 - accuracy: 0.9861 - val_loss: 1.0630 - val_accuracy: 0.7500\n",
            "Epoch 676/700\n",
            "9/9 [==============================] - 1s 105ms/step - loss: 0.4649 - accuracy: 0.9965 - val_loss: 1.0492 - val_accuracy: 0.7569\n",
            "Epoch 677/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4740 - accuracy: 0.9965 - val_loss: 1.0580 - val_accuracy: 0.7431\n",
            "Epoch 678/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4821 - accuracy: 0.9878 - val_loss: 1.0526 - val_accuracy: 0.7569\n",
            "Epoch 679/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4899 - accuracy: 0.9896 - val_loss: 1.0504 - val_accuracy: 0.7569\n",
            "Epoch 680/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4700 - accuracy: 0.9965 - val_loss: 1.0531 - val_accuracy: 0.7708\n",
            "Epoch 681/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4846 - accuracy: 0.9913 - val_loss: 1.0723 - val_accuracy: 0.7222\n",
            "Epoch 682/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4787 - accuracy: 0.9913 - val_loss: 1.0440 - val_accuracy: 0.7639\n",
            "Epoch 683/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4729 - accuracy: 0.9965 - val_loss: 1.0372 - val_accuracy: 0.7778\n",
            "Epoch 684/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4800 - accuracy: 0.9931 - val_loss: 1.0485 - val_accuracy: 0.7500\n",
            "Epoch 685/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4991 - accuracy: 0.9896 - val_loss: 1.0546 - val_accuracy: 0.7500\n",
            "Epoch 686/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4814 - accuracy: 0.9931 - val_loss: 1.0451 - val_accuracy: 0.7569\n",
            "Epoch 687/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4741 - accuracy: 0.9983 - val_loss: 1.0456 - val_accuracy: 0.7708\n",
            "Epoch 688/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4884 - accuracy: 0.9792 - val_loss: 1.0487 - val_accuracy: 0.7847\n",
            "Epoch 689/700\n",
            "9/9 [==============================] - 1s 103ms/step - loss: 0.4776 - accuracy: 0.9896 - val_loss: 1.0585 - val_accuracy: 0.7500\n",
            "Epoch 690/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4657 - accuracy: 0.9965 - val_loss: 1.0470 - val_accuracy: 0.7639\n",
            "Epoch 691/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4699 - accuracy: 0.9931 - val_loss: 1.0651 - val_accuracy: 0.7569\n",
            "Epoch 692/700\n",
            "9/9 [==============================] - 1s 100ms/step - loss: 0.4783 - accuracy: 0.9896 - val_loss: 1.0487 - val_accuracy: 0.7569\n",
            "Epoch 693/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4841 - accuracy: 0.9965 - val_loss: 1.0570 - val_accuracy: 0.7431\n",
            "Epoch 694/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4864 - accuracy: 0.9896 - val_loss: 1.0607 - val_accuracy: 0.7639\n",
            "Epoch 695/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4626 - accuracy: 0.9931 - val_loss: 1.0430 - val_accuracy: 0.7778\n",
            "Epoch 696/700\n",
            "9/9 [==============================] - 1s 102ms/step - loss: 0.4726 - accuracy: 0.9931 - val_loss: 1.0385 - val_accuracy: 0.7708\n",
            "Epoch 697/700\n",
            "9/9 [==============================] - 1s 97ms/step - loss: 0.4813 - accuracy: 0.9844 - val_loss: 1.0586 - val_accuracy: 0.7431\n",
            "Epoch 698/700\n",
            "9/9 [==============================] - 1s 104ms/step - loss: 0.4740 - accuracy: 0.9931 - val_loss: 1.0530 - val_accuracy: 0.7500\n",
            "Epoch 699/700\n",
            "9/9 [==============================] - 1s 101ms/step - loss: 0.4644 - accuracy: 0.9931 - val_loss: 1.0569 - val_accuracy: 0.7569\n",
            "Epoch 700/700\n",
            "9/9 [==============================] - 1s 98ms/step - loss: 0.4663 - accuracy: 0.9913 - val_loss: 1.0501 - val_accuracy: 0.7569\n"
          ]
        }
      ],
      "source": [
        "\n",
        "hist=[]\n",
        "scores=[]\n",
        "totalsize=X3.shape[0]\n",
        "a=create_index(kfold,totalsize)\n",
        "for i in range (kfold):\n",
        "    #print(a[i])\n",
        "\n",
        "    model_name = 'Femalemodel'+str(i)\n",
        "    savedir='RAVDESS_Model65/'\n",
        "    model_path = os.path.join(savedir, (model_name+'.h5'))\n",
        "\n",
        "    split4=np.concatenate((a[i%kfold],a[(i+1)%kfold],a[(i+2)%kfold],a[(i+3)%kfold]), axis=0)\n",
        "    split4=np.sort(split4)\n",
        "    X_train= X3.iloc[split4,:]\n",
        "    y_train= y1[split4,:]\n",
        "\n",
        "    split1= np.sort(a[(i+4)%kfold])\n",
        "    X_test = X3.iloc[split1,:]\n",
        "    y_test = y1[split1,:]\n",
        "\n",
        "    x_traincnn =np.expand_dims(X_train, axis=2)\n",
        "    x_testcnn= np.expand_dims(X_test, axis=2)\n",
        "\n",
        "    m1= model1(x_traincnn.shape[1])\n",
        "    opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.00001, decay=1e-6)\n",
        "    m1.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "    print(i)\n",
        "    hist.append(m1.fit(x_traincnn, y_train, batch_size=64, epochs=700, validation_data=(x_testcnn, y_test)))\n",
        "    scores.append(m1.evaluate(x_testcnn, y_test, verbose=0))\n",
        "\n",
        "\n",
        "    #outfile = TemporaryFile()\n",
        "    np.save((savedir+'/X'+str(i)),x_testcnn)\n",
        "    np.save((savedir+'/y'+str(i)),y_test)\n",
        "\n",
        "    model_json = m1.to_json()\n",
        "    with open((savedir+model_name+'.json'), \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    m1.save(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HaP-VojXnON"
      },
      "outputs": [],
      "source": [
        "### scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7roU5VmXnON",
        "outputId": "7af09a25-2879-478d-b5a7-aca32871bde7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.8194443583488464 0.7638888716697693\n"
          ]
        }
      ],
      "source": [
        "sum=.0\n",
        "for i in scores:sum+=i[1]\n",
        "\n",
        "print(sum, sum/len(scores))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMmOIs7YXnON",
        "outputId": "705c0ee4-cfec-4c9d-97e2-05254c6f294b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0.9700207114219666, 0.8194444179534912],\n",
              " [1.0651105642318726, 0.7013888955116272],\n",
              " [1.0141377449035645, 0.7708333134651184],\n",
              " [1.05926513671875, 0.7708333134651184],\n",
              " [1.0500925779342651, 0.7569444179534912]]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n_FvbqWXnOO",
        "outputId": "b5310c9e-6773-45ca-aa0c-155879e0abfa"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x1296 with 6 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, axs = plt.subplots(3, 2,figsize=(12,18))\n",
        "axs[0, 0].plot(hist[0].history['loss'])\n",
        "axs[0, 0].plot(hist[0].history['val_loss'])\n",
        "axs[0, 0].set_title('Fold-1')\n",
        "axs[0, 0].legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "axs[0, 1].plot(hist[1].history['loss'])\n",
        "axs[0, 1].plot(hist[1].history['val_loss'])\n",
        "axs[0, 1].set_title('Fold-2')\n",
        "axs[0, 1].legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "axs[1, 0].plot(hist[2].history['loss'])\n",
        "axs[1, 0].plot(hist[2].history['val_loss'])\n",
        "axs[1, 0].set_title('Fold-3')\n",
        "axs[1, 0].legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "axs[1, 1].plot(hist[3].history['loss'])\n",
        "axs[1, 1].plot(hist[3].history['val_loss'])\n",
        "axs[1, 1].set_title('Fold-4')\n",
        "axs[1, 1].legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "axs[2, 0].plot(hist[4].history['loss'])\n",
        "axs[2, 0].plot(hist[4].history['val_loss'])\n",
        "axs[2, 0].set_title('Fold-5')\n",
        "axs[2, 0].legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "#axs[2, 1].plot(hist[0].history['loss'])\n",
        "#axs[2, 1].plot(hist[0].history['val_loss'])\n",
        "#axs[2, 1].set_title('model loss')\n",
        "#axs[2, 1].legend(['train', 'test'], loc='upper right')\n",
        "\n",
        "for ax in axs.flat:\n",
        "    ax.set(xlabel='epoch', ylabel='loss')\n",
        "\n",
        "# Hide x labels and tick labels for top plots and y ticks for right plots.\n",
        "for ax in axs.flat:\n",
        "    ax.label_outer()\n",
        "fig.savefig('ravdesFemale_5Folds_65.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkE3puXdXnOO"
      },
      "outputs": [],
      "source": [
        "### Model yükleme, gereksizse yapma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLi1-uN5XnOO",
        "outputId": "db66c157-7f06-49a2-c1c9-5944b5ddbfa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "# loading json and creating model\n",
        "from keras.models import model_from_json\n",
        "savedir='RAVDESS_Model65/'\n",
        "m='Femalemodel3' # Infact female\n",
        "\n",
        "json_file = open(savedir+m+'.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "# load weights into new model\n",
        "loaded_model.load_weights(savedir+m+'.h5')\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1EQmKK01XnOO",
        "outputId": "7b48a4e4-1a96-436e-f119-ecfd941cef2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 77.08%\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "opt = tf.keras.optimizers.legacy.RMSprop(learning_rate=0.00001, decay=1e-6)\n",
        "\n",
        "Xloaded=np.load(savedir+'/X3.npy')\n",
        "yloaded=np.load(savedir+'/y3.npy')\n",
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(Xloaded, yloaded, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "nzkKLN-OXnOO"
      },
      "source": [
        "##çizim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZ1lmXfXXnOO",
        "outputId": "5fca3507-bf97-4196-fbc6-8d8589acedd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 16ms/step\n",
            "(144, 8)\n",
            "144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[ 7,  1,  0,  1,  0,  0,  0,  0],\n",
              "       [ 4, 11,  0,  1,  0,  0,  0,  0],\n",
              "       [ 1,  0,  7,  1,  0,  0,  0,  0],\n",
              "       [ 6,  2,  0, 11,  1,  2,  0,  1],\n",
              "       [ 1,  0,  0,  0, 21,  0,  2,  0],\n",
              "       [ 0,  0,  0,  3,  0, 23,  0,  1],\n",
              "       [ 0,  1,  0,  0,  0,  0, 16,  3],\n",
              "       [ 0,  0,  1,  0,  0,  0,  0, 15]], dtype=int64)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_pred = loaded_model.predict(Xloaded)\n",
        "print(y_pred.shape)\n",
        "yy = []\n",
        "ya = []\n",
        "for j in y_pred:\n",
        "    yy.append(np.argmax(j))\n",
        "print(len(yy))\n",
        "\n",
        "##önemli\n",
        "for j in yloaded:\n",
        "    ya.append(np.argmax(j))\n",
        "\n",
        "cm=confusion_matrix(ya, yy)\n",
        "cm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvLzmzedXnOS",
        "outputId": "3d226c24-2c1c-4118-acf5-1f469075e0a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[77.8 11.1  0.  11.1  0.   0.   0.   0. ]\n",
            " [25.  68.8  0.   6.2  0.   0.   0.   0. ]\n",
            " [11.1  0.  77.8 11.1  0.   0.   0.   0. ]\n",
            " [26.1  8.7  0.  47.8  4.3  8.7  0.   4.3]\n",
            " [ 4.2  0.   0.   0.  87.5  0.   8.3  0. ]\n",
            " [ 0.   0.   0.  11.1  0.  85.2  0.   3.7]\n",
            " [ 0.   5.   0.   0.   0.   0.  80.  15. ]\n",
            " [ 0.   0.   6.2  0.   0.   0.   0.  93.8]]\n"
          ]
        }
      ],
      "source": [
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "array = np.array(confusion_matrix(ya, yy) , dtype=float)\n",
        "for it in range(0, 8):\n",
        "    sumik = np.sum(array[it])\n",
        "    for it2 in range(0, 8):\n",
        "        array[it][it2] = round(array[it][it2] * (100.0/sumik) ,1)\n",
        "print(array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sy-eJvvTXnOS",
        "outputId": "fb3e2a8c-ad1f-4313-ab00-0c1da1d20af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           angry  calm  disgust  fearful  happy  neutral   sad  surprised\n",
            "angry       77.8  11.1      0.0     11.1    0.0      0.0   0.0        0.0\n",
            "calm        25.0  68.8      0.0      6.2    0.0      0.0   0.0        0.0\n",
            "disgust     11.1   0.0     77.8     11.1    0.0      0.0   0.0        0.0\n",
            "fearful     26.1   8.7      0.0     47.8    4.3      8.7   0.0        4.3\n",
            "happy        4.2   0.0      0.0      0.0   87.5      0.0   8.3        0.0\n",
            "neutral      0.0   0.0      0.0     11.1    0.0     85.2   0.0        3.7\n",
            "sad          0.0   5.0      0.0      0.0    0.0      0.0  80.0       15.0\n",
            "surprised    0.0   0.0      6.2      0.0    0.0      0.0   0.0       93.8\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArEAAAHsCAYAAADFIvWZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABnlElEQVR4nO3dd3gUZdfH8e9JSOhVerGiK6I+FlBRQey9Y29YHmyPiL2gggUVsQFWbFhQ7GAXGwgidngBdS2AUkRAmoQSSM77x0xIgBAiZnc2u7/Pde1FZvae2TN3ZpeTs/fcY+6OiIiIiEhlkhV1ACIiIiIi/5SSWBERERGpdJTEioiIiEiloyRWRERERCodJbEiIiIiUukoiRURERGRSkdJrIhUODPbw8w+MbP/M7NJZvaumbX9l/ucZmbtKirGDbzWYDO7sgL3197MHqmo/f3D165tZu+bWXUz28rMxpvZz2Z2Tok2Z5jZrWttd4+ZdU52vCIi5VUl6gBEJL2YWVXgLeAgd/82XHc68K6ZbeHuBZEGGI22QMuIXrsv8Ji7LzOzi8Pl14DvgSfNrDZwMbDfWtvdAowxs93cfVlSIxYRKQdVYkWkotUA6gG1SqwbAvwPyAYwsyPN7Asz+87MPjOzDuH6JmY2zMw+N7OpZjbSzBqX2M/FZvatmU1eq5LYLaz4TjCzEWa2Tbh+sJm9EbbvGy4PCKvEv5jZa2ZWMs6S9jSzsWb2q5kNN7Oa4T7bhK/xTVjVPCdcn2Vm/cPj+t7MfjCzvcysFUFC2NHMnjKzzuHxvRhu/1nYHx+Y2e9mdl9Z+ytxXA+H+/k1/Dln7QMIX/tIYFi4akX4e6kJFIbregN3u/vSktu6+yLgM6DbevpHRCRSSmJFpEK5+wLgauA9M5tiZs8CZwMfunu+mW0N3A4c5u47EyRJr4VJ4snA5+7eAdgSWAqcUWL3y9x9F+BA4A4za2tm+4Wvt6+7/wd4HhhmZhZuU8Pd27r7NeHyrsAhQBtgc+CE9RxKC+AAYBuCKupxZlYFeAW41t13BfYBrjSzPYDdgeZAB3ffDng6bDcduAkY7e5nh/tuD9zp7jsBi4HrgMOBXQgS9ebr21+J+HYP+2G78HF+KcdwNPCRu68KlwcAJwGfAFeZWRugrbu/sp4+GAEct57nREQipeEEIlLh3P1eM3uMIMnrBFwDXGNmuxEkXs2Aj4rzTAqB1u7e38w6mtnlwNbA9sAXJXb9aLj/WWY2AtifIMF80d3nhs8NNrP+BAkqwJi1wnvP3VcAmNlEoMF6DmNYUXXSzCYBjQkS2q0IvoYvalcd2NndHzazG4DzzWwroDPw93r2PdXdvwt//hVY5O75wDwzWww0cPfPN7C/we6+JIzvGeAY4IG1Xmdb4JeiBXf/gyAxJ9zuXeByMzscuIggob7Y3ecXxQnE1nMMIiKRUiVWRCpU+BX6Ve7+t7u/5e5XE4wJdYIENpugOrhT0QPYA5hkZn0JvnqfCwwiqARaid2XHE+bBawM9+drhwEUfb2+ZK3nSo7v9LX2X9LKUtplEySca8f+VJgIvh22Hw48Usa+V5TxWsEBbHh/q0r8nMWafVMy7lI/583sBOAHd/8euJegIv02cNlacWXiGGYRqQSUxIpIRZsL3GBme5dY1wyoC0wEPgIOMrNtAczsMOD/CCqaBwP3u/uzwByKk94iXcNtNiWoKH4EvAecbGaNwufOBv6iRAWyAsWBZeGFakVjTicRDFE4EHjT3R8GviaojBbFvoripLq8ytofwElmVtXMqgFnAW+uJ96t1l5pZjWAqwjGwxLGVhg+apRougXw4z+MW0QkKTScQEQqlLv/ZGbHALebWUtgObAIONvd4xBciAUMDcetrgKOcvclZnYLcLcF0z2tJBgK0LrE7quZ2bdALnCJu/8E/BReDPWxmWURJNFHuHthia/8K+rY8s3saKC/mV1NkPzd6O6fmdlfwAvhEIUqBFXk48OYxgG9zOw1gnGp5fFIGfuDYLzwaKA+wTjdp0rZxzDgajPLXmtWiOuBB919cbh8NzAZWAh0KdHuEODlcsYrIpJU5r72t3AiIpLKzGwwMMnd7y5H20EEF9W99A9fow4wFmjn7ss3KlARkQTScAIRkfR2NfBfM6v+D7frDfRQAisiqUqVWBERERGpdFSJFREREZFKR0msiIiIiFQ6SmJFREREpNLRFFtreb9jtgYJhw56+duoQ0gZVqdF1CGkDF88M+oQUoLOCREptxoNK3a+v43Ue9uchOQ4vX9cGcnxqRIrIiIiIpWOKrEiIiIiGSAlysEVSEmsiIiISAao4JsYRk7DCURERESk0lElVkRERCQDpFvlMt2OR0REREQygCqxIiIiIhkg3cbEKokVERERyQBplsNqOIGIiIiIVD6qxIqIiIhkgHQbTqBKrIiIiIhUOqrEioiIiGSAdKtcptvxiIiIiEgGUCVWREREJAOk25hYJbEiIiIiGSDNclgNJxARERGRykeVWBEREZEMkG7DCVSJFREREZFKJyMqsWaW5e6FUcchIiIiEpU0K8SmZyXWzLLMLMfMnjOzJkpgRUREJNNlWWIekR1PdC+dGGZWFajl7iuBJcDeEYckIiIiIhUsrZJYMzsauAK4M1w1E5gdPhdpFb35wWfQ4clvVj86vvgLB36ynPb9P1xj/X7vzmfnO4atu4OsLNpc8SB7PTuRvZ6dyDYX3ZX0Y6ho7s41tz/AE0PfWL1u8d95HHX2lUz88dcyty1vu3QwcvRYjjzxTA4+5mS6X3UDS5bkRR1SQum8KJ9MOy/Kor4opr4opr5YlyXoEZW0SGLNbAczew04CHgM2NHMTgG2AzoDuLtHFyHMev9ZPj9nVz4/Z1fG/Xd38ufP5of7uvPVpQesXj/5rvNZtWQhP9z3v3W2b37wGdRstQ2fnfUfxnbdmQY7daJJ5y4RHEnF+HXaDLpedgsjRn2xet2ocd9y4oXXM3X6rDK3LW+7dDB//gKu69WHgf368P6wobRq2Zy7BzwcdVgJo/OifDLtvCiL+qKY+qKY+iIzVOok1syam9mOwOEEF6k96O5zgfOBHKAJ0MLMciMMcx1bnHY1+QvmMuONQavXWZUcduj5FD8OuJzlc2ass41lZZNdvSZZOVXJyq1KVk4uhfnLkxl2hRoy7H26HL4/B3feY/W6Z199l349L6HRJvXL3La87dLBmHFfskPbNmy+WSsATjnhWN58dwQR/02WMDovyifTzouyqC+KqS+KqS9KZ5aYR1Qq5ewEZlYduBY4GhhPUH2tB+xmZr+4+2Rgspm1Atq5e76ZWdTVWICcupuw+cmX8/m57ddY3/KIc1kxbxZzRg8rdbuZ7w6m6b5d6Pz6dCy7Cn99+QFzx76VhIgT46Ye5wLw2dcTVq97vF/Pcm1b3nbpYPbsOTRt0nj1ctPGjViyJI+8vKXUqlUzwsgSQ+dF+WTaeVEW9UUx9UUx9UXpNDtBxMysLvAIUACcCmxKkMD+AmwJrM4O3b0PsMrM6qRCAgvQ8qj/MmfMGyz7Y+oa6zc78VJ+ffr29W7X+uybyF84l0+Oasao4zYlp059NjvpskSHKxEr9EJKG86dlV3p3rpSgXReFFNfFFNfFFNfZIZK89s0szbhj/lAC+BZd/8eeAroBvwA1AIaWiDbzG4A/gLK/N7dzLqZ2ddm9vU7sxOb6zbb70RmvjN4jXW1t94Jy67CgvGj1rtd407HMvPtp/BVK1mVt5iZ7z1Lg132TWisEr1mTZsyZ+681ct/zplH3Tq1qVG9eoRRSdR0XhRTXxRTXxRTX5Quyzwhj8iOJ7JXLicza2Bm9wHDzexOgimz3gNOCZuMBrYFtgDucPfhHigABrj7Be6eX9ZruPsgd2/n7u0Oa5q4YnuVWvWo3qI1CyeOXWN9g506Mf/bT8rcdvFP39FkvxMAsOwqNN7rSBZNHpewWCU17N1hNyZMnMy036YDMPSV19m/c8eIo5Ko6bwopr4opr4opr7IDCk9JtbMjiUYMvAhcDtwHtABGAv8z8yeIajKDgd6AEPC7bLcvdDdF0cR9/rUaNma/L/+wAtWrbV+a5b9MW2d9q3P7Q3AL0/0Jj7wctpcNpC9npsMhQX89c3HTH2+XxKijt7Q4SOYFJ/CbVdfEHUoSbdJg/rc0ft6ul91AytXrWTTli3oe+uNUYeVEnRe6LwA9UVJ6oti6ovSpduYWEuRoaJrMLOuwH5ALsEMA3e5+7tm1plgGq0vgQ+Ac4BBQDuCIQXd3X3Rv3nt9ztmp16HROSgl7+NOoSUYXVaRB1CyvDFM6MOISXonBCRcqvRMCXyx4d2qpKQHOei8asiOb6UGk5gZlXN7CFgd+AOoDqwNdA+vBPXl8A8oBlQCCwFXgZ6A/f+2wRWRERERCqHlBpO4O4rzOwrYBKwC0HCugI4Bhjv7m+Y2ZPuvhDAzIYCP7j72PXsUkRERESIdk7XREi1SqwBnxLcrGAlwVyws4CmQDZAiQQ2293zlMCKiIiIZJ5Uq8S6mS0AFhPM+XoC8AnQxd3/XKttQQQhioiIiFRKaVaITa0kNrQA+Bw4luA2siMhqLwChaly0wIRERERiU7KJbFhkvpy+ABWT5mlyquIiIjIRspKs1JsyiWxJZWY77Uw6lhEREREKrM0y2FT68KutSl5FREREZHSpHQlVkREREQqhqbYEhERERGJmCqxIiIiIhkgzQqxSmJFREREMkG6zU6g4QQiIiIiUumoEisiIiKSAdKsEKtKrIiIiIhUPqrEioiIiGSAdJtiS0msiIiISAZIsxxWwwlEREREpPJRJVZEREQkA6TbcAJVYkVERESk0lElVkRERCQDpFvlMt2OR0REREQygCqxIiIiIhkg3cbEKoldy4H3PRp1CCljyn93jTqElLHVi7OjDiF15NaKOgIREdkIaZbDajiBiIiIiFQ+qsSKiIiIZICsNCvFqhIrIiIiIpWOKrEiIiIiGSDNCrFKYkVEREQyQboNJ1ASKyIiIiJJEYvF9gAGADFgLnBnPB5/PBaL5QIPAF2AAuDeeDx+R1n70phYERERkQyQlaBHecVisSxgODAgHo/XBU4BHojFYv8BbiZIbLcC2gNnxWKxMzd0PCIiIiIiiVYfaAxYLBYzwIFVQD5wFtAnHo8viMfj04C7gfPL2pmGE4iIiIhkgETdsSsWi9UD6pXy1MJ4PL6waCEej/8Vi8UeAJ4GngKygUuBP4BmwPcltv0R2KGs11UlVkRERCQDJHA4QQ9gaimPHiVfPxxOsBw4FagOdAZ6AUeFTZaWaL4UqFHW8agSKyIiIiL/xv3A4FLWL1xr+Thgr3g8flW4PCoWiz1BMJQAgsS2SA1gSVkvqiRWREREJAMkajhBOGRgYTmatgKqrrVuFcEsBbMJLuyaGa7fljWHF6xDSayIiIiIJMMI4I5YLNYNeAzYBfgvcB7wO9ArFov9H1ALuBLoX9bONCZWREREJANkmSfkUV7xeHwywZCC8wkqt88D18bj8eHATcAkYDLwFfAq8EhZ+1MlVkRERESSIh6PvwO8U8r65cDF4aNclMSKiIiIZIB0+/pdSayIiIhIBkjUhV1RSbekXEREREQyQNpWYs3M3L38o41FRERE0li6VS7T7XgAMLMsJbAiIiIi6SutKrFmlu3uBe5eaGZtgQOAt939l6hjExEREYlSuo2JTYskNqy8Frp7gZnlAtsDdwB/AW3N7CF3H68hBiIiIpKp0u3r90qdxJrZ7sA37r4qXD4N6E5wm7K73P0jM7uGYGLd8amYwL4xZjJPvv0VBlSrmkPPM/dn+y2b0uH8B2jaoNbqduccsRtH7rVddIFWsNzNtqfh+f3JqlEHLyxg7oMXkT91PA3PH0D17TsBsPSb9/jryavX3Tgrq3zt0sTI0WO5Z+Aj5OfnE9u6Nbf3uo5atWpGHVbCxX+Zym33PsKSJXlkZWdx8zWXsP22W6/R5o33PuaJIa9iZlSrWpWel5/PDm22iSji5MrU86I06oti6oti6ov0V2mTcjNrRHDLsj3NrImZ9QYOAS4B/gT2NrMc4CNgczM7KrJg12PqrPn0e2EUg67uwut3dOWCYzrQ/f5hTJ01n7q1qvH6HV1XP9IpgbWq1Wl2y7ssfPVuZvRoz4IX+9Dkymeove/p5LaIMf2SnZjefReqbd+Rmnsdv8725W2XDubPX8B1vfowsF8f3h82lFYtm3P3gIejDivhli1fznk9buC807vw+jMPcNHZp3BVr35rtJny2wz6PfAEj913K8OeeYALzz6Z7tf1iSji5MrU86I06oti6oti6ovSZVliHpEdT3QvvXHMLBvA3ecCTwCnAPWARsACd/+S4N681YF9gG+A94CpUcRbltycbG4972Aa1w8qrttv0YR5C/P48offyc4yTr/leY6+9ikefG0sBYWFEUdbcarvfCArZ09h6TfvArD0izf5s+8pkJWNVauJ5VQNHlVy8fwV6+6gvO3SwJhxX7JD2zZsvlkrAE454VjefHcEKfilQoX67ItvadWiGfvs2R6A/Truwf19rlujTW5uDrdedymNGzYAYPttt2beXwvIX7ky6fEmW6aeF6VRXxRTXxRTX2SGSjOcoGg8azjuNQdo6O79zexNYGvgbWBfM9sNGAN0ADoCo9z9+egiX78WjerSolFdANydvkM+Yd9dWmNmdNh+My4/qROrCgq5oN+r1Kqey1mHtos44oqR23wbChbMptElg8jdYkcK8xbx1+Br+fujp6m1Vxc2G/w7llWFpeM/YOlXb62zfXnbpYPZs+fQtEnj1ctNGzdiyZI88vKWpvXXYtOmz6ThJvXp2ed+fvxlCnVq1eLK/52zRpuWzZrQslkTIHj/3DngMfbtuDu5OTlRhJxUmXpelEZ9UUx9UUx9Ubp0u7Ar5SuxZpYFUDSe1cxOBD4HHjGzs4BbgXOBOLAQOByoCjwN9HX3DZZlzKybmX1tZl8Peu3ThBxHWZYuz+eyAW/w2+yF3Prfgzlxv/9ww1kHUKNaLnVqVqPrYe348Oufkx5XwlTJoUa7Q1n8/uPMvHwPFr31AM16vUmD02+lYPFcpp3RnN/O3ozsWg2oe8xl62xe/5SbytUuHRR6IVbKp05Wdsq/df+VVasK+HTs15x4zCG8+tQATj/hSM6/vBf5+eu+nZcuW06Pnnfw+4xZ3HbdpRFEm3yZel6URn1RTH1RTH1RuqwEPaKS0r/NolkHwp8bmNkJwJHAQcCDwM3AeGAWcBjwBTAPyHL3Ge6+tDyv4+6D3L2du7frdlynBBzJ+s2at5hTb36erKwsnr7hJOrUrMbw0ZOJ/z6nRHxQJY3eeAV/zWLl9B9Y8dOXQDCcwLKyqXfclSz+YDCsWknh0sX8/fEzVN+x8zrb1+pwTLnapYNmTZsyZ+681ct/zplH3Tq1qVG9eoRRJV6jhg3YcvNW/KfttgDs36kDBYUFTJ/1xxrtZs2ewyndriA7O4unH7iTOrVrlba7tJOp50Vp1BfF1BfF1BeZIaUzo3C+14Zm9iRBZbUFwbCB/wKdgV+AO4F7CIYOfOHuA919UUQh/yN5y/I567ahHNhua+695Eiq5QZfg/48Yx4DX/mMgsJCluevZMgH33HoHttGHG3FWfrNe1RpsgW5W+0CQLW2HcGdvM9fo9beXYJG2VWosduRLP/xi3W2X/Hrd+Vqlw727rAbEyZOZtpv0wEY+srr7N+5Y8RRJV6nDu2YOWs2k34MvoH46ruJmBktmzVd3WZJ3lLOvPhaDuy8J/feei3VqlWNKtyky9TzojTqi2Lqi2Lqi9KZJeYR2fGk+iBnMxsMTAPuJbiAa1dgK3e/28x6ARcA27n7gop4vcKvH09ahwwaPo7+L49hm1YN11j/yFXHM+CVMUz4+Q9WFhRwyO4xepzYsdSvRhJp6s0XJGzf1dp2ZJOz+5JVrQa+cgXzHruc/Ok/0PD8AVTdaicoLGDphI+DqbNWraT+ab0BWDCkN1m1G6y3XaJs9eLshO17Q0aNHss9Ax9l5aqVbNqyBX1vvZF6detEFo8vT87fiF99N5F+DzzBsuUryMnJoedl55Obm8ONdwxg2DMP8OjTL9J/0LNss9Xma2z31MDbqZ+E/rFqdRP+GmVJtfMiSuqLYuqLYinVFzUapsRo1E/3zU5IjtPpk4JIji+lk9jwAq6+wGvuPiZc9yBQH9gS+ATo7+4VlmEkM4lNdYlMYiubKJPYVJOsJDbVRZ3EikglkiJJ7JgEJbF7R5TEpvrsBKuAlcB2ZvYd0BKoDYwEHnH35F+FJSIiIiKRS+kk1t3dzAYC5wPPA7WAp9z9uWgjExEREalcorwxQSKkdBIL4O4zgBvNrOjCrfyoYxIRERGpbNIsh039JLaIu4+OOgYRERERSQ2VJokVERERkY2XbsMJUnqeWBERERGR0qgSKyIiIpIB0qwQqyRWREREJBNoOIGIiIiISMRUiRURERHJAFmWXjclVSVWRERERCodVWJFREREMkCaDYlVEisiIiKSCXRhl4iIiIhIxFSJFREREckAaVaIVSVWRERERCofVWJFREREMoDGxIqIiIiIREyVWBEREZEMkG6VSyWxIiIiIhnANJxARERERCRaqsSKiIiIZABd2CUiIiIiEjFVYtdiLdtHHULK2OrF2VGHkDLeP7hJ1CGkjINe/jbqEFJDtbpRRyAi8o+kWSFWSayIiIhIJrA0u7JLwwlEREREpNJRJVZEREQkA6RZIVaVWBERERGpfFSJFREREckEaVaKVRIrIiIikgHSLIfVcAIRERERqXxUiRURERHJAJpiS0REREQkYqrEioiIiGQAVWJFRERERCKmSqyIiIhIJkiz0qWSWBEREZEMoOEEIiIiIiIRUyVWREREJAOkWSE2PSuxZtbIzDYrsZxmvzYRERGRzJauldhtgcPM7DV3/8rdPeqARERERKKUbjW9tKnEmll2icWvgROBN8xs04hCEhEREUkdlqBHRNImiXX3AgAz6wS0BO4BvgXmRRmXiIiIiFS8tElizewQMxsNdAG2dveHgD+A/0YbmYiIiEj0zCwhj6hU+iTWzDYxsyzgGqA/cD+wnZn9B7gJOMrMPjSzbSIMU0REREQqUKVOYs1sF+BWoAPwErAXMAD4BXgVWAn0BAa6+09RxVmSu3PN7Q/wxNA3Vq9b/HceR519JRN//LXMbcvbLh2MHD2WI088k4OPOZnuV93AkiV5UYeUEM0PPoMOT36z+tHxxV848JPltO//4Rrr93t3PjvfMWzdHWRl0eaKB9nr2Yns9exEtrnorqQfQ0XTe6R8MuU9Uh7qi2Lqi2Lqi3WZJeYRlUqRxIaV1pLLe4Y//gn8DnQEBgGvAVcB+QQXd61w93HuPjyJ4a7Xr9Nm0PWyWxgx6ovV60aN+5YTL7yeqdNnlbltedulg/nzF3Bdrz4M7NeH94cNpVXL5tw94OGow0qIWe8/y+fn7Mrn5+zKuP/uTv782fxwX3e+uvSA1esn33U+q5Ys5If7/rfO9s0PPoOarbbhs7P+w9iuO9Ngp0406dwlgiOpGHqPlE8mvUc2RH1RTH1RTH1ROg0nSCILZLl7YbjcxszqAY+Z2a7uPhMYR3Ah1xGAAw8ApwLXu/viiEIv1ZBh79Pl8P05uPMeq9c9++q79Ot5CY02qV/mtuVtlw7GjPuSHdq2YfPNWgFwygnH8ua7I0j3mdK2OO1q8hfMZcYbg1avsyo57NDzKX4ccDnL58xYZxvLyia7ek2ycqqSlVuVrJxcCvOXJzPsCqX3SPlk6nukNOqLYuqLYuqLzJDS88SG87u6mW0NnAVcD+wG3AecB3zj7iPN7ALgYOBy4Cx3nwFBBbcoAU4FN/U4F4DPvp6wet3j/XqWa9vytksHs2fPoWmTxquXmzZuxJIleeTlLaVWrZoRRpY4OXU3YfOTL+fzc9uvsb7lEeeyYt4s5oweVup2M98dTNN9u9D59elYdhX++vID5o59KwkRJ4beI+WTie+R9VFfFFNfFFNfrIfmiU2steZ7xcwOBV4AvgBuAx5298eBmJldZGa3A8uAl9x9eaomsFJ+hV5Y6tcTWdkpd7pWmJZH/Zc5Y95g2R9T11i/2YmX8uvTt693u9Zn30T+wrl8clQzRh23KTl16rPZSZclOlyJWCa+R9ZHfVFMfVFMfZEZUu63WWK+1zbhqurA++7+prvfBGSbWVfgbIJhBLWAi9195Fr7KXcCa2bdzOxrM/t60LOvVMBRyL/RrGlT5swtnt73zznzqFunNjWqV48wqsRqtt+JzHxn8Brram+9E5ZdhQXjR613u8adjmXm20/hq1ayKm8xM997lga77JvgaCVqmfgeWR/1RTH1RTH1Rel0YVcFM7Pdwkd2uLyPmb0FXGdmWwKNgFXhzwBvAH2BP939enfv7u5L1774659w90Hu3s7d23U7o/JeFJMu9u6wGxMmTmbab9MBGPrK6+zfuWPEUSVOlVr1qN6iNQsnjl1jfYOdOjH/20/K3HbxT9/RZL8TALDsKjTe60gWTR6XsFglNWTae6Qs6oti6oti6ovMEOmYWDM7DHgOaEEw9rUxcB3BxVnTgbbAd8AWwBVmVh+YBfwMXAv0tuD7Aku3oQNDh49gUnwKt119QdShJN0mDepzR+/r6X7VDaxctZJNW7ag7603Rh1WwtRo2Zr8v/7AC1attX5rlv0xbZ32rc/tDcAvT/QmPvBy2lw2kL2emwyFBfz1zcdMfb5fEqKOnt4jmfMeKYv6opj6opj6onRRziSQCBbFlXpmll1i2MAE4H1gCvAVwQVbc4C9gW+AVcBgYDugmbs/HI6DHePu71R0bD57gi5dDFmdFlGHkDLeP7hJ1CGkjINe/jbqEFKC3h8iUm41GqZE9jj79FoJyXGaPrckkuOLZDhBiQS2M/ADcA5wHLAcuIxg2qyDgUlAy/BGBdOBWmY2CmgMrH+goIiIiIiktUiGE5hZFWAgsAnwKJAN7AccQ3Dnre2AHkAecEu42XigBvCRu6sUJCIiIvJPpNlwgkiSWHdfZWYrgHvdfZyZTQE+Bo4nmErrcWCku38DwU0Pwurt6CjiFREREZHUElUlNpvg7lpFg8qmA1OBrYFq7r6IYDzsGuNnRURERGTjpFkhNrJKbIGZvQicEY6L3RR4Exji7nPWbpv8CEVERETSS7rNThDZFFvhMIJfgJOBF9x9LKyu0ha6bnAsIiIiIusR6Tyx7j6PYE5YYI2xryIiIiJSgdKtEhv5HbsgSF4BVH0VERERkfKItBJbRMmriIiISGKlWSE2NZJYEREREUmwNMtiU2I4gYiIiIjIP6FKrIiIiEgGSLNCrJJYEREREUmOWCzWDHgY2BdYDgyKx+M3xmKxXIIZq7oABcC98Xj8jrL2pSRWREREJAOkyBRbwwnuytoEaAaMisViPwA7ADFgK6Au8F4sFpsZj8efWd+OlMSKiIiISMLFYrHdgS2BveLx+EpgaiwW6wwsA+4Gusbj8QXAglgsdjdwPqAkVkRERCSTpUAhdldgItA7Fot1JRhO8BDwBEFV9vsSbX8kqM6ul5JYERERkUyQoCw2FovVA+qV8tTCeDy+sMRyA6AjMIqgIrst8B4wN3x+aYm2S4EaZb2uklgRERER+Td6AL1KWX8z0LvE8gpgcTweL1o3IRaLPQ6cFS5XL9G2BrCkrBdVEisiIiKSARJ4Ydf9wOBS1i9ca/lHoEYsFsuNx+P54boqwAJgNsGFXTPD9duy5vCCdSiJFREREZGNFg4ZWFiOph8QDB24JxaLXUGQtJ4LXAhMAXrFYrH/A2oBVwL9y9qZ7tglIiIikgHMEvMor3g8vhzYh2A87B8E42HvisfjrwI3AZOAycBXwKvAI2XtT5VYERERkQyQCvPExuPxKcDhpaxfDlwcPspFlVgRERERqXRUiV2L//ZZ1CGkji33jTqClHHw+39GHULKKHjwqKhDSAnZ3YZGHULK8Py8qENIGVazUdQhpI6VSzfcRpIr+kJshVIlVkREREQqHVViRURERDKAZaVX7VJJrIiIiEgmSIELuypSeqXkIiIiIpIRVIkVERERyQSqxIqIiIiIREuVWBEREZEMYJZetUslsSIiIiKZQMMJRERERESipUqsiIiISCZQJVZEREREJFqqxIqIiIhkAFMlVkREREQkWqrEioiIiGQCTbElIiIiIpWNZWk4gYiIiIhIpNK2Emtmddx9sZmZu3vU8YiIiIhEShd2pTYzq2dmNwLHAyiBFREREUk/aVWJNbMsd19oZguAzc1sB3efGHVcIiIiIpFLswu70upo3L0w/PEtoCrQwcyqRhiSiIiISEows4Q8olKpk1gz62JmW5RYzjKzj4FtgM+BrYDdoopPRERERBKjUiaxZlbFzK4EjgTmmll7M9s3rMS+AJwFfA0sAdqZWaMIwxURERGJnlliHhGpdGNizSzb3VeZWQ1gLtARqA30APZ098fMrAtwOPAx0BVoC4yMJOAS3vjsR5585xvMoFpuDj1P34ftt2zC8x9O4JVRk1mRv4q2WzTmtnMPIDen9F/NH3/9zcm3vMiw206jfu3qST6CxPhg1DgGPvkCWWbUrVObW6+5iE1bNFv9/LB3P2Hwi8NXL/+dt5Q/5/zFyNefoGGDehFEnFwjR4/lnoGPkJ+fT2zr1tze6zpq1aoZdViJ1boTWYffSGH/A8k6qg/Ub1H8XN3mMP07Cl+/Zs1tLAs74HKs5c4A+NTP8ZEPJDHoxPtw5Gdc1bsv3418Y53nnntpGC+8+hZmRquWzbjt+svYpEH9CKJMLH1elC0jPy9K0Hsks1S6Sqy7F4Q/TgMuJEhihwHTzOx/4XPPAVcCvwMPuPvI5Ea5rql/LKDf0NEMuuoYXr/tNC44uj3dB7zFiK9+YcgHE3jymuN4844zWJ6/iqff+67UfQwb8wNn9HmFOQvykhx94ixfsYKrb72PgX2uZdjg+9l3r/b0uf/xNdocc+i+DBt8P8MG38/Lj99Nwwb1ueGybhnxH9L8+Qu4rlcfBvbrw/vDhtKqZXPuHvBw1GElVr2WZHX+HxD8dV/4Rk8Kn+4aPN7vC8uXUPjhPetsZtsdgtXfjMLBZ1D49JlBMrvNvkkOPnGm/T6DvgMGQSkTrkz64SeeHPIKQ5/oz1tDH2PzVi3o/+jTEUSZWPq8KFtGfl6UoPdIOaRZJTblk1izNS+lM7NjzOxL4Degf7h6JfA4cKmZXUVQhX0CmOXuE5IZ7/rkVsnm1nMPoHG94C/i7bdowrxFS3ll1CS6HroL9WpVIyvL6N11P47aq806289ZsISPvvmVx646JsmRJ1ZBQSHuzt9LgsR86bJl5ObmrLf948+9xib163LyMQcnK8RIjRn3JTu0bcPmm7UC4JQTjuXNd0eQtjPHValK1uG9KPxkwLrPZVUh69AbKPzkfvh7TinPZ0FONcjOgexcyK4CBfkJDzkZli1fzlW9+nJtj/NLfX77Ntvw/quDqV2rJitW5PPn3HnUq1s7yVEmnj4vypZxnxcl6D1SPmZZCXlEJaWHE4RTZhWGP1cBmgOnAhPcfZSZfQG8CRzi7u+a2e3ATsAt7v59VHGXpkWjOrRoVAcAd6fv85+y7y5b8uvM+cxfvJT/9hvGnIVL2HWbFlx58t7rbN+4fi0GXnpEssNOuJo1qtP7ygs55cJrqVenNoWFhTz/8J2ltl2wcDFPDR3Oq0+sW4VLV7Nnz6Fpk8arl5s2bsSSJXnk5S1Ny68I7aBr8AnDYO4v6z6345GQNw9+/rTUbX3SO1hsP7IuHA5Z2TDtS/j1swRHnBw33XE/Jx17OLHWW663TU6VKnw48jN69rmX3Nwcunc7K4kRJoc+L8qWaZ8XJek9kplSuhLr7oVmtrmZDQIGANnAcKDAzNq4+3LgZeAqM6vp7k+5+6X/NIE1s25m9rWZfT1o2JiKP5ASlq5YyWUPvMNvfy7i1nMOYGVBAWMnT+e+/x3KyzefwqK85dz/8tiExpBK4r9O46HBL/L2cwMZPfwpzj/zBLr37Ftq5eDFN95nv4670apF0wgijUahF5Y6fUlWdkq/dTeK7XQcFBbgk94u/fldT6Lw88Hr337Pc/ClCyl88AgKHz4GqtXB2p2SmGCTaMgrb1AlO5suRx2ywbYHdN6LLz54lUv+eybndr+OwsLCDW5TmejzomyZ9HlRkt4j/4CGEySOmWWH/1r4734EwwTeJpj39WTgF4KhBIcDuPsgYIC7b/RAUXcf5O7t3L1dt2PWrYJWlFnzFnPqLS+RlZXF09cdT52aVWlcrxYH7roVtapXJbdKNkfuuS0TfvkjYTGkmjFfjGfnHdqsvjDjtOMO5eepv7Nw0d/rtH33o8847rD9kx1ipJo1bcqcufNWL/85Zx5169SmRvX0uKivJNv+MKxpG7LOGkzW8fcEQwvOGgw1G0LjbYLq6vTSx4sD2Nad8YlvQeEqyM/DJ72LbbpL8g4gQV5/awQTv/+Jo087n26X9WT5inyOPu18/ixxXvw2fSZfj5+0evn4Iw9m1uw5LFq8JIqQE0afF2XLpM+LkvQeyVwbTGLNrKaZtTSzJmZ2o5ltVtFBmNkesMZFW9XCf+sAjwLjgRrACeFz04DNzGybcLthFR1TRctbls9Zd7zKge224t6LD6VabjCS4+D2rXnvy59Znr8Kd+ejb35l+y2bRBxt8rSNbclX4ycxb/5CAD4c/QUtmzWmfr06a7RbtHgJv8/8g5132DaCKKOzd4fdmDBxMtN+mw7A0FdeZ//OHSOOKjEKnzuPwsGnBxdwvXoFrFpB4dNdIW8e1mon/Pdvytze58SxbfcLFrKysdZ747MmJz7wBHtl8AO8NfQxhg95lEH39aFa1VyGD3mUJo0arm4zd958Lr+hD/MXLgLgzfc+ZustN1/nfVTZ6fOibJn0eVGS3iPlZ1mWkEdUyjMmdgjwFHA88D0wCKiQUfJmlgs8CNQCxplZe6AP8H9mNt/dbzezK4A93P0UM3uVYMqsJwnGvc6tiDiSYciHE5g1728+/OZXPvzm19Xrn7zmOBblLafLTS9QUFjIdps35ppTgw+dAa9+DkD34ztEEnMy7LHrjpx7yrGceckN5FSpQt06tXjwjuuZ+OMv3HjnAwwbfD8Av8/8g0ab1CenSkoP465wmzSozx29r6f7VTewctVKNm3Zgr633hh1WMlXvxUsmr3OatvrPAD8s8fxj/tjB1xB1jkvgBfgv32Df/lcsiNNmonfx7mhz70MH/Io7XbegQu6nsqZF1xJdnYWjRttwoP9ekcdYoXT50XZ9Hmxpkx8j2Qa29BVi2Y2CugMfOju+5vZSHfvXGEBmPUFlhHcnOBs4C5gNvAVcDSwPdABiAMHAbcmcsqswi8eSv/LOMvJtkyf6Yn+Laup+2UUKXjwqKhDSAnZ3YZGHULK8Pz0mfbv39JnRQkrl0YdQeqou2l05coSVvTaPiE5TtWbJ0VyfOX5MzUXuAL41sy2I6iaVqRVwOXAh8A4YD+gE0HFdw+CC7kOBnLcPbMGOImIiIhUlAgvwkqE8iSxVwDHEHzNfxpwUQXH8BJQABxAkLQuI7iAaxeChHYqcIq7r6zg1xURERGRSmqDSay7jw1v8XoCMBr4qSIDcPcJZjYF2JHgQq73gcfCn2/2YLyDElgRERGRf6G0Kdgqsw0mseENBFoCbYB84DqgQidfdPe/zexF4GrgWWCqu4+oyNcQERERkfRRnuEEe7t7JzP7xN2fNrMLExTLMKA6sEwJrIiIiEgFy7RKLFDFzKoBHt6MoGBDG2wMd19GMHWWiIiIiFQ0S6l7XP1r5Uli7wO+ARoBX4TLIiIiIiKRKc+FXS+b2YdAa4KxqvM2tI2IiIiIpJZMvLDrKcBLLOPu5yQ0KhERERGRMpRnOEHRbWmMYO7W5okLR0REREQSIivDKrHu/n6JxffMTDMHiIiIiFQylmkXdpnZQSUWmwFNEheOiIiIiMiGlWc4QckbGywHNB5WREREpLLJlAu7zCw3/PH8JMUiIiIiIlIuZVVi45SYlSBk4botExaRiIiIiFS8TKnEuvsWyQxERERERKS8ynNh11HAxUAOQSV2E3ffMdGBiYiIiEjFybibHQA3AZcAFwCfAAcmNCIRERERqXhpNsVWeY7mL3f/HMDdBwMtExqRiIiIiMgGlKcSu8LMOgE5ZnYwwVyxIiIiIlKZpNlwgvVWYs3sHDOrDlxIMB72NqAbwfACEREREZHIlFWJ3RG4HhgBDHL374HjkxKViIiIiFSodLuwy9zXngq2xJNmOcDRwNlAPeBJ4AV3X5qU6KKw6Pf1d0imyakRdQQiKevBPZtGHULKuHjs7KhDSBm+dF7UIaQMq9Ew6hBSR42GKZE9Ft7XKSE5TtZln0ZyfGVe2OXuK939FXc/HOgCbA38npTIRERERETWozzzxFYDjgXOBGoDVyc6KBERERGpYGk2nGC9SayZdQbOAjoDw4Gr3H1SUqISERERESlDWZXYm4FHgQvcfUWS4hERERGRREizmx2sN4l1932SGYiIiIiIJFCaDSdIr5RcRERERDJCee7YJSIiIiKVXaYMJyhiZi2AvkAj4BXg/9z9i0QHJiIiIiKyPuVJyQcR3OQgF/gU6J/QiERERESk4pkl5hGR8iSx1dz9Y8DdPQ4sT3BMIiIiIiJlKs+Y2BVmdjCQbWZ7oCRWREREpPLJtDGxQDfgbqAhcCVwYUIjEhEREZGKl2ZTbG0wiXX3GcDJSYhFRERERKRcyjM7wR+AAwY0AKa4e5tEByYiIiIiFSjNhhNs8GjcvZm7N3f3ZsA2wLjEhyUiIiIisn7/6GYH7v6bmW2bqGBEREREJEEybUysmb1AMJwAoBnwZ0IjEhEREZGKl2lJLPAisCD8eTnwdeLCqVhmluXuhVHHISIiIiIVqzxJ7JXuvnfCI0mAkgmsmZm7e1ntRURERNJWpl3YBcw3s0vN7BAzO8jMDkp4VBvJrLhOboHWZvYUBLcbiy4yEREREalI5anE/gXsFD4gGB87IkHxbJSiKmtRompmNd09z8zmhsuN3H1utFGKiIiIRChTxsSa2YvufpK7n53MgP6ptce9mtlhwEFm9jEwFshWAisiIiIZL82GE5RViW2UtCj+haIE1swuA5YCvwAvAQ8BpwKbmdke7p6S89t+OPIzrurdl+9GvrHOc8Pf/ZAnnn0ZM6herRo9r7iIHbaLRRBl8o0cPZZ7Bj5Cfn4+sa1bc3uv66hVq2bUYUVCfVEsk/pii32PZrcLe4EXsnzRAj655Xw6XHoH9TbdanWb2s23YNY3n/JOj2PX2f6cT2aTN2fG6uXvnr6Hn955ISmxJ1smnRclfTDqcwY+8QJZlkXdOrW49ZqL2bRlszXaPPfK2wx9/V3MjFYtmnLrtRezSf160QScZJl6XmQSW99QUTP7DRhS2nPufn0igypL0bjXEkMH9gKOABoDU4B2wNXAtsCuwJHAFe4+slwvsOj3pI2dnfb7DP7boyfz/prPd6PeXOO5Kb9N58wLruS1Zx+iccNNGPXZF/S6sz8j33w+WeFBTo3kvVYJ8+cv4PAup/PCU4+w+Wat6Nf/IfLyltL7+isjiSdK6otiqdYXD+7ZNGH7zq5ajXNH/smLJ+7Coum/8p/TL6Xl7vvz9iVHrW7TuG07Dun3Iq+dvQ9L/pyxxvb1NtuGwwcMY8jR2yUsxpIuHjs7Ka9TmlQ7L3zpvKS8zvIVK+hw2BkMe7o/m7VsxuChw/n86wk8evdNq9tM+vEXuvfsy/Cn76d2rZr0feAp8pYu45arL0pKjFajYVJepzSpdl5Qo2FKfI9f+MRxCclxss59LZLjK6uuvBSIr+cRiXDogLu7m1nVcHVPYHN3P9fd+wAfAhe6+5vA3QS3y20Tbp8SJxHAsuXLuapXX67tcX6pz+fm5HBbz8tp3HATALZvsw3z/lpA/sqVyQwzEmPGfckObduw+WatADjlhGN5890RZOK1eeqLYpnUF1lZ2YCRW6suADnVa1GwYnnx81Vy2P+WJxnd7/J1EliApjt1oLCggGOfHMlJL31Lu243YFnp9TVikUw6L0oqKCjE3fl7SR4AS5ctJzc3d40222/bmvdffJjatWqyYkU+f879i3p1akcRbtJl6nmRacoaTjDb3Z9OWiTl4O6FZlYNuBNobGbDgduA682srrsvAhYC08L2S8zsJoKqbErNUHDTHfdz0rGHE2u9ZanPt2zelJbNg0qPu3PH/Y+yX6cO5ObkJDPMSMyePYemTRqvXm7auBFLluSRl7c0474KUl8Uy6S+WLksj1F9LuL4p0ezfOFfWHY2r3XttPr5NseeQ97cP5j6yfBSt8/KrsKMLz7i8/7Xk5WTwxED3yQ/bzH/N2RAsg4haTLpvCipZo3q9L7qQk654Brq1alNYWEhzz/Sd512OVWq8OGn47jhzgfIzcmh+3mnRhBt8mXqebFBaTYmtqyj+SZpUayH2Zq9bWbtgeHALIJE9kogh+AuYreZWTfgEsKbM5hZE+AK4Ockhr1BQ155gyrZ2XQ56pANtl26bBmXXncrv8+YyW09L09CdNEr9EJKK5pnZafXm6881BfFMqkvGrTenvbdbuD543Zg8EGb8s3jd3DI3S+tfn6n0y/l68dvX+/237/2BKP79mDV8qXk/72I8c/ex5b7HpOEyJMvk86LkuK/TuOhp17k7eceYPQbgzn/rBPo3vPOUiuNB3Tag3HvPMf/zj2F8y7vTWFh+t8DKFPPi0yz3t+mu0c66C6cNqvooq2tw6EADYAtgDfd/f+Ax4DzgRsJxsL+BzjT3Z8Nd/MXcJK7l16uKH6tbmb2tZl9PWhw4secvv7WCCZ+/xNHn3Y+3S7ryfIV+Rx92vn8OXfNsVSzZs/h5HN7kJ2dzTMP3U2d2rUSHlsqaNa0KXNK9MWfc+ZRt05talSvHmFU0VBfFMukvth0z4P4Y8JYFs+YAsDEFx+iQevtqVZvExrGdsKyqzDr61Hr3X6bw09jk613WL1sZhSuSs+hSJl0XpQ05ovv2HmHNqsv5DrtuMP4ecrvLFz09+o2v834g28mfL96+fjD92fW7Lks+ntJ0uNNtkw9LzbILDGPfygWi9WLxWK/x2KxruFybiwWGxSLxebHYrG5sVjsuvLsJ+X+JDGzKhB89W9mm5rZY8ArwGXAPIJZB04Lm38CrHL3WQQVWnf3n8IbHZi7r3L3ORt6TXcf5O7t3L1dt66J/6rllcEP8NbQxxg+5FEG3deHalVzGT7kUZo0Kh4EvyRvKWdccAUH7bs39/XpSbVqVcvYY3rZu8NuTJg4mWm/TQdg6Cuvs3/njhFHFQ31RbFM6ou5P3xH8107Ub1B8HXoFvsezd8zp7J84V80b9eJmV9+Uub2m7Tent0u6o1lZZFdtRo7nHwxv4x4qcxtKqtMOi9Kahvbiq/GT2be/IUAfPjpF7Rs1pj69eqsbjN33nwu73U3CxYuBuDNEaPYestNqV+3Tmm7TCuZel5skGUl5vHPPQK0KLF8MxADtgLaA2fFYrEzN7ST8tzsIOHCKute7j7G3VeFy00JEtc3gfuAXsAc4DPgLjN7HtgMeDTczYPAy2bW2t1/SfpBVICJ38e5oc+9DB/yKENeHs6s2XP4YOQYPhg5ZnWbwQ/2W+NDKh1t0qA+d/S+nu5X3cDKVSvZtGUL+t56Y9RhRUJ9USyT+mLmV5/w3dP3cMzjH1G4Mp/lixfwzmXHAVBv09YsnvXbOtvsdmFvAL58uDdfPXoLna4dwMkvjycrJ4dfP3iV7197IpmHkDSZdF6UtMeuO3Luqcdw5v96kpNThbq1a/HgnT2Z+MPP3Hjngwx7+n7a7dSWC846gTP/15Ps7GwaN2zAg3dENrlQUmXqeVEZxGKxs4A6wMQSq88Cusbj8QXAglgsdjfBN+3PlLWv9U6xlUxm1hk4AxgAbA2cSDDudTrwLXAS0AxYRDDtV0PgPKCLu/9VdMMDM8t19/x/FUwSp9hKeRFNsSVSGSRyiq3KJsoptlJNsqbYqgyinGIr5aTKFFtPn5yQHKfN7d/VB+qV8tTCeDy+sGghFottAXwE7Am8B9wPDCO4lqlVPB6fEbbbG3gnHo+XWbVLleEEXwDfE8w0cBTQn6DKuhPQ3t0vAO4hKDNvTnDR2W/A0eH2DvCvE1gRERER+ad6AFNLefQoahCLxbKB54Ar4/F4yb98iy74WVpi3VJgg5W0lBhO4O7LzOwDYB/gU3f/zMyWAB8AXcxsK2Bn4GZ3fxvAzIYCf4fbq3oqIiIiUpbETbF1PzC4lPULS/x8IxCPx+OvrdUmL/y35FV3NYANXoGYEklsaBJBaTlmZk3dfYKZvQwcCnzg7mvcFcDd34siSBEREZFKKUH3fAqHDCzcQLOTgeaxWOy4cLk2wcX6uwGzCS7smhk+ty3BN/RlSpkkNhzT+hbQDegCPABcRVB9nQNgZtnuXhBhmCIiIiLyD8Xj8W1LLsdisfHA/fF4fHAsFlsC9IrFYv9HMLzgSoKhpWVKmSQWwN1/N7OfCO7GVR1Y5u5Li5JXJbAiIiIiGyl179h1E8G1T5MJrtcaRDANV5lSKokNDV37Ai0lryIiIiLpIx6P71Ti5+XAxeGj3FIuiS1KYMObFeiCLREREZGKkKAxsVFJuSS2iBJYERERkQqUusMJNkp6HY2IiIiIZISUrcSKiIiISAVKs+EEqsSKiIiISKWjSqyIiIhIJtCYWBERERGRaKkSKyIiIpIJ0mxMrJJYERERkUyg4QQiIiIiItFSJVZEREQkE2Sl13ACVWJFREREpNJRJVZEREQkE+jCLhERERGpdHRhl4iIiIhItFSJFREREckEaTacQJVYEREREal0VIldW06NqCMQSWm+eGbUIaSEi8fOjjqElPF4x6ZRh5Ayzhut82K1lcuijkDWlmZjYpXEioiIiGSCNEti0+toRERERCQjqBIrIiIikglUiRURERERiZYqsSIiIiKZQFNsiYiIiIhES5VYERERkUyQZmNilcSKiIiIZII0S2LT62hEREREJCOoEisiIiKSCXRhl4iIiIhItFSJFREREckEaTYmVkmsiIiISCZIsyQ2vY5GRERERDKCKrEiIiIimUCV2MrBzBqYWSzqOERERESk4qVtEgucAfQ1s9pRByIiIiISObPEPCKSVkmsmWWZWTaAu/cHDDgs2qhEREREUoBlJeYRkbRJYs0sy90L3b3AzDYPV98HdDWzZhGGJiIiIiIVrNInsSUqr4VmVtfM7geeM7O3ga+AX4AzzdLsNhUiIiIi/4QqsanDzMzdC4p+Bu4Cprj73kABcCNwC3AI8J/IAhURERGRClXpptgys1rAdu7+pbu7mXUgSFTvAt4A6prZPcB4gou7ngI+AXYL16WskaPHcs/AR8jPzye2dWtu73UdtWrVjDqsSKgvimVaX7g7197xINtsuSnnnnwUAIv/zuP07r3oc82F7LDtVuvdtrzt0kEmnReb7Xs0u57fCy8sZMXiBYy+7Xz+njGF0z+aTd6fM1a3+79n7+HXd19YY9vsqtXY85qBNGrbHjNjzqQvGdv3EgpWLE/2YSRFJp0XJT330jBeePVNzIxWLZtx2/WXs0mD+qufH/b2CJ56/tXVy38vyePPOXMZ9dZQGm5Sv7RdpqesSl27XEdlPJq6QCczO9jMjgUGAa+4+wfASGBH4EVgILAE+C9wm7sPiijecpk/fwHX9erDwH59eH/YUFq1bM7dAx6OOqxIqC+KZVpf/DptBl0vu4URo75YvW7UuG858cLrmTp9VpnblrddOsik8yK7ajU63/oMH155Aq+f2o7fP32LDlfdT93NtmHFovm8fmq71Y+1E1iAnc65nqzsKrx28s68dvLOVKlanf+cfW0ER5J4mXRelDTph594csjLDH2iP28NfZzNW7Wk/6OD12hzzOEHMXzIowwf8iivPP0gjTapz41XXZJZCWwaqoxJrANnAvcAk4HvgGrhc02BhgTDCF4BbnH3K929MIpA/4kx475kh7Zt2HyzVgCccsKxvPnuCNw94siST31RLNP6Ysiw9+ly+P4c3HmP1eueffVd+vW8hEYb+M+mvO3SQSadF5aVjZmRU6suAFVq1KJgxXIa79gBLyzgiMdHctzQb9n5vzdgpVSZZn83mu+euB3c8cJC/oqPp1azTZN9GEmRSedFSdu32Yb3X32a2rVqsWJFPn/OnUe9unXW2/6xp4fSoEE9Tj7uiCRGmSLSbIqtlB5OEI559RL/dgXeJKi+7gTUJEhm7zKzYe7+a3hh157A8+6+JKLQ/7HZs+fQtEnj1ctNGzdiyZI88vKWZsRXQSWpL4plWl/c1ONcAD77esLqdY/361mubcvbLh1k0nmxalkeY26/iKOeGs3yRX+RlZXNm+d0oln7zsz84iO+Gng9WVVyOLj/m+QvWczkFwassf3McR+s/rlW001pe2p3xvS5MNmHkRSZdF6sLadKFT4c+Rk9+9xDbm4O3budVWq7+QsX8dTzr/DaMw8lOcIUoTt2JY8X//lYPfx3D+Bpd38AGAuc6O4TgN+Bi8Jptia5+6DKlMACFHohpU2gkJWd0r+ihFBfFFNfSGky6byo33p7dv7vDbxywg68cMimjH/yDvbv9xLx15/g8349WLV8KflLFjFxyH1svu8x693PJtvuwhFPjOT7Fx9i+ui3k3cASZRJ50VpDui8F1988BqX/PdMzu1+LYWF634J+9Lrb7N/pz1p1aJ5BBFKRUu5M7toyqwSyycQzPeKu18AtDazfYD3gdpm9hrwITB8Y4cNmFk3M/vazL4e9OQz/+4ANlKzpk2ZM3fe6uU/58yjbp3a1KhevYyt0pP6opj6QkqTSedFyw4H8eeEsfw9YwoA37/0EPW32p7Wh51Gg9Y7FDc0o3DVylL3seVBJ3LoQ+/x1cDrmfDUnckIOxKZdF6U9Nv0mXw9fuLq5eOPPIRZs+ewaPHf67R954ORHHfkwckML7Voiq3ECm9WkG1mJ5hZHWAmkGVmRYNX7gOedPeZwP3AO+7+oruP/RevOcjd27l7u27nnPmvj2Fj7N1hNyZMnMy036YDMPSV19m/c8dIYoma+qKY+kJKk0nnxbwfv6PZLp2o3iD4mnyzzkfz96yp1N9qe3a5sDeWlUV21Wq0PfFipnzw0jrbb9rxCDpcdT/vXXwov743NNnhJ1UmnRclzZ03n8tv6MP8hYsAePO9j9h6y82pX6/uGu0WLf6b32fMYucd20YRpiRA5GNizSyLYOSAh8vHAJcDk4C2wGKCquspwFvAdKCOme3m7l8S3Myg0tukQX3u6H093a+6gZWrVrJpyxb0vfXGqMOKhPqimPpi/YYOH8Gk+BRuu/qCqENJukw6L/746hP+75l7OHzQRxSszGfF4gV8cPlx/D1rKntePYDjXhxPVpUcpn74KvHXnwBglwt6A/DtI73ZrUdfMKPjjY+u3uefE8Yytm/3KA4noTLpvCip3c47cEHXUznzgivIzs6mcaNNeLDfzUz8Ps4Nfe5l+JDgd//bjJk0atiAnCqRpz7RSbP7PlmUVy0W3So2/LklsBA4lyBpBegPTAEGE0yVtTvBXbj6uns8IUEtnZfel3GK/Eu+eGbUIaQEq9Mi6hBSxuMdm0YdQso4b/TsqENIHSuXRR1B6qjbKiWyx8LRdyckx8nqeGUkxxfpnyPhrWLrA7cB7YE/CaqvuwB1gAcJhjz8BvQAdvw3wwZEREREJD1EOibWzHYhSFRnuPtuBHO+bg60IbjbVm3geqCeuy9RAisiIiKykdLswq6oB4b8RXDzglXh8j3AEcA84EqgNXCcu88ofXMRERERyURRDyf4LZwia3cz287dvzezV4CWBLeKXbWBXYiIiIhIeehmBxXuI2ApcDKAu9/u7hcpgRURERGpQLrtbMVy94Vm9inBjQssXKcZAkRERERkvSJPYkOfKHEVERERSSANJ6h4SmBFRERE5J9IlUqsiIiIiCRSmlVilcSKiIiIZII0u+1seqXkIiIiIpIRVIkVERERyQRpNpwgvY5GRERERDKCKrEiIiIimUCVWBERERGRaKkSKyIiIpIJ0qwSqyRWREREJBNkaYotEREREZFIqRIrIiIikgnSbDhBeh2NiIiIiGQEVWJFREREMkGaVWKVxIqIiIhkgjRLYtPraEREREQkI6gSK+uXvyTqCFJHbq2oI0gZVqdF1CFIijlv9OyoQ0gZrx/QNOoQUsYxL4yMOoSUYXVbRR1CwDTFloiIiIhIpFSJFREREckI6VWJVRIrIiIikgl0YZeIiIiISLRUiRURERHJBLqwS0REREQkWqrEioiIiGSE9KpdptfRiIiIiEhGUCVWREREJBOk2ZhYJbEiIiIimSDNklgNJxARERGRSkeVWBEREZGMEG3tMhaLHQjcCWwNzAH6xePxR2OxWC7wANAFKADujcfjd2xof0piRURERCShYrFYK+BV4CxgOLAr8H4sFpsGdAZiwFZAXeC9WCw2Mx6PP1PWPpXEioiIiGSCaMfEbg48H4/HXw+Xv4rFYiOBvQgS267xeHwBsCAWi90NnA8oiRURERHJeAlKYmOxWD2gXilPLYzH4wsB4vH4aGB0iW0aAB2BZ4FmwPcltvsR2GFDr6sLu0RERETk3+gBTC3l0aO0xrFYrC7wBvAF8E24emmJJkuBGht6UVViRURERDJCwmqX9wODS1m/cO0VsVhsG4Ixsd8DpwHVw6eql2hWA1iyoRdVEisiIiIiGy0cMrBwQ+1isVgnggT2EeD6eDzuwPJYLDab4MKumWHTbVlzeEGplMSKiIiIZIIIL+yKxWJbAW8BPePx+MC1nn4W6BWLxf4PqAVcCfTf0D7TNok1sybu/mfUcYiIiIikBIv0UqiLgdrAHbFYrOQcsA8CNwH3AJMJxjwMIqjWliktk1gzawH0MrNx7v6kmZm7e9RxiYiIiGSieDx+OXB5GU0uDh/lllazE5gFdXJ3nwm8D+xlZvWVwIqIiIhYgh7RSKtKbFGyamZ7AUcAzYFTCUrVKW/k6LHcM/AR8vPziW3dmtt7XUetWjWjDisSd/Z/lPc+Gk3dOrUB2GKzltzfp2fEUUVD50Ux9UUx9UWxTO+LZp2Ops15vfDCQlb+vYDv7jyfvD+mscMl/Wiyx8FYdhV+fv5epg0bFHWoCefuXNvvSbbZogXnnnAIAHt0uZSmDeuvbnPuCYdw5P57RBWiVCCr7EVKM8t294ISy/sB/YAbCZLYTsBd7j6pXMMKls6LpEPmz1/A4V1O54WnHmHzzVrRr/9D5OUtpff1V0YRTiB/g7NbJMxJ5/bgmkv/yy47to0shjXk1orkZVPyvIiI+qKY+qJYqvXF6wc0TerrZeVW4/B3/+TjM3chb+avbHXSpTRuvz+zx75D0z0PZ9w1x1ClRm32GTSGb245mwU/fJW02I55YWTSXgvg199nccvAIfzfj1P435lHc+4JhzBl+mwuvGkA7z91e1JjWZtttnekt8oqUvjzuwnJcbK2PjSS46u0wwlKDB0oMLNsM9sxfKop8JS7v0Nwj94fgZPDtimbsY8Z9yU7tG3D5pu1AuCUE47lzXdHkMIhJ0x+fj7f//QLjz/7Mkeeej6XXHMLs2bPiTqsSOi8KKa+KKa+KJbpfWHZ2WBGTq26AFSpXouCFctp3ukYfnt7MF5QwMq/FzLjw5dodcipEUebWEPe+IQuh3bk4E7tVq/77vtfyM7K4rTL7+So83vx4HNvUFBQGGGUUpEqXRJrFlxaV2LowAnAWKC/mfUAfqU4aV0A1Afam1kskoDLafbsOTRt0nj1ctPGjViyJI+8vKVlbJWe/pw3nz123YkeF3TljSGP8J/t23DRVb0z5j+lknReFFNfFFNfFMv0vihYlsf4uy6i06OjOWT472zZ5SImP3Qd1Zu0ZNmcGavbLZszg+qNWkYYaeLd9L/TOHK/NYcJFBQU0GGXNjzW5zKeu+caxnw9meeGfxRRhCnAshLziEilSmLNLMvdC8Ofa5tZZ+BYYB/gBqA38B0w0cwGmNnHQE3gInePl7Hfbmb2tZl9PejJZxJ8FKUr9EKslPnbsrIr1a+oQrRq3pTH7r+NbbbaHDPj3NO78PuMP5jxR+bNmKbzopj6opj6olim90WdLbdn23Nu4KPTduC9ozcl/vQd7H77S1hWNpT4w9/M8MKCMvaUnk48bB9uvPg0alSvSp1aNeh6/IF88Nm3UYcVGTNLyCMqlepd7u6FZtbYzB4luMXZPOAj4ArgUGAiMIRgioa7gHvc/SJ3/3UD+x3k7u3cvV23c85M6DGsT7OmTZkzd97q5T/nzKNundrUqF69jK3S048/T2HYOx+usc5xcrKzI4ooOjoviqkviqkvimV6XzTe/SDm/99Y8mZOAWDKqw9RZ8vtWTr7d6o1bLa6XbWGzVk2Z+b6dpO2hn84lviU6auX3SGnSub9X5KuKlUSa2Z1gBeBScDdQDWCW5QVuvsNwDCgPdDa3We4+9tRxfpP7d1hNyZMnMy034I329BXXmf/zh0jjioaWVlZ9Ln3YabPmg3A86++Raz1FjRt0ijiyJJP50Ux9UUx9UWxTO+LhT99xyY7d6Jq/WBIRfNOR5P3x1T+GP0Gmx1xNpadTU6turQ84ERmfTo84miT7+dpMxnw9DAKCgpZviKfIW98zKH7tI86rAhlJegRjUo1O4GZ1SeosP4I7E8w/vV0gqS2BjAa6Ovuf2z0i0Q0OwHAqNFjuWfgo6xctZJNW7ag7603Uq9unajCiXR2guHvfsRjz7xIQWEhTRs3pE/Py2netPGGN0yUiGYngBQ8LyKkviimviiWSn2R7NkJALY47kK26nIRhSvzyV+8gAn3dmfJ73G2/99dNG5/AFk5uUwd9hi/vHBvUuNK9uwERa7t9wRbbx5MsbVs+QpufXAIE36YwqpVBRzcqR2XnX1c0r8CT5XZCfzXDxOS49hWB0RyfJUqiQUws0YECew3BONdLwAeBWq6+5h//QIRJrEpJ8IkNuVEmMSKSOURRRKbqqJKYlNRyiSxUz5KTBK75f6RHF9lvNnB3wTJ6/XAFsAgd/8u2pBEREREUlyEF2ElQqVLYt19uZm9AqwAXnb3FVHHJCIiIiLJVemSWAB3XwQ8F3UcIiIiIpVHpbqef4PS62hEREREJCNUykqsiIiIiPxDGhMrIiIiIpVOmiWxGk4gIiIiIpWOKrEiIiIiGSG9apfpdTQiIiIikhFUiRURERHJBBoTKyIiIiISLVViRURERDKBpVftUkmsiIiISEbQcAIRERERkUipEisiIiKSCXRhl4iIiIhItFSJFREREckEurBLRERERCodDScQEREREYmWKrEiIiIiGUGVWBERERGRSKkSKyIiIpIJ0uzCLnP3qGNILUvnqUNkHb58UdQhpAyrVjfqEESkEui9S7OoQ0gZvX9cmRLf4/sf4xOS41iznSI5vvRKyUVEREQkI2g4gYiIiEgm0BRbIiIiIiLRUiVWREREJCOoEisiIiIiEilVYkVEREQygcbEioiIiIhES0msiIiIiFQ6Gk4gIiIikgk0nEBEREREJFqqxIqIiIhkhPSqxCqJFREREckEGk4gIiIiIhKttExizSzHzE6OOg4RERGR1GEJekQj7ZJYM8sCmgGXmdkBJdaJiIiISJpIq+TOzLLcvdDdfwdeB84FcPfCaCMTERERiZhZYh4RSask1t0LzayVmQ0C2gCtzKwrqBorIiIimU7DCVKGmWWXsvocYKm7nwXcBpxhZnXDBDe9LssTERERyVCVOol19wIAMzsyfNQCcoB3w+ffA2YB14TLHlWsIiIiIpFKs+EElWqe2KJKalEyamaNgeeAacBKYAugAXCImU0F6gAO1DezXHfPjyJuEREREalYlaYSa2ZVPGRmOeHqHYBP3b0bQcK6D/AW8CdwA3AvMNjdL1QCKyIiIpktvcbEpnwl1sx2c/cv3X1VuNwbqGlmDwH5wKXhVFoPhMur3P1OM2vo7vNK7CdLsxSIiIiIpIeUTWLDoQO7AfXCn+sAzwLjw3+3AH4G3gf+AiYDAwkqsSOA+eF+st29oDIksCNHj+WegY+Qn59PbOvW3N7rOmrVqhl1WJHI1L6I/zKV2+59hCVL8sjKzuLmay5h+223XqPNG+99zBNDXsXMqFa1Kj0vP58d2mwTUcTJlannRWnUF8XUF8UyqS92O/1idjvtQlYtX87cKT/wzi3dKSwo4Og+g2i4RQzLymL8sGf57PG719nWsrI47MYBbN6+IwA/f/oeI+66JtmHkHxpdn17Sg4nKDF04AvgU+B0gljrAr8AVwPHAXcC/wNmEwwfuMXd74fiuWGLLv5KdfPnL+C6Xn0Y2K8P7w8bSquWzbl7wMNRhxWJTO2LZcuXc16PGzjv9C68/swDXHT2KVzVq98abab8NoN+DzzBY/fdyrBnHuDCs0+m+3V9Ioo4uTL1vCiN+qKY+qJYJvXF5rvvw97nXckzXQ/mkWPb8fOo9zjylofZ79KbWTx7Jg8dtTODTuhA+1POp+VOe6yz/X+OPp2GW2zDQ0ftzMPH7Mpm7Tux3cHHR3AkyZZewwlSMol191VmVsvM+gI9CCqy+wJnANWBRwgS2ZrAKuAudz/N3T+1UEShb7Qx475kh7Zt2HyzVgCccsKxvPnuCDJxQoVM7YvPvviWVi2asc+e7QHYr+Me3N/nujXa5ObmcOt1l9K4YQMAtt92a+b9tYD8lSuTHm+yZep5URr1RTH1RbFM6ovmbXdhyucfs/jPmQD88MHrbLPvEYy46xpG3HU1ALUbNSM7pyor/l60zvaWlU1O9ZpUya1KldyqZOfksip/eVKPQf69lEhi174RgZntDLxHMONAf+A7YC+C6bMWAkcAI4EP3H1Jiam2soou/kpe9BVj9uw5NG3SePVy08aNWLIkj7y8pRFGFY1M7Ytp02fScJP69OxzP8ef3Z1zuvdkVcGaXyS0bNaEznvtBoC7c+eAx9i34+7k5uSUtsu0kqnnRWnUF8XUF8UyqS9mTPiSLXbvTN3mmwKw83FdqZJbler1GlBYUMBxdz3NRW+OZ9pXo5g3Nb7O9uNff5rlixdw+ajfuGL0dOb//gs/ffJ2sg9D/qXIk1gzs6Kv/s2sU5jA/kBwkdb37r4U+Ar4Gzga+ATIA05y9wdL7qsyjHtdn0IvpLQCclZ25L+ipMvUvli1qoBPx37NicccwqtPDeD0E47k/Mt7kZ+/bpV16bLl9Oh5B7/PmMVt110aQbTJl6nnRWnUF8XUF8UyqS9+/+YzRj54GycPfIVur4zDCwtZuvAvClYGExG9dvVZ3NWhKdXrNmCfi29YZ/vOF99I3vx53L13C+7dZ3Oq121Ah7N7JPko5N+K7MwuuttWOGVWq3C2gZsJKq/nAC8DR5pZHWASMIVgKMFCd7/V3aeaWVZFDB0ws25m9rWZfT3oyWf+7e42SrOmTZkzd/VkCvw5Zx5169SmRvXqkcQTpUzti0YNG7Dl5q34T9ttAdi/UwcKCguYPuuPNdrNmj2HU7pdQXZ2Fk8/cCd1ateKItyky9TzojTqi2Lqi2KZ1Be5NWvx21ef8ujxuzGoyx78+NEbADTffldqN24GQP7SPCa9/SLNttt5ne3bHHgM3732FAUrV7JiyWImDHuWLXbvnMxDiISZJeQRlciSWHcvMLMaZtYJuArY1N33Bc4CDgBGEYwW7hYOD3jN3fsUzfdaVMGtiKED7j7I3du5e7tu55z5b3e3UfbusBsTJk5m2m/TARj6yuvs37ljJLFELVP7olOHdsycNZtJP/4MwFffTcTMaNms6eo2S/KWcubF13Jg5z2599ZrqVatalThJl2mnhelUV8UU18Uy6S+qN24OV2f+ZCqNWsD0OmC65j09ou0PeQE9rn4RgCyc3Jpe0gXpo4buc72f3w/nraHnABAVpUqxPY9ghnjv0ha/NFJrwu7LKrho2Z2JHAZMJxgdoGzgTPcfa6ZPQl8AEwF2rn7AyW2S+x8r0vnRTaedtTosdwz8FFWrlrJpi1b0PfWG6lXt05U4UQq1frCl697YUAifPXdRPo98ATLlq8gJyeHnpedT25uDjfeMYBhzzzAo0+/SP9Bz7LNVpuvsd1TA2+nfpL6x6rVTcrrlCbVzosoqS+KqS+KpVJf9N6lWUL3v9tpF9H+1AuwrCx+/2Ys79zanSq5VTmi94M03rotAD98OJyRA2/G3dn3kl4AfDLwZqrXa8BhN/anWZudKCwoYOq4Txhx19UUJOgi2d4/rkyNC84XTE1MjlN/i0iOL+FJbFgx9RL/7uTu481sOPC7u19iZnUJZhvIBZ4guHHBLe7+aUKDK02ESaykrmQlsZVBlEmsiFQeiU5iK5OUSWIXTktMjlNv80iOL6HDCYoSVwjGvoar3zGzownmeK1pZm3cfRHwDsE0Wv2BviUT2Mo4ZZaIiIiIJE5CktiSF22Fy8ea2Unh092Am939c4I7bR0QXrz1LTAE+MHdPwi3s5L7EREREZGNlV5jYhOSxJaYt/U0M7sfaAMcbWZ13P0tYJGZXQcMAvYBGrr7MoK5X5uF02wpeRURERGpKGaJeUQkUZXYGmb2ArA/MIJgeqw/gVPDJi8A1wO/Af9z9ynh+u+BC939u0TEJSIiIiLpoUqC9ptDkCC/CXQAmgINgY5mtg+wFDg5nC5rdtHYWXdfAaxIUEwiIiIiGSy9LjFKVBK7BHiIIIH9AXiVoAr7AtColDttadiAiIiIiJRbQpLY8EYGYwmqr3WA24EJwMslLvZK7HyvIiIiIlIszSZ7SlQlFndfaWa/ABcAd649ZZYSWBERERHZWAlLYgHcfQJwYdFyUfVVwwdEREREkk2V2H+sRPKq6quIiIhIFNJsOEFC79hVRMmriIiIiFSkpFRiRURERCRqqsSKiIiIiERKlVgRERGRTJBehVglsSIiIiKZIb2yWA0nEBEREZFKR5VYERERkUygKbZERERERKKlSqyIiIhIRkivSqySWBEREZFMkALDCWKx2H+AR4AdgSnAOfF4/KuN2ZeGE4iIiIhIwsVisVxgOPAiUA/oA4yIxWJ1NmZ/SmJFREREMoIl6FFunYGceDx+fzweXxmPx4cCk4GTNuZoNJxARERERDZaLBarR1BZXdvCeDy+sMTydsAPa7X5EdhhY15XSezaajSMfMCImXVz90FRx5EKUqUvrEbDqENImb5IBeqLYuqLYuqLYqnQF71/XBnly6+WCn2RMhKX4/QGepWy/ubwuSK1gKVrtVkK1NiYF9VwgtTULeoAUoj6opj6opj6opj6opj6opj6opj6IvHuB7Yo5XH/Wu3ygOprrasBLNmYF1UlVkREREQ2WjhkYGE5mn4PXLbWum2BZzbmdZXEioiIiEgyfAJYLBa7DHgAOJ5gqq3XN2ZnGk6QmjR2p5j6opj6opj6opj6opj6opj6opj6IkXE4/F84FCC5HU+0BM4Jh6Pz92Y/Zm7V2B4IiIiIiKJp0qsiIiIiFQ6SmIlpZnZSDPbNuo4KpqZVTOzaWZ2v5ltmsDXOdbMmidq//+WmWWb2ftmNsbM6m/kPi4ys/FmVupk2WbW28wu+HeRJoeZdTWzO6OOozIzs03N7Mh/0D4tP2NKY2aHmNngqOOIQnjsGz1LgZlta2YjKzAkqQC6sEskQu7eI8EvcSlwATArwa+zsZoBDd1913+xj+OAM9x9YgXFJJXbfgRXO78ZdSCSOtz9vahjkIqnJDYJzKwO8DjB3SwaAo8R3GJtPLA9UAc4wd1/M7MbgWOBuQRzp91IcJu2PQkmCX4RaOnuV5lZdriPdu6+InlH9O+ZWXXgKWAzIAe4AriYEn3k7g+XaN8baB0+1wB4iGBg+DbAWe4+LonhbxQzqwUMAeoDv4TrRhIkmZsA9wArgQXAacAqgmlHmgPTgU7u3rxoG3f/MawwNgXuBF4C6hLMwXc1UBPYCXjGzPZ29/ykHOg/MwjY2syeAmoT9ANAd3efaGb/I0hSc4BF4c+nAucQfJP0LNAOeCKsxL7g7nsAmNk44ORkHkwF2cPMRgCNgIcJLn64mOJ7O3Yh+NzoCRQS/P4HufuD4bnxI0ESZwSfM92BmeHz9YEP/+UfDQllZl2Bwwg+/7YC+gLfAAMIjukvgt//zgTvg5PD7WYDLYBrgRpmNha4nOCztD7B58VjrOczprIxs22AwQSfGauAMwkmlm9F8D56191vNLM2wJME83PmEXy+pKxSjutJ4MiSv2d3bxpWlDcJH/2Aiyj9/VD0+38B2Jpg4v01PivdfaSZnUBwvhQAY9z9WjNrRvCZbcDshB+8/GMaTpAcrYGh7n4QcATBGwXgS3c/APgAOMXM/kNw1V574BiCKlWRH9x9T4I39DFhAnsI8EllS2BDFwDT3L0D0BXYldL7qKRl7n4I8BpwmLsfSZC8VZZEpSswyd07AY+u9dwxBMe1D8HvuD7BBN1T3X0vgg/eJmXseyuCD+8jCZK8Gu7+NsEfOWemaAILwX883wNzgI/cfV+C437YzLII/oM6wN07EiSy7cPtFrj73u7+KOExAulylepK4GCCP2Z7EPyhdri7dwbi4XMQJGxHAXsAl5lZ43D92LDti8D1BH9Anxk+dyrBf8qprq67H0FwfNcSJJ8Xh8f1DsEfaetw9wKCz4Tn3f2NcPXz4efsVmz4M6YyOZAguT8A6EPwmTHO3Q8G9gYuDNvdCtwU9sHYKAL9h0o7rvX5OPx/cQHrfz8U/f4LwuV1PivNrAHBHwD7u/veQAszO5CguPJC+Lk0rOIOUSqKKrHJMRvoYWbHAYsJ/jMG+C78dzrBm6oNQWJbACwzs69L7CMO4O5/m9kogv/IzgZuSUL8iRAD3gVw90lmNh+4s5Q+Kunb8N+FBIkPBB9e1RIbaoVpC7wH4O5fmFnJezLeTlBZ+wiYCXxBcD4Utf/RzEqbgsTC5yeb2YME1YYcgqpVZbIDsF+Jca313b3QzPKBF8xsCdCS4vMiXo59Rn4L6Y30rbt7WFmsQZDgPx32wbbA52G7sUV/wJrZJIL/nAE+LnoeONrdp5jZ32a2HUGF/6hkHci/MD78dzrB+7sN8JCZQXAO/FTKNuv7fRedK+v7HK6sngCuIfiMWETwh257M9uX4Piqhu3aAl+GP39G0JepbO3jGrHW8yV/zyU/B9b3fljjs2I9n5WtCb75eCc8x2oDWxL03bPhpp9R/IeBpAhVYpPjSuBzdz8deJniN+HalaPJBB9CWWZWleDrsiKFJX5+DDgPaOzu/5egmBPtB8KqmpltSTDpcWl9VFJlr7T9CHQAMLOdWfM/0dOAweFf/JMJqpGTSrTfiuArUIDlFFfpdwmf3wGo7e6HA2cBA8PnC6kc7/MfgfvCStuJwBAz2xE4xt1PAi4hOI6i86KwlH0sBxqHF4vVI7jlYWVU8jyvS1AhOpngPb+M4j7YKTzWGgT/2f4cri8aKrAXwbkEwWfGDcAMd5+XwNgrytrv9TjBNwqdCaqwb1PifWBmmxEMM4J1z/mic2V9n8OV1dHAaHffn+B4JgAL3f00gqFJNSzIyFZ/7lD8TUYqW/u4TqL03zOs+TmwvvfDGp8V6/msnErwB9OB4Tk2kKCQUNn6LuOoEpscbxJ8PXoawXiuVRT/lbxaOAbwHWAcMI/ga8WVpbT7wsxaAw8mNOrEehR4MqwqZwPDgUtL9lGYyKeTB4GnzGwMwYdjyWEgX1FcbcsnSGJnA4PN7FPgN4L/tCGoHDxoZtMJqrYQfGD3MrMzw+1vCtePJRgTe5C7z0/cof1rfQjGtXYjGCPem2DccF74jcQK4A+C8cGlcvfZZvYBQV/+Ej4qu8UE/5l+S/F4xuYE/+nmEHybsQlwm7vPC6tIXc3s8rD9GeF+Xif4Q/H0pEZfcS4kOI+zw+VzgSnAQjP7guCP4qnhcxOBnmb27Vr7WOdzuJJ/xnwNPGdmqwgStb2BR8ysI8Hv/meCc+Ui4EUzu4pgfOjy9ewvVax9XFcR/D7X/j2vbX3vh7Wt81np7nPN7F5gVHiOTSMYN3sjQd+dXMbrSoR0s4MUEo7h6eLuD4UfrpOB/dz997XaZRF8tXGwuy+OIFRJAjPbE6jl7iPMbGvgPXffakPbSfozs86UuKipxPqR4fof11pfAxgF7O7upVWxRSqt9b0fJP2pEpta5hEMJ/iK4Ou0x0tJYLcgqKo8qgQ27U0hGA/ai6DKcHHE8UglFP4x9CjQUwmsiKQTVWJFREREpNKpDBd8iIiIiIisQUmsiIiIiFQ6SmJFREREpNJREisiKc/MOpvZHDMbaWafmNk4M7tkI/d1p5l1NbOdzOymMtoda2brndJrrbaHhLfBLLnuGTM7Z611l5nZbevZx0gz27Y8ryciIkpiRaTy+NjdO4c3hNgHuCK8qcFGcffx7l7WHe8uJZizdmMNovh2r0XOIrgNrIiI/EtKYkWkMqpNcC/0VWEF82Uz+9DMqprZE2b2qZmNCeePxMyON7PvzGwEwb3Vi6q7Q8OfzzWzr8M2vc3scGAnggn2c83sEjP73MzGmln3cJs24boPKeV2lO4+BmgU3mUIM2tPcAOL+Wb2kpmNMLNvzWyNbcPXvyD8edtw7lfMbJ/wmEaZ2ZNmlmNm24QxjTKzj8ysRQX3s4hIylISKyKVxX5hwvoxMAS4xN2XhM897+4HAOcA89y9E8HtK4vuancXcABwMLC05E7Dm4xcC3QkuGVrXYIbA4wnqKS2Jrj15d7h4xgziwG3Etzt5wCCO6OV5gmK75J1NsF8ra2Boe5+EHAEcPmGDjy8fehjwHHuvg/Bndq6AgcC34TH1geov6F9iYikC93sQEQqi4/LuCNPPPx3B6Cjme0eLlcxsybAYnf/C8DM1k44twQmufuycPmysF3R89sDmwEfhcv1CRLRtsCX4brPgDalxPUM8JGZ3QN0BroDjYEeZnYcwW1lc8o45qIgGhHcP/6lMK7qwAiCxPUa4D1gEXB9GfsSEUkrqsSKSDoouhPVj8AL7t4ZOBR4GVgA1DWzRmGb9mtt+yuwbXirZ8zslfBr+UKCz8g4wS2g9w33OxiYGL5Wh/XsEwB3n0dwv/cbgdfdfRVwJfC5u58exrf2Dd6XEySsALuE/84DZgBHhzH0AT4hqDaPdvf9w31ds74OEhFJN6rEikg6eRR4zMxGEVyU9ZC755vZ2cD7ZjYfWFlyA3efa2Z9gVFm5sCb7j4zrNg+AxxEUIUdEya6XxJ8nX8R8KKZXQXMJUg+S/MY8A4QC5ffBB42s9OAvwjG9VYt0f5FgoprJ4KhArh7oZldCrxtZlkEFdwzCcYGP2dmqwiS7ss2ptNERCoj3XZWRERERCodDScQERERkUpHSayIiIiIVDpKYkVERESk0lESKyIiIiKVjpJYEREREal0lMSKiIiISKWjJFZEREREKh0lsSIiIiJS6fw/7Q1L8mNqePQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "listik = ['angry', 'calm', 'disgust', 'fearful', 'happy', 'neutral', 'sad', 'surprised']\n",
        "df_cm1 = pd.DataFrame(array, index = [i for i in listik],\n",
        "                  columns = [i for i in listik])\n",
        "print(df_cm1)\n",
        "print()\n",
        "plt.figure(figsize = (12,8))\n",
        "plt.title('Seaborn heatmap (%)')\n",
        "sn.set(font_scale=1.2)\n",
        "aa=sn.heatmap(df_cm1, annot=True, cmap=\"Oranges\", fmt='g', annot_kws={\"size\": 12})\n",
        "aa.set_yticklabels(df_cm1,rotation=30)\n",
        "aa.set_ylabel('True Values')\n",
        "aa.set_xlabel('Predicted Values')\n",
        "plt.savefig('ravdesFemale_65.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59SPrpr-XnOT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}